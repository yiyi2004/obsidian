- Time：2023-06-06 15:53
- Label： #LLM #AI

- [x] 收集资料,并熟悉这些资料 ✅ 2023-06-06

## Abstract

随着 ChatGPT 的爆火，越来越多人开始关注大语言模型（Large Language Models）。但其实早在去年就有一些国外大学开设了相关的课程。发现知乎上这方面信息并不多，因此打算在这里长期持续更新相关的内容。

这些课程通常由 NLP 大牛教授开设，系统性强，并有配套的讲义、PPT 与相关论文推荐，很适合感兴趣的同学快速入门。

这部分内容主要收集大语言模型的资料.

## Content

### LLM 课程

- **Stanford CS324 - Large Language Models**
- 课程链接：[https://stanford-cs324.github.io/winter2022/](https://link.zhihu.com/?target=https%3A//stanford-cs324.github.io/winter2022/)
- Percy Liang 刚开的新课，主要材料是一些 notes，介绍了大语言模型的基础知识、能力范围、训练部署以及一些大模型相关的问题（数据安全、法律、危害等），总体来说比较简单，适合入门。
- **JHU CS 601.471/671 NLP: Self-supervised Models**
- 课程链接：[CSCI 601.771 (Self-supervised Models)](https://link.zhihu.com/?target=https%3A//self-supervised.cs.jhu.edu/sp2023/index.html)
- JHU 也是 NLP 大牛校，这门课难度适中，课程主页上各类资源还挺多的，建议大家看一看。
- **Princeton COS 597G: Understanding Large Language Models**
- 课程链接：[https://www.cs.princeton.edu/courses/archive/fall22/cos597G/](https://link.zhihu.com/?target=https%3A//www.cs.princeton.edu/courses/archive/fall22/cos597G/)
- Danqi Chen 的课，课程难度较高，主要材料是 PPT 和相关的论文，适合深入 LLM 某个方向的同学。
- **Stanford CS224N: Natural Language Processing with Deep Learning**
- 课程链接：[Natural Language Processing with Deep Learning](https://link.zhihu.com/?target=https%3A//web.stanford.edu/class/cs224n/)
- 这门课 Christopher Manning 在斯坦福开了很多年，很经典的课程。前面是 NLP 的基础知识，后面几节课会涉及到大语言模型。
- **Hugging Face NLP Course**
- 课程链接：[https://huggingface.co/learn/nlp-course/chapter1/1](https://link.zhihu.com/?target=https%3A//huggingface.co/learn/nlp-course/chapter1/1)
- Hugging Face 大家应该不陌生，最受欢迎的 NLP 社区，提供模型与数据集。这门 NLP 课程结合了他们的框架的学习代码，推荐给需要实践的同学。

### NLP 课程

- **Princeton COS 484: Natural Language Processing**
- 课程链接：[Natural Language Processing](https://link.zhihu.com/?target=https%3A//princeton-nlp.github.io/cos484/)
- Danqi Chen 最近刚开的课，课件的质量还是挺高的。前半部分传统 NLP，后半部分深度学习 NLP。
- **JHU Course # 601.465/665 Natural Language Processing**
- 课程链接：[Natural Language Processing](https://link.zhihu.com/?target=https%3A//www.cs.jhu.edu/~jason/465/)
- JHU 开了很多年的 NLP 课程，但是大部分内容主要涉及传统 NLP，如果对这些经典 NLP 算法细节感兴趣的话可以看一看。
- **JHU 601.467/667 Introduction to Human Language Technology**
- 课程链接：[https://jhu-intro-hlt.github.io/](https://link.zhihu.com/?target=https%3A//jhu-intro-hlt.github.io/)
- 机器翻译大佬 Philipp Koehn 的 NLP 基础课，涉及文本和语音方面的基础知识与应用。

### 学习资料

- **Speech and Language Processing (3rd ed. draft)**
- 教材链接：[Speech and Language Processing](https://link.zhihu.com/?target=https%3A//web.stanford.edu/~jurafsky/slp3/)
- 最经典的 NLP 教材，本来计划在大概三四年前就完稿的，但是由于近几年 NLP 领域发展实在太快，作者干脆就不设 DDL 了，一直在持续更新中。
- **李宏毅 【生成式 AI】**
- 课程链接：[https://www.youtube.com/watch?v=yiY4nPOzJEg&list=PLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W&ab_channel=Hung-yiLee](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DyiY4nPOzJEg%26list%3DPLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W%26ab_channel%3DHung-yiLee)
- 李宏毅老师的视频，讲得比较深入浅出。这个系列的视频除了介绍 ChatGPT 以及背后的原理，还涉及到其他生成式 AI 比如 AI 绘画的核心算法 Stable Diffusion。
- **李沐 【跟李沐学 AI】**
- 课程链接：[跟李沐学AI的个人空间-跟李沐学AI个人主页-哔哩哔哩视频](https://link.zhihu.com/?target=https%3A//space.bilibili.com/1567748478/)
- 李沐老师的 B 站视频，最近上了一些大模型相关的论文精读。
- **吴恩达 Andrew Ng - ChatGPT Prompt Engineering for Developers**
- 课程链接：[ChatGPT Prompt Engineering for Developers](https://link.zhihu.com/?target=https%3A//www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
- 学习笔记：[hibo：吴恩达联合OpenAI新课ChatGPT Prompt Engineering for Developers学习笔记](https://zhuanlan.zhihu.com/p/625917566)
- 吴恩达教授最近开设的一小时的提示工程教学视频，最后还会教你如何利用 GPT 开发一个 AI 聊天机器人。
- **The Illustrated Transformer**
- 笔记链接：[The Illustrated Transformer](https://link.zhihu.com/?target=https%3A//jalammar.github.io/illustrated-transformer/)
- 非常经典的 Transformer 笔记，图文并茂的讲解 Transformer 的结构。如果你还不熟悉 Transformer，那务必尝试一下这个资料！

### LLM 论文

#### 综述

- [A Survey of Large Language Models](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2303.18223)
- LLM 的综述论文，必看

#### GPT 系列

- 李沐 GPT 系列论文精读：[GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili](https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1AF411b7xQ/%3Fspm_id_from%3D333.788%26vd_source%3D1e55c5426b48b37e901ff0f78992e33f)
- GPT1：[Improving Language Understanding by Generative Pre-Training](https://link.zhihu.com/?target=https%3A//s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
- GPT2：[Language Models are Unsupervised Multitask Learners](https://link.zhihu.com/?target=https%3A//d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- GPT3：[Language Models are Few-Shot Learners](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2005.14165)

#### 指令微调

- RLHF：[Training language models to follow instructions with human feedback](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2203.02155)
- Instruction Tuning：[FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.01652.pdf)

### OpenAI 相关

- OpenAI 官方博客：[Blog](https://link.zhihu.com/?target=https%3A//openai.com/blog)
- OpenAI Cookbook：[GitHub - openai/openai-cookbook: Examples and guides for using the OpenAI API](https://link.zhihu.com/?target=https%3A//github.com/openai/openai-cookbook)
- OpenAI 应用研究主管 Lilian Weng 个人博客：[Lil'Log](https://link.zhihu.com/?target=https%3A//lilianweng.github.io/)

## Reference

- [大语言模型（LLM）课程、论文与资料推荐 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/623894148)
