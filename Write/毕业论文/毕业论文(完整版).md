# 摘要
几年来，由于机器学习算法

# 简介
近些年，由于机器学习算法和深度神经网络急速得到快速发展，使分类模型的性能得到了很大程度上的提升，当训练集和测试集满足独立同分布的基本假设时，分类模型可以很好的运作。然而，在实际应用中，往往不能保证训练集和测试集之间有相同的分布，例如图片中具有相同的主体，但是其所处的环境、光照、拍摄角度不同，这些非关键因素，往往会引起训练集和测试集的分布差异。而且在实际场景中，人工标记的数据并不是很多，而且人工标记成本有时会很高，例如对 Cityscapes 中的一张图像进行语义标注。因此需要新的方法来解决这些问题。

机器学习的一个不可否认的趋势是深度神经网络的使用增加。深度网络已经为各种机器学习任务 [73, 80] 产生了许多最先进的结果，例如图像分类、语音识别、机器翻译和图像生成 [79, 80]。当对大量数据进行训练时，这些多层神经网络可以学习强大的分层表示 [80、147、182、226]，并且可以高度扩展 [76]。同时，这些网络也可能由于域漂移（domain shift）而导致性能下降 [72, 226]。因此，许多研究已经开始将此类网络从大型标记数据集调整到很少（或可能没有）标记训练数据可用的域（有关列表，请参见 [257]）。这些单源且通常是同质的无监督深度域适应方法，将深度学习的好处与域适应的非常实际的使用相结合，以消除对潜在成本高昂的目标数据标签的依赖。
领域自适应的研究场景可按照不同维度进行划分，本文将从数据标签是否可获取、参与域的数量、跨域数据特征空间的构成 3 个维度对域适应算法进行分类。
# 研究背景
## 迁移学习
本文的重点是无监督域自适应。由于领域适应可以被视为迁移学习的一个分支[182]，我们首先回顾迁移学习，以强调领域适应在本主题中的作用。迁移学习主要解决的是将一些任务（source domain）上学到的知识迁移到另一些任务（target domain）上，以提升目标任务上的效果。当目标任务有较充足的带标签样本时，迁移学习有多种实现方法。例如，采用 Pretrain-Finetune 的方式，先在源任务上Pretrain，再在目标任务上用一定量的数据 Finetune；或者利用 Multi-task Learning 的方式，多个任务联合训练。例如，我们可能希望在手写数字数据集（例如MNIST[130]）上学习一个模型，目的是使用它来识别门牌号（例如 SVHN[175]）。或者，我们可能希望在合成的、廉价的交通标志数据集[168]上学习一个模型，目的是使用它对真实的交通标志进行分类（例如GTSRB[224]）。在这些示例中，用于训练模型的源数据集是相关的，但与用于测试模型的目标数据集不同——两者分别是数字和符号，但每个数据集看起来都有显著差异。当源和目标不同但相关时，可以应用迁移学习来获得目标数据的更高精度。然而，当目标任务没有带标签的数据，或者只有非常少量的带标签样本时，上述两种方法就无法采用了。因此，领域自适应（Domain Adaptation）应蕴而生，主要解决目标任务没有数据或数据量非常少无法训练模型的场景。

Domain Adaptation是一种源任务和目标任务一样，但是源域和目标域的数据分布不一样，并且源域有大量的标记好的样本，目标域则没有（或者只有非常少的）有标记的样本的迁移学习方法。这样就是怎么把源域上从大量的有标记样本中学习的知识迁移到目标域上，来解决相同的问题，而目标域上能利用的大多只有没有标记的样本。
本文介绍了Domain Adaptation的基本方法，主要介绍了基于对抗学习的Domain Adaptation框架，以及在此框架基础上的优化方法，包括4篇近5年的顶会论文。核心思路是，让feature generator生成的source domain和target domain表示同分布，以此实现source domain上训练的模型可以直接应用在target domain的目标。当我们面临目标域样本缺少有标签数据时，Domain Adaptation是一个有力方法。
### 领域自适应
领域自适应的基础结构主要分为特征提取器（feature extractor） 和分类器（classifier）其中，特征提取器用来从源域（source domain）样本或目标域（target domain）样本上提取特征表示，分类器用于根据特征提取器提取的特征进行具体的分类任务。领域自适应的核心思路为，让特征提取器部分生成的源域或目标域的特征表示是同分布的，即将源域和目标域的特征表示进行对齐。这样后续的分类器就可以使用源域上训练好的模型预测目标域的数据了，无需再用目标域有标签样本进行微调（Finetune），解决了目标域无有标签数据的迁移学习问题。


### 相关定义(排版时候完成)
本小节主要介绍迁移学习与领域自适应的相关定义和符号表示方法

域（domain）：域由两部分组成，特征空间 $X$ 和其边缘分布$P(X)$，其中$X=\{x_1,\dots，x_n\}$，$x_i$ 为训练数据，可表示为 $D=\{X, P(X)\}$

任务（task）：对于某一域$D={X, P(X)}$，它的任务也由两部分组成，可记为$T=\{Y，f(·)\}$。其中 $Y$ 是标签空间，$f(·)$ 为映射函数。在机器学习中，$f(·)$ 经由数据训练得到。由于机器学习一般是有监督的，因此训练数据包含训练图片 $x_i \in X$ 及其对应的标签 $y_i \in Y$，可以为数据标签对 $\{x_i, y_i\}$。

迁移学习（transfer learning）：给定一个源域 $D_S$ 和源学习任务 $T_S$，目标域 $D_T$ 和目标学习任务 $T_T$，在 $D_S \neq D_T$ 或者 $T_S \neq T_T$，即源域和目标域不相同的设定下，迁移学习旨在利用源域 $D_S$ 和源学习任务 $T_S$ 的知识来帮助提高目标域 $D_T$ 中目标预测函数 $f_T(x)$ 的学习性能。

域漂移（domain shift）：了解 domain shift 需要先了解贝叶斯公式：
$$
p(x,y) = p(x|y)p(y) = p(y|x)p(x)
$$
域漂移主要分为以下三种情况，分别由输入的边缘概率分布 $p(x)$，输出标签的边缘概率分布 $p(y)$，以及对应的条件概率分布$p(x|y)$ 或者 $p(y|x)$ （后验分布）不一致导致的。

**Covariate Shift**：输入的边缘概率分布不同，其他相同。以领域自适应为例，源域$S$，目标域 $T$，机 $p_s(x) \neq p_t(x)$，但是条件分布概率相等 $p_s(y|x) = p_t(y|x)$，输出标签的边缘概率分布也相等，$p_s(y) =p_t(y)$。这个很好理解，就是数据采样方式不同，导致输入数据的分布压根就不一样。

**Prior Shift（即Label Shift）**：从名字也可以看出，输出的边缘概率分布（先验分布）不同，即 $p_s(y) \neq p_t(y)$ 对应的条件概率分布相等，即 $p_s(y|x) = p_t(y|x)$ 。这种偏移属于先天类型的偏移，是由于源域数据和目标域数据每个标签的数据出现的频率不一样导致的，比如标签为猫的数据在源域中占了80%，而在目标域中只有30%。

**Concept Shift**：：两个边缘概率分布都相同，即 $p_s(x) = p_t(x)$、$p_s(y) = p_t(y)$但是后验分布不同，即 $p_s(y|x) \neq p_t(y|x)$。这种比较奇怪，我感觉就是模型的问题。比如面对同样的目标域样本，然后域适应模型分类错误的概率比纯粹在目标域样本上训练的模型高，就是说模型能力不行。还有个例子是：输入数据类型分布相同，但是学习的任务发生了变化；比如在水处理系统的传感器时间序列异常检测中，因为上游放水，一段维持较高水位，但是并不能和其余时间一样被认定为是报警事件。但这种学习任务发生变化的不太可能在训练过程中发生。

### 领域自适应分类
域自适应根据目标域中的数据是否包含标签可分为三类：目标域中所有数据均包含标签的有监督域自适应，目标域中少量数据包含标签的半监督域自适应和目标域中没有数据包含标签的无监督域自适应。无监督域自适应旨在减小源域(有标签的数据)和目标域(无标签的数据)之间的域偏移对模型性能的影响，使用源域中的数据提升模型在目标域的性。由于深度神经网络有着强大的层次化特征学习和数据表征能力，并且在计算机视觉任务中发挥着重要作用，因此本文主要聚焦无监督深度域自适应。

### 相关问题
多域学习和多任务学习学习与迁移学习和领域自适应有关。与迁移学习相比，这些学习方法的目标是在指定的域(或任务)获得高性能，而不是仅仅在单个目标域(或任务)。例如，我们经常假设训练数据集中的数据是独立同分布的，但事实并非如此。一个典型的例子就是去为对什么是垃圾邮件有不同标准的用户去训练一个垃圾过滤器，如果所有用户的数据都结合在一起，训练数据可以被视为来自于多个域。每个域中的数据可能是独立同分布的，但是结合起来的数据集就不一定了。如果根据每个用户去划分数据集，每个数据集中的数据可能不足以来训练一个较好的模型。多域学习能够利用整个数据集来学习个体用户的偏好。一些研究人员已经开发出对抗的策略来解决这个多域学习挑战(89、213)。

当处理多个任务时，而不是为不同的任务单独训练模型（例如，一个模型用于检测图像中的形状，一个模型用于检测图像中的文本），多任务学习将同时学习这些独立但相关的任务，以便它们可以通过（部分）共享表示从其他任务的训练数据中受益[29]。 如果同时存在多个任务和域，那么这些方法可以组合成多域多任务学习，正如 Yang 等人所描述的那样。 [261]。

另一个相关的问题是领域泛化（domain generalization），其中模型在拥有标记数据的多个源域上进行训练，然后在训练期间未看到的单独目标域上进行测试[173]。 这与在训练期间可以使用目标域数据（可能未标记）的领域自适应形成对比。示例包括 Zhao 等人介绍的对抗性方法。  [284] 和 Ghifary 等人的自动编码器方法。  [75]

## 生成对抗网络
生成对抗神经网络(Geberative Adversarial Networl) 是无监督学习的一种方式，通过让两个神经网络相互博弈的方式进行学习，该方法由伊恩·古德费洛等人于 2014 年提出。[1] 生成对抗网络由一个生成器(Generator) 和一个判别器(Discrimiter!)组成。生成网络从潜在网络中随机取样作为输入，其输出结果需要尽量模仿训练集中的真是样本，判别网络的输入则是真实样本或生成网络输出，其目的是尽量将生成网络生成的的样本与真实样本区分开。而生成网络的目的是尽量生成假样本却迷惑判别网络。生成网络和判别网络相互对抗，不断更新参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。这里可以配上一张图片（GAN 里面的原图）

领域泛化是领域自适应中的一种特殊的技术，其目的是基于领域自适应技术学习对于任何不可见的目标域的具有很强鲁棒性的分类器。所谓不可见的目标域是指在分类器的训练过程中，我们并不知道目标域的任何情况。与传统的机器学习方法不同，由于目标域和源域是具有不同的概率分布的，如果在训练过程中我们无法获得目标域的任何信息就代表着训练出的分类器可能无法在目标域上取得良好的表现，而在现实应用中，目标域往往是不可知的。从其目的上看，这项技术有两个主要的难点：一是目标域不可见，二是要对任何目标域都起作用。按照我个人的理解，第二项难点中的“任何”二字应该还是有局限的，比如说源域为图像分类任务，目标域应该也和图像分类有关而不能是自然语言理解之类的任务，所以在这里的“任何”并不是广义上的任何。在这个层面上来讲，我们剩下的难点就可以融合成一个，即目标域不可知。

## 无监督域自适应(拓展的写一下)
### 基于距离度量的方法
为了减少源域和目标域的数据分布差异，可以基于某种差异度量指标将源域和目标域特征映射到一个公共的再生核希尔伯特空间（RKHS）中，通过最小化域间分布差异的度量指标学习特征变换，实现源域和目标域的分布对齐，这便是基于距离度量的方法的基本思想。度量域间分布差异的指标包括KL散度、最大均值差异（MMD）、Wasserstein 距离等。典型方法包括 TCA、JDA、DAN、WDGRL 等等。

### 基于对抗学习的方法
基于对抗学习的方法一般来说同时训练特征提取器和一个域分类器，域分类器用来判断特征提取器生成的表示来自于哪个域（源域或目标域）。经过两个优化任务的对抗训练，最终特征提取器生成的表示让域分类器无法分辨是来自源域还是目标域，达到了不同域生成特征同分布的目标。在整个过程中，域分类器替代了基于分布距离度量约束方法中衡量分布差异的距离度量函数。

可以看出，无论是哪种方法，核心都是衡量特征提取器生成的源域和目标域表示的差距，并在模型优化目标中最小化该差距。目前主流前沿方法集中在基于对抗学习的零与自适应的方法。下面我们将简单介绍多篇近几年顶会中对基于对抗学习的领域自适应的优化方法。

#### Maximum Classifier Discrepancy for Unsupervised Domain Adaptation
Maximum Classifier Discrepancy for Unsupervised Domain Adaptation（CVPR 2018）认为，传统的对抗学习领域自适应方法在对齐两个域的特征时，没有考虑目标域样本和具体任务分类边界之间的关系。如下图所示，现有的方法直接将两个域特征对齐，而对齐后的特征无法被源域上训练超平面（模型）有效区分。因为源域有标签而目标域无标签，因此目标域的分类实际上是在复用源域的分类平面，如果目标域的特征没有考虑到源域的分类超平面，就可能导致对齐后的特征无法有效使用源域的分类器进行分类。本文优化的核心思路是，寻找那些用源域分类器进行分类效果不好的目标域的样本，让特征提取器产生的目标域样本表示更好的被源域的分类器分类。

![[Pasted image 20220512164624.png]]

具体的做法示意图如下。首先生成两个不同的源域的分类器，然后让特征提取器生成的表示能够尽可能减小两个分类器的预测结果的不一致性（disagreement），即如果一个目标样本的表示被两个不同的分类器分类产生的结果不一致的话，这个样本很有可能是无法被源域分类器很好区分的，因而特征提取器对于这个样本生成的特征表示很有可能是不适用于下游任务的。本文对两个分类器引入 Maximize Discrepancy 目标，让两个分类器产生的结果尽可能差异大，同时让特征提取器生成的表示经过两个分类器后尽可能差异小，这也是一个对抗学习的过程，同时 Maximize Discrepancy 让两个分类器尽可能产生差异，防止两个分类器最后学的一样而失去了判别样本disagreement 的能力。在下图中，黑线表示源域学到的准确分类器，阴影表示目标域中让两个分类器产生 disagreement 的样本。在 Maximize Discrepancy 过程中，两个分类器分歧增大；在Minimize Discrepancy中，特征提取器产生的表示能更好的被源域分类从而减小分歧。

![[Pasted image 20220512164640.png]]

#### 学习 Domain-specific 表示辅助 Domain-invariant 表示
基本的领域自适应方法对齐源域和目标域的表示，但是没有考虑每域独有的信息。如果能将 domain-specific 的信息提取出来，有助于域不变性（domain-invariant）部分的学习。Domain Separation Networks（NIPS 2016 提出使用 private-share 类型的网络结构实现公共部分和私有部分分离的结构。整个网络包含 Encoder、Decoder、Classifier 三个部分。Encoder包括一个两个 Domain 公用的 Encoder，以及每个Domain 特有的 Encoder；Decoder 用来根据 shared encoder 和 private encoder还原图片，是两个域公共的；classifier 根据源域的表示进行图像分类。

模型的损失函数主要包括4个部分，除了任务分类损失和 decode r的 reconstruction损失外，包含 difference loss 和 similarity loss。Different loss 用来让 private-encoder 和 shared-encoder 编码不同的表示，为了达到这个目的，通过正交损失进行约束（让两个向量正交）：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/dcUv9UF2OUVCliarHqXQ3y5YC5iczBVuDyAmEkqIKd9HnB5s6qhUib6e26Qic1ZfibialTKACX5Q976wBKm0oumVyhVQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

Similarity loss 让两个域生成的表示更相似，采用经典的是用 MMD 度量两个Domain生成表示的距离，并用 GRL（在 DANN 小节详细阐述过） 方式实现训练。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/dcUv9UF2OUVCliarHqXQ3y5YC5iczBVuDyFfMicY5aUfwAR0VwicuWeSwZX2iatqwuN9mGtlF1XjCln2Wibo5aytZZDg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### Gradually Vanishing Bridge for Adversarial Domain Adaptation

#### Heuristic Domain Adaptation（NIPS 2020）
Heuristic Domain Adaptation（NIPS 2020）中提出，学习 domain-specific 表示要比 domain-invariant 表示更容易，因此先学 domain-specific 表示，再用总的表示减去 domain-specific 表示，就可以得到 domain-invariant 表示。基于这个思路，本文提出了一种启发式的 domain adaptation 框架。在下面的模型结构图中，F(x) 表示图像整体的表示，G(x) 为通过对抗学习提取到的 domain-invariant 表示，H(x) 为通过启发式方法学习到的 domain-specific 表示，G(x)=F(x)-H(x)。通过学习H(x)，将 doman specific 部分从 F(x) 中有效的去除，得到G(x)。要注意的是，H(x)只需要去除掉 G(x) 中根据对抗学习学到表示中的 domain specific 部分（通过对抗学习已经能去掉一部分 domain specific 表示了，这部分表示可以不管），因此 H(x) 和G(x) 应该具有相似的 domain specific 部分。
  
![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/dcUv9UF2OUVCliarHqXQ3y5YC5iczBVuDys3FicAC2mJQicIORKdF4mMNRlSZF1zFoejQv8ibr2DWvgU2Wia0jh7P6uw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

中心极限定理表明：对于混合信号，其概率密度比任何一个源信号的概率分布都接近高斯分布；反过来，最大化信号的非高斯性与最大化信号的统计独立性是一致的，ICA就是利用了这一原理进行独立成分分析。为了让 F(x) 更好的被拆分成两个独立的表示，本文提出引入对 F(x) 的非高斯性度量作为约束。最终，网络的损失函数由两部分组成，分别是 Generator Loss（对抗学习零与自适应的分类损失和域分类损失）以及heuristic 损失：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/dcUv9UF2OUVCliarHqXQ3y5YC5iczBVuDyGeiaPWvHL6hH7UNuhpD7EYAHgmz7UWCOoW5nNpUFKia4n1urCiaYjkX7w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



> 这里可以列举一些常见的方法（简介，而不是详细介绍）。

# 正文部分
## DANN
### DANN 简介
第一个基于对抗学习的领域自适应工作是 Unsupervised Domain Adaptation by Backpropagation（ICML 2015，UDA），该工作提出的框架至今仍然被各个工作作为基础。DANN 模型的主体结构如下图，主要包括特征提取器（Feature Extractor）、域分类器（Domain Classifier）、标签预测器（Label Predictor，用于预测源域上数据的标签） 三个部分。模型训练过程中，输入一批来自源域或目标域上的样本，经过特征提取器后生成特征表示。一方面，对于有的源域数据，特征表示会进入标签预测器进行分类任务学习，损失函数为交叉熵损失。另一方面，源域和目标域的特征表示都会进入域分类器，域分类器根据特征表示预测该样本是来自源域还是目标域。模型的优化目标由下面两个优化目标组成：

![[Pasted image 20220512162702.png]]

其中 $D$ 代表 Discriminator，也就是上述的 Domain Classifier，$D$ 的目标是分辨出源域和目标域；$G$ 代表 Feature Extractor，$G$ 的目标是既让图像分类任务预测的好，同时生成的 feature（特征表示） 能够欺骗 Discriminator（最大化 Domain 分类loss，对抗 Discriminator）。整个模型端到端训练，其中使用了 gradient reversal layer（GRL），即在反向传播的过程中将 Discriminator 的梯度加上负号用来更新Feature Extractor 的参数，达到对抗学习的目的。

![[Pasted image 20220512162716.png]]

### DANN 模型
在上一小节中我们简单介绍了 DANN 模型，在本节中，我们将会详细说明具体的 DANN 模型。我们假设模型与输入样本 $x \in X$，其中 $X$ 是特征空间，其对应的标签（输出） $y \in Y$ ，其中 $Y$ 是标签空间，我们假设分类问题的标签空间是一个有限集合（$y = \{1,2,3,...,L\}$）DANN 方法是通用的并且可以应对任何标签（输出）空间（像其他深度前馈神经网络做到的那样）。我们进一步假设存在两个分布 $\mathcal{S}(x, y)$ 和 $\mathcal{T}(x,y)$ 在 $X \otimes Y$ 上。其中  $\mathcal{S}(x, y)$ 代表源域(source domain or source distribution)， $\mathcal{T}(x,y)$ 表示目标域(target doamin or target distribution)，源域和目标域的分布都是未知的，它们相似但不同，换句话说，$\mathcal{S}$ 和 $\mathcal {T}$ 之间存在域漂移(domain shift)。

![[Pasted image 20220517104918.png]]

我们的最终目标是能够在给定目标域中的输入 $x$ 的情况下预测标签 $y$。 在训练时，我们可以访问大量训练样本 $\{x_1, x_2,\dots ,x_N\}$ 他们来自于自边缘分布 $\mathcal{S}(x)$ 和 $\mathcal{T}(x)$ 。 我们用 $d_i$ 表示第 $i$ 个样本的二进制标签（域标签，其实是一个二分类问题），它表示 $x_i$ 是来自源域（$x_i\sim \mathcal{S}(x) \; if \; d_i=0$）还是来自目标域（$x_i \sim \mathcal{T}(x)\;if\; d_i=1$)。 对于来自源域 ($d_i=0$) 的示例，相应的标签 $y_i \in Y$ 在训练时是已知的。 对于来自目标域的示例，我们在训练时不知道标签，我们想在测试时预测这些标签。 我们现在定义一个深度前馈网络，对于每个输入 $x$ 预测其标签 $y \in Y$ 及其域标签 $d \in \{0, 1\}$。 模型分为三个部分，我们假设输入 $x$ 首先通过映射 $G_f$（特征提取器）映射到 $D$ 维特征向量 $f \in \mathbb{R}^D$。$f$ (feature extractor, 特征提取器)可能包括几个前馈层，我们将这个映射中所有层的参数向量表示为 $\theta_f$ 即 $f = G_f(x; \theta_f)$。 然后，特征向量 $f$ 通过映射 $G_y$（label predictor 标签预测器）映射到标签 $y$，我们用 $\theta_y$ 表示这个映射的参数。 最后，相同的特征向量 $f$ 通过带有参数 $\theta_d$ 的映射 $G_d$（domain classifier, 域分类器）映射到域标签 $d$（图 1）。 在学习阶段，我们的目标是最小化训练集上的损失值，

通过最小化训练集上的损失值来优化优化特征提取器和标签预测器的参数。这确保了通过特征提取器得到的特征 $f$ 的判别性以及特征提取器和标签预测器组合在源域上的整体良好预测性能。同时，我们想让特征 $f$ 具有域不变性。也就是说，我们要使分布 $\mathcal{S}(f) = \{G_f(x; \theta_f) |  x\sim\mathcal{S}(x)\}$ 和 $\mathcal{T}(f) = \{G_f(x; \theta_f) |  x\sim \mathcal{T}(x)\}$ 相似。  然而，考虑到 $f$ 是高维的，测量分布 $\mathcal{S}(f)$ 和 $\mathcal{T}(f)$ 的相异性并非易事，而且再学习过程中，分布本身也在不断变化。估计差异的一种方法是查看域分类器 $G_d$ 的损失值，前提是域分类器的参数 $\theta_d$ 已被训练以能够很好的区分两个分布。

在训练时，为了获得域不变的特征，我们寻求使域分类器的损失最大化的特征映射的参数 $\theta_f$（通过使两个特征分布尽可能相似），同时寻求参数 $\theta_d$ 最小化域分类器的损失值。 此外，我们寻求最小化标签预测器的损失值。 更一般的，上述表达可以由下面的公式进行表达：
$$
\begin{equation}
\begin{aligned}
E(\theta_f, \theta_y,\theta_d) = \sum_{i=1..N, d_i=0}{L_y(G_y(G_f(x_i;\theta_f);\theta_d),y_i)} - \\
\lambda \sum_{i=1..N}{L_d(G_d(G_f(x_i; \theta_f); \theta_d), y_i)} = \\
= \sum_{i=1..N,d_i = 0}L_{y}^{i}(\theta_f, \theta_y)-\lambda\sum_{i=1..N}{L_d^i(\theta_f, \theta_d)}

\end{aligned}
\end{equation}

$$

上面是公式(1)（再 overleaf 中应该能正常标号吧）

这里，$L_y(\cdot,\cdot)$是标签预测的损失值，$L_d(·,·)$ 是域分类的损失，而 $L_y^i$ 和 $L_d^i$ 表示在 第 $i$ 个训练样例。基于上述讨论，我们的目的是为了寻找提供函数 (1) 鞍点的参数 ${\hat{\theta}}_f$、$\hat{\theta}_y$、$\hat{\theta}_d$：

$$
\begin{equation}
\begin{aligned}
&(\hat \theta_f, \hat \theta_y) = \arg\min_{\theta_f, \theta_d}{E(\theta_f, \theta_y, \hat{\theta_d})} \\
&\hat{\theta_d} = \arg\max_{\theta_d}E(\hat{\theta_f}, \hat{\theta_y}, \theta_d)


\end{aligned}
\end{equation}
$$
公式(2) 和公式(3)

在鞍点，域分类器的参数 θd 最小化域分类损失（因为它以负号进入（1）），而标签预测器的参数 $\theta_y$ 最小化标签预测损失。 特征映射参数 $\theta_f$ 最小化标签预测损失（即特征是有区别的），同时最大化域分类损失（即特征是域不变的）。 参数 $\lambda$ 控制在学习期间塑造特征的两个目标之间的权衡。 下述公式展示了标准随机梯度求解器 (SGD) 可以适用于鞍点 (2)-(3) 的搜索。

$$
\begin{equation}
\begin{aligned}
&\theta_f \longleftarrow \theta_f - \mu \left (\frac{\partial L_y^i}{\partial \theta_f} - \lambda \frac{\partial L_d^i}{\partial\theta_f} \right) \\
&\theta_y \longleftarrow \theta_y - \mu \frac{\partial L_y^i}{\partial \theta_y} \\
& \theta_d \longleftarrow \theta_d - \mu \frac{\partial L_d^i}{\partial \theta_d}

\end{aligned}
\end{equation}
$$
公式(4)、公式(5)、公式(6)

其中 $\mu$ 是学习率 (可以随时间变化)。更新 (4)-(6) 非常类似于用于前馈深度模型的随机梯度下降 (SGD) ，所谓的前馈深度模型包括特征提取器（feature extractor）、标签预测器（label predictor）、域分类器（domain classifier），其中特征提取器的输出是标签预测器和域分类器的输入。与 SGD 不同的是 (4) 中的 $-\lambda$ 因子 (差异很重要，因为如果没有这样的因子，随机梯度下降将试图使特征在域之间不相似，以最小化域分类损失)。尽管 (4)(6) 作为 SGD 的直接实现是不可能的，但是非常希望将更新 (4)-(6) 减少到某种形式的SGD，因为 SGD (及其变体) 是在大多数用于深度学习的包中实现的主要学习算法。幸运的是，这种减少可以通过引入如下定义的特殊梯度反转层 (GRL) 来实现。梯度反转层没有与之相关的参数 (除了元参数 $\lambda$ 之外，它不会通过反向传播来更新)。在前向传播期间，GRL 充当身份变换。但是，在反向传播期间，GRL从后一层获取梯度，将其乘以$-\lambda$ 并将其传递到前一层。使用现有的面向对象的包实现深度学习这样的层很简单。

在特征提取器和域分类器之间插入了如上定义的 GRL，从而形成了图1所示的体系结构。当反向传播过程通过 GRL 时，用 $-\lambda\frac{\partial L_d}{\partial \theta_f}$ 去代替 $\frac{\partial L_d}{\partial \theta_f}$。因此，在生成的模型中运行 SGD 实现了更新 (4)-(6) 并收敛到 (1) 的鞍点。 在数学上，我们可以正式将梯度反转层视为 “伪函数”$R_{\lambda}(x)$，由此描述其前向和反向传播行为的两个（不兼容）方程定义：

$$
\begin{equation}
\begin{aligned}
&R_{\lambda}(x) = x  \\
& \frac{\mathrm{d} R_\lambda}{\mathrm{d} x}  = - \lambda \mathrm{I}
\end{aligned}
\end{equation}
$$
公式(7)、公式(8)
$$
\begin{equation}
\begin{aligned}
&\tilde{E}(\theta_f, \theta_y, \theta_d) = \sum _{i =1..N, d_i=0}
{L_y(G_y(G_f(x_i; \theta _f);\theta_y), y_i)} + \\
&\sum _{i = 1..N} L_d(G_d(R_\lambda (G_f(x_i; \theta _f));\theta _d), y_i)
 

\end{aligned}
\end{equation}
$$
公式(9)

其中 $I$ 是一个单位矩阵。我们可以定义 (θf, θy, θd) 的目标 “伪函数”，该伪函数通过该方法中的随机梯度下降进行优化：更新 (4)-(6) 然后可以实现为对 (9）并同时获得具有域不变性和判别性的特征。 在学习之后，标签预测器 $y(x) = G_y(G_f(x; \theta_f); \theta_y)$ 可用于预测来自目标域（以及来自源域）的样本的标签。 

1. 攻防技术
2. 综合
3. 网络安全
4. 


## ToAlign
### ToAlign 简介
ToAlign: Task-oriented Alignment for Unsupervised Domain Adaptation（NIPS 2021）提出另一种方法来生成便于下游任务分类的域对齐方法。在以往的思路中，通过直接将源域的表示和目标域表示全部对齐。然而，有一些和分类任务不相关的表示，这些表示不被对齐对下游任务没有坏处，同时又能让和任务相关部分的表示更好的对齐。例如，当进行图像中实体分类时，对齐不同域的图像中的实体部分特征表示非常重要，而不同域的图像的背景区域不需要对齐。本文的思路为，识别出哪部分是和下游任务相关的，哪些是无关的，然后只对齐和下游任务相关部分的表示。两种思路的对比如下图所示。

![[Pasted image 20220512164041.png]]

为了识别表示中哪部分是和下游任务相关的，本文采用 Grad-CAM 方法。Grad-CAM/CAM 通过图像分类层最后一层的输出的权重，衡量上一层生成的表示每一个channel 的重要性，再对各个 channel 各个像素点的值加权，得到对于分类最重要的像素点，如下图所示。通过这种方式，可以识别出对于当前分类任务来说，哪些像素点是和任务最相关的。

![[Pasted image 20220512164113.png]]

识别出哪些像素点和任务最相关，接下来就可以在表示对齐的时候，通过像素的任务重要性加权实现有选择性的对齐。具体的实现比较简单，相比 baseline 模型，Discriminator 的输入在生成的表示上乘每个表示（像素点）对于下游任务的权重，来实现对任务相关的表示进行迁移，对任务不相关的表示不进行迁移。模型结构如下图：

![[Pasted image 20220512164154.png]]

### ToAlign 模型
用于分类的无监督域自适应 (UDA) 的目的在于在有标签的源域图像集和未标记的目标域图像集上训练分类模型，以在目标域测试集上获得较好的分类效果。正如上一小节中所述，基于整体特征的对齐得到的模型是次优的，其中这种对齐不明确地服务于分类。 为了解决这个问题，如图 1 (b) 所示，ToAlign 提出了一种有效的面向任务的对齐方式，以明确地使对齐服务于分类。ToAlign 提出根据分类元知识将源样本的特征分解为应该对齐的任务区分特征和应该忽略的任务无关特征。 然后，在目标特征和正向特征（positive features, 在此处表示那些与分类有关的特征）之间进行对齐，这与分类任务的本质是一致的，即关注判别特征（discriminative features）。

![[Pasted image 20220518155836.png]]

这里只能说 C 是定好的

#### 回顾 DANN 模型
基于域对抗学习的 UDA 通常训练域分类器 $D$ 以区分样本属于哪个域（即源或目标），并对抗性地训练特征提取器 $G$ 以欺骗鉴别器 $D$ 以学习域不变的特征表示。该s神经网络还在有标记的源样本的图像分类监督下进行训练。 特别是，$D$ 被优化以最小化域分类损失 $\mathcal{L}_D$（即二元交叉熵损失）。 同时，对 $G$ 进行优化以最大化域分类损失 $\mathcal{L}_D$ 并最小化图像分类损失 $\mathcal{L}_{cls}$（即交叉熵损失）：

![[Pasted image 20220517220528.png]]

为了实现对抗性训练，通常使用连接 $G$ 和 $D$ 的梯度反转层 (GRL) [18, 19]，通过在反向传播到 $G$ 期间将 $D$ 的梯度乘以负常数来使用。$\mathcal{L}_D$ 通常定义为 [19  , 41, 15]:

![[Pasted image 20220517220548.png]]

#### 面向任务的特征分解和对齐
在基于对抗学习的无监督与自适应中，$D$ 提取的特征作为来自源或目标样本的**整体**特征，既包含任务相关的信息，同时也包含任务不相关的信息（例如分类任务）。 直观地说，对齐与任务无关的特征并不能有效地减少任务判别特征的域差距，因此对分类任务没有明显的好处。错误地将目标特征与源任务无关的特征对齐可能会损害目标特征的辨别能力。通过实验证实，**在图 3 中**，即与任务无关的特征（TiAlign，紫色线）对齐会大大降低目标域分类器的分类精度。 因此，我们建议将每个源样本的整体特征分解为任务判别特征和任务无关特征（positive features and negative features），以实现与目标特征与任务相关的特征进行对齐。

特别是，我们选择源样本的特征向量 $\mathrm{f}^s$ 并对其进行加权以获得任务判别特征 $\mathrm{f}_p^s$，该特征对于识别 groundtruth 类具有判别性，一般称其为正特征（positive feature）。相应地，可以同时获得与任务无关的特征 $\mathrm{f}_n^s$，我们称之为负特征（negative feature）。

面向任务的特征分解。Grad-CAM [78, 55, 9] 是一种广泛使用的技术，用于定位卷积神经网络模型中最重要的分类特征。 正如 [78, 55, 9, 56] 中分析的那样，对应于 ground-truth 类的最终预测评分的梯度（分类特征）传达了任务判别信息，该信息能够识别相关特征以达到能够分类正确的目的。值得注意的是，这种任务区分信息通常与分类任务中的前景对象高度相关（但不限于）。受 Grad-CAM 的启发，将使用对应于 ground-truth 类的预测分数的梯度作为权重来获得任务判别特征。

如图 1 所示，我们从特征提取器的最后的卷积层 (具有 ReLU 层) 获得特征映射 $F\in\mathbb{R}_{+}^{H \times W \times M}$(即非负实数的张量，其中 $H$ 代表高度，$W$ 代表宽度，$M$ 代表通道的数量)。在经过一个全局平均池化层 (GAP) 之后，我们得到一个特征向量 $\mathrm{f} = pool(F) \in \mathbb{R}^M$。分类结果是通过分类器。
$C(·)$ 预测得到的（logit 层，馈入到softmax 的层）。根据响应 $C(\mathrm{f})$，我们可以得到$y^k$ 的梯度 $\mathrm{w}_{cls} \in \mathbb{R}^M$。

![[Pasted image 20220518194203.png]]

其中 $y_k$ 是对应于正确分类类型 $k$ 的预测分数。 正如 [55, 9, 56] 中分析的那样，梯度 $w_{cls}$ 传达了特征 $\mathrm{f}$ 的通道重要性信息，用于将样本分类到其真实类别 $k$。 我们从 Grad-CAM 中汲取灵感，该方法使用 $w_{cls}$ 以通道方式调整特征映射以找到分类相关的判别特征。类似地，用 $w_{cls}$ 对原始特征进行调整，我们可以获得任务判别（positive feature）特征：

![[Pasted image 20220518194215.png]]

其中 $\odot$ 是哈达玛积（Hadamard product）其中权重向量 $w_p^{cls}=sw^{cls}$ 其中 $s \in \mathbb{R}_{+}$ 是一个自适应的非负参数使得 $\varepsilon(\mathrm{f}_p)=\varepsilon(\mathrm{f})$，其中 $\varepsilon(\mathrm{f})={\left \| \mathrm{f} \right \|}_2^2$，$\varepsilon(\mathrm{f}_p)={\left \| \mathrm{f}_p \right \|}_2^2$。

$$
\begin{equation}
\begin{aligned}
s = \sqrt{\frac{{\left \| \mathrm{f} \right \|}_2^2}{{\left \| \mathrm{w}^{cls} \odot \mathrm{f} \right \|}_2^2}} 
= \sqrt{\frac{ {\textstyle \sum_{m=1}^{M}} f_m^2}{ {\textstyle \sum_{m=1}^{M}} (w^{cls}f_m)^2}} 

\end{aligned}
\end{equation}
$$
![[Pasted image 20220518194302.png]]

受 [55] 中的反事实分析的启发，与任务无关（即负数）特征可以表示为 $\mathrm{f_n} = -\mathrm{w}_p^{cls}\odot\mathrm{f}$，原因是任务判别相关的特征在 $-\mathrm{w}_p^{cls}$ 中表示为更小的值（因为是复数的原因）。

为了更好地理解和验证正负特征的区分性，我们在 [55, 78] 之后可视化空间图 F，其通道由 wcls 和 -wcls 调制。 如图 4 所示，正面信息更多与为分类任务提供判别信息的前景对象相关，而负面信息更多与非判别背景区域相关。

![[Pasted image 20220519115028.png]]

Task-oriented Domain Alignment

如上所述，我们期望域对齐明确地服务于最终的分类任务。给定基于分类元知识获得的源任务判别特征，我们可以通过不同的基于域对抗学习的对齐方法[18,19,13]引导目标特征与源任务判别特征 $\mathrm{f}_p$ 对齐。 该程序小节3.1 中讨论的 UDA 的程序几乎相同。除了输入源特征 $\mathrm{f}^s$ 到最终域鉴别器被这个源样本的正特征 $\mathrm{f}_p^s$ 代替。 因此，域分类器的损失函数可以定义为以下形式 (2):

![[Pasted image 20220518194338.png]]

其中 $G^p(x_s)=\mathrm{f}_p^s$ 表示 $x_s$ 的正特征。

# 实验及数据
### 数据集及相关工作
#### MNIST-MNISTM
**MNIST** 数据库（Modified National Institute of Standards and Technology 数据库）是一个大型的手写数字数据库，通常用于训练各种图像处理系统。该数据库还广泛用于机器学习领域的训练和测试。它是通过“重新混合”来自 NIST 原始数据集的样本创建的。创作者认为，由于 NIST 的训练数据集取自美国人口普查局员工，而测试数据集取自美国高中生，因此不太适合机器学习实验。此外，来自 NIST 的黑白图像被归一化以适合 28x28 像素边界框和抗锯齿，从而引入灰度级别。

MNIST 数据库包含 60,000 张训练图像和 10,000 张测试图像。训练集的一半和测试集的一半取自 NIST 的训练数据集，而训练集的另一半和测试集的另一半取自 NIST 的测试数据集。数据库的原始创建者保留了在其上测试的一些方法的列表。在他们的原始论文中，他们使用支持向量机来获得 0.8% 的错误率。

Extended MNIST (EMNIST) 是 NIST 开发和发布的更新数据集，作为 MNIST 的（最终）继任者。MNIST 仅包含手写数字的图像。 EMNIST 包括来自 NIST Special Database 19 的所有图像，这是一个包含手写大写和小写字母以及数字的大型数据库。通过与 MNIST 图像相同的过程，EMNIST 中的图像被转换为相同的 28x28 像素格式。因此，适用于较旧、较小的 MNIST 数据集的工具可能无需修改即可适用于 EMNIST。

**MNIST-M** 数据库是通过将 MNIST 数字与从 BSDS500 的彩色照片中随机提取的补丁作为背景相结合而创建的。 它包含 59,001 个训练图像和 90,001 个测试图像。MNIST-MNISTM 是领域自适应的经典问题。

#### Office-Home
**Office-Home** 是一个用于领域自适应的基准数据集，它包含 4 个域，每个域由 65 个类别组成。这四个领域是： 艺术（Art）—— 素描、绘画、装饰等形式的艺术形象； 剪贴画（Clipart）—— 剪贴画图像的集合；产品（Product）—— 没有背景的物体图像；真实世界图像（RealWorld） —— 用普通相机拍摄的物体图像。 它包含 15,500 张图像，平均每个类大约 70 张图像，一个类最多 99 张图像。

**Office-Home** is a benchmark dataset for domain adaptation which contains 4 domains where each domain consists of 65 categories. The four domains are: Art – artistic images in the form of sketches, paintings, ornamentation, etc.; Clipart – collection of clipart images; Product – images of objects without a background and Real-World – images of objects captured with a regular camera. It contains 15,500 images, with an average of around 70 images per class and a maximum of 99 images in a class.

#### DomainNet
**DomainNet** 是一个包含六个不同域的数据集。所有域都包括 345 个类别的对象，例如飞机、鸟、大提琴和手镯等。领域包括 clipart：剪贴画数据集；real：照片和真实世界的图像数据集；sketch：特定对象的草图；infograph：信息特征图（用来描述对象的特征的图像）；painting：绘画：quickdraw：“Quick Draw！”比赛的全球参赛者的绘图。DomainNet 也是一个经典的数据集，常常用于领域自适应和领域泛化的工作中。

### 实验环境及开发工具介绍
#### Pytorch 简介
##### Pytorch 是什么？
PyTorch 是一个年轻的框架。2017年1月28日，PyTorch 0.1 版本正式发布，这是Facebook 公司在机器学习和科学计算工具 Torch 的基础上，针对 Python 语言发布的全新的深度学习工具包。PyTorch 类似 NumPy，并且支持 GPU，有着更高级而又易用的功能，可以用来快捷地构建和训练深度神经网络。一经发布，PyTorch 便受到深度学习和开发者们广泛关注和讨论。经过一年多的发展，目前 PyTorch 已经成为机器学习和深度学习者重要的研究和开发工具之一。

2017年7月，Facebook 和微软宣布，推出开放的Open Neural Network Exchange(ONNX，开放神经网络交换) 格式，ONNX为深度学习模型提供了一种开源格式，模型可以在不同深度学习框架下进行转换。亚马逊的AWS接着加入进来，2017年10月，INTEL、NVIDIA、AMD、IBM、Qualcomm、ARM、联发科和华为等厂商纷纷加入 ONNX 阵营，ONNX 生态圈正式形成。ONNX 生态系统除了原本支持的开源软件框架 Caffe2、PyTorch 和 CNTK 也包含 MXNet 和 TesorFlow。PyTorch 是一套以研究为核心的框架，但是用PyTorch开发的算法模型可以通过 ONNX 转换，可用于其他主流深度学习框架。

PyTorch 使用 Python 作为开发语言，使得开发者能接入广大的 Python 生态圈的库和软件。同时，在 PyTorch 开发中，数据处理类型类似数据计算包 Numpy 的矩阵类型，代码风格类型机器学习包 scikit-learn，方便广大的机器学习者进入深度学习这个新的领域。

目前大多数开源框架(比如 TensorFlow、Caffe2、CNTK、Theano 等)采用静态计算图，而 PyTorch 采用动态计算图。静态计算图要求对网络模型先定义再运行，一次定义多次运行。动态计算图可以在运行过程中定义，运行的时候构建，可以多次构建多次运行。静态图的实现代码冗长，不直观。动态图的实现简洁优雅，直观明了。动态计算图的另一个显著优点是调试方便，可随时查看变量的值。由于模型可能会比较复杂，如果能直观地看到变量的值，就能够快速构建好模型。同时 PyTorch 的 API 设计简洁优雅，方便易用。PyTorch 的API 设计思想来源于 Torch，Torch 的 API 设计以灵活易用而闻名，Keras 作者就是受 Torch 的启发而开发了 Keras。PyTorch 有种使用 Keras 的快感，就是来源于此。相比而言，TensorFlow 就臃肿难用多了。

Pytorch 提供了丰富的工具包，本次实验中利用 torch.autograd 实现 GRL（梯度反转层） 层，利用 torch.nn 构建神经网络。Pytorch 也提供了大量的封装好的优化算法，例如 SGD、Adam、Adadelta 和 AdaGrad 等，本次实验中使用的优化算法为 SGD 和 Adam。Pytorch 也提供了许多经典数据集的调用接口，包括 MNIST、CIFAR100、SVHN 等经典数据集，但遗憾的是，本次实验中使用的 Office-Home 并不包括在内，需要按照 Pytorch 官方提供的接口进行封装。同时，torchvision 也提供了许多预训练好的模型，例如在 ImageNet 上训练好的 ResNet 系列神经网络、AlexNet 以及 VGG 等神经网络。本次 ToAlign 的实验中，使用 ImageNet 预训练好烦人 ResNet50 作为模型的 Basebone。

### DANN 实现
深度神经网络在上个世纪 70 年代就已经被提出来了，反向传播和梯度下降法的方法也早已存在，但是真正让深度神经网络进入人们视线还是 2012 年的提出的 AlexNet，虽然 AlexNet 的优化大多数都体现在网络结构的优化上，但是这也从侧面告诉我们，如果不做优化的话，梯度下降法的实用性只能停留在理论层面。所以在 DANN 实验中两种不同的网络结构（一个作为 baseline 没有进行网络结构的优化，一个加入了池化层和 dropout 方法）和两种不同的优化算法，两种不同的优化算法分别为 SGD 和 Adam，旨在对比不同优化算法对模型的影响和提升。

#### 优化算法
##### SGD
标准的梯度下降法是在实践中是很难实现的，因为其要求的计算量过高，现在甚至可预见的未来都可能没办法满足梯度下降法对于计算量的要求。SGD 全称 Stochastic Gradient Descent，随机梯度下降，1847 年提出，是梯度下甲肮发的一个改进，用更少的计算实现差不多的效果。每次选择一个 mini-batch，而不是全部样本，使用梯度下降来更新模型参数。它解决了随机小批量样本的问题，梯度下架发的有时在于速度快和计算快，但仍然有自适应学习率、容易卡在梯度较小点等问题。

![[Pasted image 20220520095744.png]]
（要注明出处哦）

##### Adam
在实现的过程中，分别采用了 Adam 算法和 SGD 优化算法。实现数据表明，自从 2012 年提出 AlexNet 之后，优化问题越来越受到人们的关注，尤其是其对于深度神经网络的意义，在实验中，通过对比两种方法得到最终模型的准确率，Adam 优化算法，在 MNIST-MNISTM 的领域自适应问题上表现出更大的优势，因此本章简单介绍 Adam 优化算法。

Adam 优化算法应用在非凸优化问题中所获得的优势。
1. 直截了当的实现
2. 高效的计算
3. 所需内存少
4. 梯度对焦缩放不变性
5. 适用于非稳态(non-stationary)目标
6. 适用于解决包含很高噪声活系数梯度的问题
7. 超参数可以很直观地解释，并且基本上只需极少量的调参

Adam 优化算法实际上是 RMSprop 和动量法的结合下面是，具体方法是指数加权移动平均法。

 ![[Pasted image 20220508154321.png]]

下面为 Pytorch 提供的 Adam 优化器的算法：
![[Pasted image 20220517081434.png]]

#### GRL 层的实现
GRL 层的实现利用 torch.autograd，实现起来也比较简单，实现的时候仅需要让类 ReverseLayerF 继承 torch.autograd.Function ，然后按照接口标准实现 forward 和 backword 函数，其中 backword 函数的实现即将梯度进行反转（也就是乘以 $-\lambda$）

#### 参数设计
根据不同的数据集，要设计不同的 transform 对图片进行预处理。torchvision 并没有提供所有的数据集的 Loader，因此需要封装 MNISTM 数据集的 DataLoader。

该模型的批次大小为 128（batch size）。图像通过平均减法进行预处理。 每个批次的一半由来自源域（具有已知标签）的样本填充，其余由目标域（具有未知标签）组成。 为了在训练过程的早期阶段抑制来自域分类器的噪声信号，而不是固定适应因子 $\lambda$，我们使用以下时间表逐渐将其从 0 更改为 1；初始的学习率是 1e-3。

### ToAlign 实现
在 ToAlign 实验中，我们尝试了多种网络结构做为 basebone，包括上述 DANN 中的神经网络，同时还包括在 Pytorch 提供的在 ImageNet 上已经预训练好的 ResNet（Pytorch 提供 ResNet18、ResNet34、ResNet50 和 ResNet101，但是本次实验中使用 ResNet50 作为 basebone）。其实 ToAlign 算法实现起来相对比较容易，从模型中可以看到，仅仅是将最终结果的梯度作为权值，使那些更为重要的特征被赋予更高的权重，这就是本次实验中所谓的元知识，这种思想来源于 Grad-CAM。

#### 神经网络的设计
在 ToAlign 的实验中，标签预测器的网络结构 $C$ 由一个全连接层组成，域分类器 $D$ 由三个全连接层和若干 dropout 层和 ReLU 层组成。

#### 优化算法
ToAlign 的优化算法采用 NAG。在原始形式中，Nesterov Accelerated Gradient（NAG）算法相对于 Momentum 的改进在于，以 “向前看” 看到的梯度而不是当前位置梯度去更新。经过变换之后的等效形式中，NAG 算法相对于 Momentum 多了一个本次梯度相对上次梯度的变化量，这个变化量本质上是对目标函数二阶导的近似。由于利用了二阶导的信息，NAG 算法才会比 Momentum 具有更快的收敛速度。

#### 参数设计
在设置学习率方面，我们不能简单的将学习率设置为固定的值，根据 [74]，我们将学习率设置为 $\eta_t=\frac{\eta_0}{(1+\gamma p)^{\tau}}$，其中 $p$ 是一个由 0 到 1 线性增长的参数，表示训练过程的进度，$\gamma=10$，$\tau = 0.75$。学习率的初始数值为 1e-3。

### 实验数据及表格
![[Pasted image 20220522231503.png]]

![[Pasted image 20220522231308.png]]

![[Pasted image 20220522231412.png]]
![[Pasted image 20220523120745.png]]


可以对比一下其他算法哦。

### 实验结论及分析
#### DANN
原始数据，修改神经网络结构之后的数据，不同参数的数据。

#### ToAlign
于 DANN 相比的数据。
![[Pasted image 20220531150005.png]]


# 总结
在本次基于无监督域自适应的算法研究过程中，我先后研究了多个算法，包括 DANN、DSN、TCA、JDA、metaAlign、ToAlign 等算法，复现了 DANN 及优化算法，并在此基础上进行了网络结构的改进，证明了 ToAlign 在 DANN 算法上的可行性，并且有明显的提升。同时，网络结构的优化是非常重要的，在第一个实验中，在原有的基础上，增加了池化层、dropout 层和 relu 层对网络结构进行优化，用更为先进的 Adam 优化算法代替原有的 SGD 优化算法，证明这也能提升算法的准确率。DANN 算法仍然存在一些缺陷，boundary 数据、仍然由许多探索的空间。训练的一致性，metaAlign 论文中提出了解决方案，在未来可能会将这些优化方法结合，可能会产生很好的化学反应。

# 致谢


# 引用

[1] 李晶晶,孟利超,张可,鲁珂,申恒涛.领域自适应研究综述[J].计算机工程,2021,47(06):1-13.DOI:10.19678/j.issn.1000-3428.0060659.

[2] 胡昊. 基于领域自适应的跨领域图像分类算法研究[D].重庆邮电大学,2020.DOI:10.27675/d.cnki.gcydx.2020.000358.

[3] 赵春晖,李彤,冯收.基于密集卷积和域自适应的高光谱图像分类[J].光子学报,2021,50(03):156-166.

[4] 孙琦钰,赵超强,唐漾,钱锋.基于无监督域自适应的计算机视觉任务研究进展[J].中国科学:技术科学,2022,52(01):26-54.

[5] S. J. Pan, I. W. Tsang, J. T. Kwok and Q. Yang, "Domain Adaptation via Transfer Component Analysis," in IEEE Transactions on Neural Networks, vol. 22, no. 2, pp. 199-210, Feb. 2011, doi: 10.1109/TNN.2010.2091281.

[6] M. Long, J. Wang, G  . Ding, J. Sun and P. S. Yu, "Transfer Feature Learning with Joint Distribution Adaptation," 2013 IEEE International Conference on Computer Vision, 2013, pp. 2200-2207, doi: 10.1109/ICCV.2013.274.

---

# 写作思路
图片部分
1. 论文中图片
2. 自己做的图片 draw.io
3. tensorboardX
4. matplotlib ---> 可以形成自己的图片

表格
1. latex 在线      

引用部分
1. endnote

先把代码改好吧，然后看一下能不能跑起来。

其他可以写的东西
1. GVB 可以写一下凑字数
2. 实验工具内容什么的

还可以水的内容
1. 国内外研究现状
2. GAN 论文的部分
3. 关于 Grad-CAM 的内容

1. 删除空行
2. 标点符号 全角，半角。
3. 摘要

1. 基于距离度量的，

基于距离度量，深度学习之后

第二章：增加几句话

1. 英文字体问题，那我还是写成中文，尽量转成中文。

# 致谢
1. 非常幸运感谢老师
2. 走上科研道路，学习技能
3. 升华一下，为国家，为社会贡献自己的力量

我选择了周老师的课题，作设计的过程中，我有许多不懂得地方，在老师的指导下我一步步的解决问题完成论文，在完成过程中老师指导我去怎么选择资料，如何去利用网络资源，在这个学习的过程中，我了解到MATLAB的实用价值，更深的理解数字调制技术的调制原理。对键控方式的调制原理也理解的更加透彻。这都是老师的功劳。老师一次次为我解答思路及仿真上方方面面的问题。对论文的要求及答辩时间的改动老师都及时地联系我，通知我。在作毕业设计中，没有老师的帮助我是不可能完成的。感谢老师对我的关心和帮助。经过我的努力和周老师的耐心指导毕业设计顺利按时完成，它是对我们把本科四年所学的理论知识运用到实践中的一次系统的检验。

通过这段时间的亲身经历，我感觉自己学到了：收集、整理资料、共同协作、分析及处理问题等许多方面的知识。我真诚感谢这期间老师给予我的全力帮助，细心指导以及对我的严格要求，是她在我遇到问题时，不辞辛苦帮我解决,感谢她在设计和任务安排上长时间的指导。在设计的过程中，我还从老师身上学到好多东西：周老师热心工作的精神感动了我们，她还用实际行动告诉我们在工作中要脚踏实地，在学术上要严谨，在思维上要活跃，在学业上要勤奋刻苦。还有，在设计过程中感谢给我提供便利的条件，使得我们能够顺利的完成毕业设计。最后感谢各位评委给予批评指正。

首先要感谢我的指导老师杨立然老师，督促并指导我完成了本次毕业设计，在这次毕业设计中我学习到了很多，学习了深度学习相关知识和技术。但最重要的是在本次毕业设计过程中摸索出一条模糊的做科研的道路，这对我这个即将成为一名研究生的人是非常有意义的。

接下来我将会开启我的人生的新阶段，我有时在想古人说的 “为天地立心，为生民立命，为往圣继绝学，为万世开太平” 我到底能做到哪一点，想了又想，似乎只有“为往圣继绝学” 离我近一点。我是一个有技能而无才华的人，我不妄想能够在学术上有多么大的成就，但能多学一点就多学一点，能多做一点就多做一点。

我真的是一个非常幸运的人，出生在一个幸福的家庭，生活在一个和平的国家。而且有幸考上华北电力大学，在这里度过了四年的学习生活。在接下来的人生中，我也将继续努力，为国家做出自己的贡献。

# PPT 怎么做
注意几个关键点

1. 封面学校、学院等基本信息
	1. 题目
	2. 答辩人
	3. 专业
	4. 导师
	5. 日期
2. 四步走目录
	1. 研究背景和现状
	2. 研究内容及方法
	3. 现象分析及应用
	4. 工作总结和展望
3. 研究背景：多图少字逻辑分明
4. 介绍别人工作一定要本页引用
5. PPT 要有页码，方便老师提问
6. 微软雅黑字体
7. 谢谢大家！希望各位老师批评指正！
	1. 答辩人
	2. 指导老师
	3. 日期
8. 了解导师大概率会提的问题


![[Pasted image 20220601181443.png]]
![[Pasted image 20220601181509.png]]

![[Pasted image 20220601181526.png]]
![[Pasted image 20220601181536.png]]

![[Pasted image 20220601181546.png]]
![[Pasted image 20220601181559.png]]
![[Pasted image 20220601181613.png]]

# 问题记录
同学2：
刘老师
1. 论文序号问题
2. 图的问题 3-2 不是流程图
	1. 流程图的图素

李老师
1. 有没有做过需求分析
	1. 课堂派批改作业不舒服
	2. 作业批和改的过程，批改意见
2. 统计课程中有多少同学交作业？
	1. 催交功能？

同学3
刘老师
李老师
1. 论文模板问题
	1. 字体、图片
	2. 目录不对
2. 隐私和安全性，冒领，怎么判断是主人，机制？
3. ？

杨老师

最后一个同学
刘老师
1. 应用一下，实践中解决问题
2. 论文中小问题
3. 为什么选择 Python 语言？特点是什么
4. 论文字数加加加！！！33+

李老师

杨老师
# GVB 部分
![[Pasted image 20220605142402.png]]

Gradually Vanishing Bridge for Adversarial Domain Adaptation
提出了一个新的框架，即在生成器和鉴别器上构建GVB，以实现更均衡的领域适应对抗训练。生成器上的GVB作为框架中的关键角色，可以有效地减少表示中的领域特征，减轻迁移困难。GVB在大多数情况下优于竞争对手，可视化也显示了GVB的积极作用

### **1、Adversarial Domain Adaptation**

普遍认为，域自适应可以通过最小化分类损失和附加传输损失来实现。

源域中的分类损失公式如下：

![](https://pic2.zhimg.com/80/v2-fa9d40217625121ea27415df6e2e0685_1440w.jpg)

  

Lce表示cross-entropy损失函数。G* 是获得类别信息的网络结构。

transfer loss = 在分类器输出上最小化领域差异（domain discrepancy）的loss + adversarial loss

![](https://pic1.zhimg.com/80/v2-cf61c6d8b4959de6723eb3c0eaf83c80_1440w.jpg)

  

D是整个discriminator。

一些方法中还利用了extra loss，本文也借鉴了。

所以，整体目标函数为：

![](https://pic2.zhimg.com/80/v2-c7de97eef271f953ddf70f1937b88c35_1440w.jpg)

以上是adversarial domain adaptation的一般框架。

本文假设分类网络是由一个特征提取器G1和一个连续的分类器层G2构成。于是，在只有Discriminator D1的情况下，这个baseline方法可表示成如下：

![](https://pic3.zhimg.com/80/v2-c5c6e810cfc84290e6f81204d17743c2_1440w.jpg)

### **2、Gradually Vanishing Bridge on Generator**

事实上，源域和目标域的divergence很难减小到0，因此，寻找从源域到目标域的直接知识迁移具有很大的挑战性。**但是可以减低迁移的难度**，于是，本文把迁移过程分成两个分开的过程。之前是**Ds**->**Dt**,现在是**Ds**->**Di**和**Dt**->**Di**。其中，**Di**应该在**Ds**和**Dt**中间，且与**Ds**和**Dt**相比，**Di**具有更少的领域特有特性。为了给领域特有表示建模，构造了一个**bridge layer** **G3**，将**G3**的输出定义为**γi**，它从源域或者目标域的输入上获得了领域特有表示。用分类器输出**ci**减去**γi**就得到了领域不变表示，记为**ri**。

引入**γi**之后，生成器表达式就变成了如下形式：

![](https://pic3.zhimg.com/80/v2-319b2bf0e0fdadacfb348aed2f48bdda_1440w.png)

对抗性训练过程要求各领域的**ri**分布尽可能相似。因此，根据等式5，**γi**倾向于由领域特有表示控制。

在现有的研究中，已经提出了一些基于生成器的桥接方法，但是现有研究中的**bridge**构建方法仍有待讨论。在一些文献中，**bridge**是通过图像重建而成的。然而，由于图像重建功能的存在，不可避免地会导致**bridge**的残差特征过多，整体范围大。关于我们的框架，如果用向量范数测量的**γi**的范围过大，它有以下解释。首先，它意味着数据**xi**是一个hard example，包含大量的领域特有属性。第二，对于**xi**的领域特有部分和领域不变部分几乎不能分离。因此，大范围的bridge意味着**γi**中丰富的领域特征，并不可避免地影响**ci**和**ri**。对表示的影响导致目标域**DT**中较高的误分类概率，这在图5中的实验结果中得到了验证。（存在的问题）

为了更有效的限制**bridge**，本文寻找能够减少**γi**中领域特性的影响的方法。因此提出以下公式来逐步减小**γi**的影响：

![](https://pic3.zhimg.com/80/v2-70d6a0465a370d9dab45d36ddfc0a57e_1440w.jpg)

**γi**被期望接近0。通过减小**γi**的范围，**γi**中的特性被压缩，从而减小了对**ci**和**ri**的影响。这种最小化**γi**范围的机制定义为**GVB.**使用了GVB的生成器叫做GVB-G。

### **3、Gradually Vanishing Bridge on Discriminator**

在对抗领域适应中，很少有人关注discriminator.除此之外，不想generator那样能够在大规模数据集上与训练，discriminator通常是随机初始化的，并且discriminator易于陷于局部最小值。为了让discriminator更有效，本文提出在discriminator上构建**bridge layer** D2。D2建模了基本**discriminator** D1函数超平面与理想判决边界的距离，给D1提供了额外的鉴别力。

于是，discriminator就变成了

![](https://pic3.zhimg.com/80/v2-c7e66d2146e27d7155953b998a1e9706_1440w.png)

与之前方法类似，减少在discriminator上bridge的overall range：

![](https://pic3.zhimg.com/80/v2-8d5f084014d1c42903a37a844b6f2d42_1440w.jpg)

  

GVB应用在discriminator上后，称为GVB-D。

综上，整个框架如下：

![](https://pic4.zhimg.com/80/v2-681ae8f51fb6bd45666f428ecd204527_1440w.jpg)

1. 解释中间域的概念
2. 解释桥的概念

为了减少领域差异，最大的挑战在于丰富的领域特定特征，这些特征被认为可以通过分布对齐 [8, 23] 或对抗性训练 [9, 35] 来缓解。 为了更全面地减少特定领域的特征，一些方法 [2, 3, 11] 通过输入图像重建显式地对特定领域和领域不变的表示进行建模。 耗时的重建功能需要在特定领域的表示中具有丰富的领域特征。 这样的特性不可避免地导致中间域中的域属性更多，这应该是域不变的。 从对抗学习的另一个角度来看，对抗 minmax 游戏可以通过平衡生成器和判别器之间的学习能力来取得更好的结果。 在某些情况下，通过多个鉴别器 [30] 加强鉴别能力可能有助于与强大的生成器更好地协作，而过于关键的多个鉴别器也可能会打破对抗训练的关键平衡。 在本文中，我们将桥定义为一个基本概念，它是对现有表示与理想表示之间的差异进行建模的度量。 如图 1 中的示例所示，桥应用于生成器和鉴别器。 生成器上的桥对特定领域的部分进行建模，并将源域和目标域连接到中间域，因此它可以减轻整体传输难度并促进更全面的域对齐。 判别器上的桥测量判别函数超平面与理想域决策边界之间的差异。 我们建造的桥梁的关键限制是桥梁的范围逐渐减小。 有了约束，桥机制被称为逐渐消失的桥（GVB），用于对抗域适应。 我们将应用于生成器和判别器的 GVB 分别表示为 GVB-G 和 GVB-D。 在这些桥中，生成器上的桥对特定领域的部分进行建模，因此 GVB-G 可以显式减少特定领域的特征。 因此，GVB-G 在学习域不变表示中起着主要作用。 它还可以减少领域特征对表示的不利影响，避免具有过多领域特征的难例的影响。  GVB-G 和 GVB-D 都集成到整个框架中，记为 GVB-GD，以确保两人最小最大游戏的平衡性和鲁棒性。 实验表明，GVB-GD 在三个具有挑战性的数据集上优于竞争对手，并在 OfficeHome 上达到了最先进的水平。 我们还将 GVB 应用于其他 UDA 方法，包括 CDAN [24] 和 Symnets [48]。  CDAN 和 Symnets 的改进表明 GVB 在对抗域适应方面的普遍适用性。 为了更好地解释，我们将 GVB-GD 中的桥可视化，以验证桥可以测量特定领域的特征。 我们进一步验证了 GVB 的功能性和必要性，通过观察更大范围的 GVB-G 输出往往会导致更高的错误分类概率。


[摘要................................................................................................................................ I](#_Toc105348886)

[Abstract.......................................................................................................................... II](#_Toc105348887)

[目录................................................................................................................................ 1](#_Toc105348888)

[1绪论............................................................................................................................. 1](#_Toc105348889)

[1.1课题背景.................................................................................................................. 1](#_Toc105348890)

[1.2 迁移学习................................................................................................................. 1](#_Toc105348891)

[1.2.1 领域自适应.......................................................................................................... 2](#_Toc105348892)

[1.2.2 相关定义.............................................................................................................. 2](#_Toc105348893)

[1.2.3 领域自适应的分类.............................................................................................. 3](#_Toc105348894)

[1.2.4 领域自适应相关问题.......................................................................................... 4](#_Toc105348895)

[1.3 无监督域自适应..................................................................................................... 4](#_Toc105348896)

[1.4 小结......................................................................................................................... 8](#_Toc105348897)

[2 ToAlign 算法原理..................................................................................................... 9](#_Toc105348898)

[2.1 DANN 模型............................................................................................................ 9](#_Toc105348899)

[2.2 ToAlign 优化算法................................................................................................ 12](#_Toc105348900)

[2.3 小结....................................................................................................................... 16](#_Toc105348901)

[3 ToAlign 优化实验................................................................................................... 17](#_Toc105348902)

[3.1 数据集................................................................................................................... 17](#_Toc105348903)

[3.2 实验环境及相关工具........................................................................................... 19](#_Toc105348904)

[3.3 DANN 实现.......................................................................................................... 19](#_Toc105348905)

[3.3.1 优化算法............................................................................................................ 20](#_Toc105348906)

[3.3.2 GRL 层的实现................................................................................................... 21](#_Toc105348907)

[3.3.3 图像预处理与参数设计.................................................................................... 21](#_Toc105348908)

[3.4 ToAlign 实现........................................................................................................ 21](#_Toc105348909)

[3.4.1 ResNet................................................................................................................. 22](#_Toc105348910)

[3.4.2 神经网络的设计................................................................................................ 23](#_Toc105348911)

[3.4.3 优化算法............................................................................................................ 23](#_Toc105348912)

[3.4.4 参数设计............................................................................................................ 24](#_Toc105348913)

[3.5 实验数据及分析................................................................................................... 24](#_Toc105348914)

[3.6 小结....................................................................................................................... 25](#_Toc105348915)

[结论.............................................................................................................................. 26](#_Toc105348916)

[参考文献...................................................................................................................... 27](#_Toc105348917)

[附录A DANN相关代码............................................................................................ 29](#_Toc105348918)

[附录B ToAlign相关代码.......................................................................................... 31](#_Toc105348919)

[致谢.............................................................................................................................. 33](#_Toc105348920)