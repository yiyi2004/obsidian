- 理论基础
	- 故障机制
		- 故障检测
		- 故障处理
		- 故障恢复
	- 具体措施
		- 熔断
		- 限流
		- 降级
- 在 gRPC 中接入服务治理
- 不同框架接入服务治理
	- Kratos
	- go-zero
- gRPC 超时控制

## 理论基础

![[Snipaste/Pasted image 20240311194439.png]]

1. 服务治理
	1. 熔断、限流和降级
	2. 超时控制
	3. 隔离
	4. 分组和路由
	5. 优雅退出
2. 亮点：一整套的从前端到后端的服务治理方案

![[Snipaste/Pasted image 20240311194752.png]]

1. 故障检测
2. 故障处理
3. 故障恢复

![[Snipaste/Pasted image 20240311194858.png]]

1. 故障检测
	1. 静态检测：压测 + 研发人员历史经验，设定阈值
	2. 动态检测：硬件信息 + 服务本身信息 (响应时间、错误率) 等来判断

![[Snipaste/Pasted image 20240311200958.png]]

1. 故障处理的方式玩的花样很多
	1. 同步转异步：把请求记录下来，后续再处理
	2. 执行特殊代码：对于熔断、限流来说，就是返回 error；对于降级来说，可能是返回默认值，或者执行一个快路径
	3. 请求转发：转发到其他节点，这个过程如果通过客户端来配合，实现更加简单

![[Snipaste/Pasted image 20240311201302.png]]

1. 故障恢复的要点在于
	1. 如何确定我的服务已经恢复正常了？
		1. 固定时间等待
		2. 实时计算：故障检测算法，实时计算服务端节点的状态。
		3. 试探发
	2. 避免抖动：退出故障处理流程的时候，不要立刻引起系统再次触发故障。
		1. 基本思路：结合试探发逐步放开流量，也可以叫做灰度
2. 故障恢复如果处理不好，很容易导致出现系统一会好，一会崩溃的情况。

故障恢复通用策略

试探 + 逐步放开流量的方式

![[Snipaste/Pasted image 20240311201905.png]]

1. 故障恢复之后，试探一个请求
2. 正常处理，不能处理
3. 逐步加大流量，正常处理，出现错误
4. 不断加大流量，直到 100%

### 微服务流量放大与雪崩

![[Snipaste/Pasted image 20240311202111.png]]

1. 一个请求再微服务处理的过程中，会产生非常多的服务调用
2. 流量增加 1 倍，系统负载增加不止 1 倍
3. 通过限流、熔断等措施防止服务雪崩，或说风险扩大

## 具体措施

### 熔断

![[Snipaste/Pasted image 20240311203216.png]]

1. 保护机制，防止微服务架构中的级联故障

![[Snipaste/Pasted image 20240311203421.png]]

1. 如何判断服务是否需要熔断？**故障检测**：静态检测、动态检测
2. 熔断之后怎么办？大多数时候都是**返回特定错误码**
3. 怎么从熔断之中恢复出来？**试探请求 + 逐步放开流量**

熔断的状态

1. 开放状态
2. 关闭状态
3. 半开放状态：恢复过程中的状态

### 降级

![[Snipaste/Pasted image 20240311204016.png]]

熔断直接拒绝全部请求，**降级就是尽可能返回一个响应**：提前配置好的默认选项 | 特定的快路径。

大多数业务：快慢路径、资源消耗、计算

正常是先执行快路径，再执行满路径，降级之后，可以只执行快路径。

#### 典型案例：缓存剪辑方案

![[Snipaste/Pasted image 20240311204218.png]]

#### 降级：跨服务降级

![[Snipaste/Pasted image 20240311204348.png]]

1. 停掉增删改操作，所有资源全力支持查询操作。
2. 更高级
	1. 集群层面、停掉边缘业务，腾出服务器资源给核心服务
	2. 读服务写服务分组部署、可以关掉写服务、调用资源支持写服务
	3. 同一节点上部署的不同服务，不重要到重要，一次停掉服务，直到腾出足够资源

### 限流

![[Snipaste/Pasted image 20240311204640.png]]

1. 大多数时候静态限流、阈值
2. 拒绝请求，返回特定错误码

![[Snipaste/Pasted image 20240311204727.png]]

1. 被限流的请求怎么办
	1. 同步转异步
	2. 执行特殊带啊吗
	3. 转发请求：通知客户端 换个节点试试
2. 界线不是很分明

#### 限流对象：针对什么限流

![[Snipaste/Pasted image 20240311205044.png]]

1. 针对单机限流 | 针对集群限流
2. 针对整个应用限流，针对应用的某个服务限流，比如用户服务，针对用户服务中的某个接口限流，某个内部接口，比如更新信息。
3. 针对业务对象限流：
	1. 针对用户用户对象限流：VIP
	2. 针对 IP 限流：WEB 登录阶段采用过

#### 限流算法

1. 计数器
2. 固定窗口
3. 滑动窗口
4. 令牌桶
5. 漏桶

实际随便选一个就好了

##### 计数器算法

![[Snipaste/Pasted image 20240311210114.png]]

1. 收到请求的时候，计数器 + 1；返回下昂应的时候，计数器 -1
2. 效果很好、实现简单、固定请求数量

##### 固定窗口

![[Snipaste/Pasted image 20240311210221.png]]

1. **将时间切成一个个窗口**，确保每个窗口内的请求数量没有超过阈值

##### 滑动窗口

![[Snipaste/Pasted image 20240311210322.png]]

1. 固定窗口，在这个窗口内，只能处理固定数量的请求
2. 窗口在不断的滑动

![[Snipaste/Pasted image 20240311210626.png]]

- 固定窗口没有滑动窗口常用，**固定窗口流量不如滑动窗口均匀**。

##### 令牌桶

![[Snipaste/Pasted image 20240311210817.png]]

- **按一定速率发令牌**

##### 漏桶

![[Snipaste/Pasted image 20240311211024.png]]

1. 10 ms 一个人

![[Snipaste/Pasted image 20240311211109.png]]

1. 令牌桶：令牌积压，突发流量，更多请求拿到令牌
2. 没有积压、绝对均匀，不管什么时候哦，**放过去的请求速率都是均匀的**

### 总结

![[Snipaste/Pasted image 20240311211329.png]]

1. 希望即便出现各种故障，**尽可能高可用** ---> **降级**
2. 希望**尽快从故障中恢复过来** ---> **熔断**
3. 希望至少**一部分请求能够被正确处理** ---> **限流**

个人：限流 > 降级 > 熔断

**熔断本身的破坏性也很强**

![[Snipaste/Pasted image 20240311211538.png]]

1. 动态判定：实际业务、服务信息 ---> 判定服务状态
	1. 硬件指标
	2. 服务指标：响应时间、超时比例、错误码
2. 熔断、限流、降级
3. 恢复过程、动态判定加大流量还是降低流量

### 面试要点

![[Snipaste/Pasted image 20240311211955.png]]

- 第二个问题 #不懂
- 根据业务特征、设计过独有的限流算法，赢得竞争优势
