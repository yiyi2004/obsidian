每个 OS 的线程都有⼀个固定⼤⼩的栈内存，通常是 2MB，栈内存⽤于保存在其他函数调⽤期间哪些正在执⾏或者  
临时暂停的函数的局部变量。这个固定的栈⼤⼩，如果对于 goroutine 来说，可能是⼀种巨⼤的浪费。作为对⽐  
goroutine 在⽣命周期开始只有⼀个很⼩的栈，典型情况是 2KB, 在 go 程序中，⼀次创建⼗万左右的 goroutine 也不  
罕⻅（2KB*100,000=200MB）。⽽且 goroutine 的栈不是固定⼤⼩，它可以按需增⼤和缩⼩，最⼤限制可以到  
1GB。

goroutine 没有特殊的标识

在⼤部分⽀持多线程的操作系统和编程语⾔中，线程有⼀个独特的标识，通常是⼀个整数或者指针，这个特性可以  
让我们构建⼀个线程的局部存储，本质是⼀个全局的 map，以线程的标识作为键，这样每个线程可以独⽴使⽤这个  
map 存储和获取值，不受其他线程⼲扰。  
goroutine 中没有可供程序员访问的标识，原因是⼀种纯函数的理念，不希望滥⽤线程局部存储导致⼀个不健康的  
超距作⽤，即函数的⾏为不仅取决于它的参数，还取决于运⾏它的线程标识。

---

atmoc.Value

sync.Map 方法学习和使用。

---

```go
go test -race mypkg // 测试包
go run -race mysrc.go // 编译和运⾏程序
go build -race mycmd // 构建程序
go install -race mypkg // 安装程序
```

---

switch case 检查变量类型

---

使⽤ new 函数来分配空间  
传递给 new 函数的是⼀个类型，⽽不是⼀个值  
返回值是指向这个新⾮配的地址的指针

new 是分配一个空间，然后返回这个空间的地址

---

要复制⼀个 Slice，最好使⽤ Copy 函数。

---

Golang 中 map 的底层实现是⼀个散列表，因此实现 map 的过程实际上就是实现散表的过程。在这个散列表中，主要出现的结构体有两个，⼀个叫 hmap(a header for a go map)，⼀个叫 bmap(a bucket for a Go map，通常叫其 bucket)。

装载因⼦：count/2^B

触发条件：

1. 装填因⼦是否⼤于 6.5
2. overflow bucket 是否太多

解决⽅法：

1. 双倍扩容：扩容采取了⼀种称为“渐进式”地⽅式，原有的 key 并不会⼀次性搬迁完毕，每次最多只会搬迁 2 个 bucket
2. 等量扩容：重新排列，极端情况下，重新排列也解决不了，map 成了链表，性能⼤⼤降低，此时哈希种⼦

hash0 的设置，可以降低此类极端场景的发⽣。

[[../../../Coding/Go/深入理解go/Go Map 原理|Go Map 原理]]

Go 语⾔中 map 采⽤的是哈希查找表，由⼀个 key 通过哈希函数得到哈希值，64 位系统中就⽣成⼀个 64bit 的哈希  
值，由这个哈希值将 key 对应到不同的桶  

bucket）中，当有多个哈希映射到相同的的桶中时，使⽤链表解决哈希冲突。key 经过 hash 后共 64 位，根  
据 hmap 中 B 的值，计算它到底要落在哪个桶时，桶的数量为 2^B，如 B=5，那么⽤ 64 位最后 5 位表示第⼏号  
桶，在⽤ hash 值的⾼ 8 位确定在 bucket 中的存储位置，当前 bmap 中的 bucket 未找到，则查询对应的  
overflow bucket，对应位置有数据则对⽐完整的哈希值，确定是否是要查找的数据。  

如果两个不同的 key 落在的同⼀个桶上，hash 冲突使⽤链表法接近，遍历 bucket 中的 key 如果当前处于 map 进  
⾏了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。

---

![[Snipaste/Pasted image 20240413153945.png]]

- golang 的底层的解释

---

```go
type W struct {
 b int32
 c int64
}

func main() {
 var w *W = new(W)
 //这时w的变量打印出来都是默认值0，0
 fmt.Println(w.b,w.c)

 //现在我们通过指针运算给b变量赋值为10
 b := unsafe.Pointer(uintptr(unsafe.Pointer(w)) + unsafe.Offsetof(w.b))
 *((*int)(b)) = 10
 //此时结果就变成了10，0
 fmt.Println(w.b,w.c)
}
```

---

```go
package main

import (
    "fmt"
    "reflect"
)

type J struct {
    a string //小写无tag
    b string `json:"B"` //小写+tag
    C string //大写无tag
    D string `json:"DD" otherTag:"good"` //大写+tag
}

func printTag(stru interface{}) {
    t := reflect.TypeOf(stru).Elem()
    for i := 0; i < t.NumField(); i++ {
        fmt.Printf("结构体内第%v个字段 %v 对应的json tag是 %v , 还有otherTag？ = %v \n", i+1, t.Field(i).Name, t.Field(i).Tag.Get("json"), t.Field(i).Tag.Get("otherTag"))
 }
}

func main() {
    j := J{
      a: "1",
      b: "2",
      C: "3",
      D: "4",
    }
    printTag(&j)
}
```

```go
func typeFields(t reflect.Type) []field {
    // 注释掉其他逻辑...
    // 遍历结构体内的每个字段
    for i := 0; i < f.typ.NumField(); i++ {
        sf := f.typ.Field(i)
        // **不能导出的原因**
        isUnexported := sf.PkgPath != ""
        // 注释掉其他逻辑...
        if isUnexported {
            // 如果是不可导出的变量则跳过
            continue
        }
        // 如果是可导出的变量（public），则获取其json字段
        tag := sf.Tag.Get("json")
        // 注释掉其他逻辑...
    } 
    // 注释掉其他逻辑... 
}
```

---

golang 内存逃逸

`golang程序变量` 会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在 `栈上` 分配。否则就说它 `逃逸` 了，必须在 `堆上分配`。

> 上面是核心观点

引起内存逃逸的典型场景：

能引起变量逃逸到堆上的**典型情况**：

- **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
- **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
- **在一个切片上存储指针或带指针的值。** 一个典型的例子就是 `[]*string`。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
- **slice 的背后数组被重新分配了，因为 append 时可能会超出其容量 ( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片 b 的背后存储都逃逸掉，所以会在堆上分配。

[高频golang面试题：简单聊聊内存逃逸？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==&mid=2247492751&idx=1&sn=47d9e690947963b70e13b65a9fa13324&source=41#wechat_redirect)

---

在 GMP（Goroutine-Monitor-Processor）模型中，handoff 机制是 Go 语言运行时（runtime）为优化协程（goroutine）调度而设计的一种策略。GMP 模型是 Go 语言实现并发编程的核心机制，其中：

- **G**（Goroutine）代表用户态的轻量级线程，即协程。
- **M**（Machine）代表内核线程，是执行 G 的实体，与操作系统线程一一对应。
- **P**（Processor）代表逻辑处理器，它管理着一个本地 G 队列和一些资源（如内存分配状态），并负责将 G 绑定到 M 上执行。

**Handoff 机制**主要涉及以下情景：

1. **阻塞操作**：当一个 M 在执行 G 时遇到阻塞操作（如网络 I/O、系统调用等），M 会主动释放 P，将其与自身分离。这是因为阻塞操作会导致 M 无法继续执行任何 G，如果 M 在此期间仍持有 P，那么 P 关联的 G 队列中的其他 G 也无法得到执行，造成资源闲置。
    
2. **空闲 M 的利用**：释放 P 的 M 会进入休眠状态，而被释放的 P 会被调度器重新分配给其他空闲或新建的 M。这样，原本休眠或等待中的 M 就可以获取 P，并从 P 的本地 G 队列或全局 G 队列中取出一个 G 进行执行，实现了 G 的执行权在 M 之间的转移，这就是 handoff 过程。

简而言之，handoff 机制确保了当一个 M 由于执行的 G 阻塞而无法继续工作时，与其关联的 P 能够迅速地找到另一个可用的 M 继续执行其他待处理的 G，从而避免了因单个 M 阻塞而导致的整个 P 所关联的 G 队列的执行停滞，提高了系统的并发性和资源利用率。

此外，handoff 机制与 work stealing 机制相辅相成，共同构成了 Go 语言调度器高效调度的基础。Work stealing 是指当一个 M 发现自己本地 P 的 G 队列为空时，会尝试从其他 M 的 P 的 G 队列中“偷取”G 来执行，进一步保证了系统中所有可用的 M 都能得到充分的利用，减少线程空转。这两种机制结合在一起，使得 Go 语言的并发模型能够在多核处理器环境下高效地利用系统资源，实现高并发、低延迟的程序执行。

---

在 GMP 模型中，当一个 M（Machine，内核线程）在执行 G（Goroutine，协程）时遇到阻塞操作，如网络 I/O、系统调用等，导致 M 无法继续执行任何 G。此时，M 之所以不能直接去执行其他 G，主要是出于以下原因：

1. **操作系统限制**：
   - M 本质上是操作系统级别的线程，每个线程在执行过程中有自己的上下文（如寄存器状态、栈信息等）。一旦线程因阻塞操作进入等待状态，它无法自行切换到其他 G 的上下文来执行其他 G，因为这是由操作系统内核负责管理和调度的。

2. **调度粒度与并发控制**：
   - GMP 模型设计时有意将 G 和 M 分离，G 代表用户态的轻量级线程，而 M 则是执行 G 的实体。这样设计的好处是可以实现细粒度的并发控制，一个 M 可以快速地在多个 G 之间切换，而无需频繁创建和销毁内核线程，降低了上下文切换的开销。
   - 当 M 遇到阻塞操作时，若 M 本身试图切换到其他 G 执行，将打破这种细粒度的调度控制，可能会导致资源争抢、上下文切换频繁等问题，影响系统整体性能。

3. **资源管理与公平性**：
   - P（Processor，逻辑处理器）在 GMP 模型中负责管理一个本地 G 队列和一些资源（如内存分配状态），并负责将 G 绑定到 M 上执行。当 M 因 G 阻塞而释放 P 时，P 可以被重新分配给其他空闲或新建的 M，确保了资源的公平分配和充分利用。
   - 如果 M 在阻塞时直接执行其他 G，而不释放 P，可能会导致资源集中在该 M 上，其他 M 无法获取 P 执行 G，从而影响系统的并发能力和资源利用率。

综上所述，当 G 阻塞时，M 没有能力直接拿到其他 G 执行，而是需要通过 GMP 模型中的 handoff 机制，将与阻塞 G 关联的 P 释放，让调度器重新分配给其他空闲或新建的 M。这样既遵循了操作系统的线程调度规则，又维持了 GMP 模型的细粒度调度、资源管理和公平性，确保了整个系统的高效并发执行。
