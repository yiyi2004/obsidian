1. 笔试
2. 自我介绍
3. 项目介绍
	1. 介绍项目的具体详情，为什么要写这个项目，具体是怎么实现的
	2. 挑一个项目详细介绍一下 背景、遇到了什么问题、你是怎么解决的
	3. 说一下你觉得你项目中的难点，或者最有价值的东西
	4. 主要工作，遇到的困难
	5. 一些细节问题，改进方案
	6. 代理服务的默认端口？（第一次听说代理还有默认端口）
	7. 页面解析用的什么？
	8. 爬虫比较困难的场景？
	9. 纯 js 渲染的页面怎么爬？
	10. **说一下项目里面的 Channel+Select 调度**
	11. **项目里的 Redis 限流**
4. 反问
	1. 您觉得我还有什么不足，我现阶段学习的方向，面对生产环境怎么办之类的
	2. 反问: 部门业务和技术栈
	3. **和胜任字节实习生,能力 gap 多少, 需要从哪里改进**
	4. **被发现套话了,他说第二个问题其实是想知道面试结果吧,我就回答第一个好了**…
	5. 字节对实习生的期待
	6. 对我的建议

## 深维智讯 2.27（OC 已拒）

笔试 1h：逻辑题、语言特性、三大件、算法题  
面试 1h：  
自我介绍  
项目选一个介绍  
项目提问

**MySQL 事务隔离级别**  

- 未提交读
- 已提交读 RC
- 不可重复读 RR
- 串行化

**覆盖索引**

- 覆盖索引指的是命中的索引是联合索引，不需要回表进行查询。这样可以减少一次回表，性能更高。

**SQL 执行慢，如何排查**

- 可以通过通过开启慢查询日志查询
- 可以通过 explain 看 SQL 的执行计划、是否命中索引、是否全表烧苗、各个操作的成本估算。

当遇到 SQL 查询执行缓慢的问题时，可以采取以下步骤进行排查和优化：

1. **检查查询计划**：
   - 使用 `EXPLAIN` 或者 `EXPLAIN ANALYZE` 命令查看 SQL 查询的执行计划。这可以帮助你理解数据库如何执行你的查询，包括它是如何使用索引的，是否有全表扫描，以及各个操作的成本估算。
2. **优化查询语句**：
   - **简化查询**：尝试简化查询逻辑，避免复杂的子查询，可以考虑将复杂查询拆分成多个简单查询。
   - **减少数据量**：尽量减少查询返回的数据量，比如通过具体的条件过滤不必要的记录，使用 LIMIT 限制返回的行数。
   - **使用索引**：确保你的查询能够有效地利用索引。没有被索引的列在进行搜索时会导致全表扫描，极大地影响性能。
3. **数据库索引优化**：
   - **添加或调整索引**：根据查询计划中的信息，确定是否需要为某些列添加索引。同时，注意不要过度索引，因为这会增加写操作的成本。
   - **索引维护**：定期维护索引，比如重建或重新组织索引，以确保查询效率。
4. **服务器和硬件资源检查**：
   - **资源瓶颈**：检查数据库服务器的 CPU、内存、磁盘 I/O 是否有瓶颈。高负载或资源饱和可能会导致查询执行缓慢。
   - **配置优化**：调整数据库服务器的配置设置，如内存分配、缓存大小等，以适应实际的工作负载。
5. **查询分析器和监控工具**：
   - 使用数据库提供的查询分析器和监控工具来收集和分析性能数据。这些工具可以帮助你发现慢查询，分析数据库的性能瓶颈。
6. **数据库表结构优化**：
   - **归档旧数据**：定期清理或归档旧数据，减少表的大小，可以提升查询性能。
   - **表分区**：对于非常大的表，考虑使用分区技术，将数据分布到多个物理分区中，以提高查询效率。
7. **避免锁争用**：
   - 确保查询不会因为与其他事务的锁争用而被阻塞。分析和优化事务的设计，减少长事务，合理使用事务隔离级别。

**B+ 树和跳表的查询的时间复杂度**

O(logn)

**Redis 持久化** #不懂

1024&1023

**三次握手四次挥手**

在面试中解释 TCP 的三次握手和四次挥手时，你可以按照以下结构进行回答：

TCP 三次握手（连接建立）

三次握手（Three-way Handshake）的目的是可靠地建立两个 TCP 主机之间的连接。它包括以下步骤：

1. **SYN**：客户端发送一个 SYN（同步序列编号）报文到服务器，并进入 SYN_SEND 状态，等待服务器确认。
2. **SYN-ACK**：服务器接收到客户端的 SYN 报文，回送一个 SYN-ACK（同步确认应答）报文，确认收到了客户端的 SYN。同时，服务器将自己的 SYN 报文发送给客户端。服务器进入 SYN_RECV 状态。
3. **ACK**：客户端收到服务器的 SYN-ACK 报文后，会发送一个 ACK（确认）报文，当服务器接收到这个 ACK 报文时，连接建立成功。

这个过程主要是为了确认双方的接收和发送能力都是正常的。

TCP 四次挥手（连接释放）

四次挥手（Four-way Handshake）的目的是可靠地关闭两个 TCP 主机之间的连接。它包括以下步骤：

1. **FIN**：当主机完成数据发送后，会发送一个 FIN（结束）报文给对方，并进入 FIN_WAIT_1 状态。
2. **ACK**：接收方收到 FIN 报文后，会发送一个 ACK 报文给发送方，并进入 CLOSE_WAIT 状态。发送方收到 ACK 后，进入 FIN_WAIT_2 状态。
3. **FIN**：接收方准备好关闭连接时，发送一个 FIN 报文给发送方，并进入 LAST_ACK 状态。
4. **ACK**：发送方收到这个 FIN 后，发送一个 ACK 报文给接收方，然后进入 TIME_WAIT 状态。经过一段时间后，确保对方收到 ACK 报文，发送方关闭连接。接收方收到 ACK 后立即关闭连接。

这个过程中涉及四次挥手是因为 TCP 是全双工模式，双方都需要单独关闭自己的发送和接收通道。

补充说明

- 在三次握手中，第三次握手是确认双方的接收能力和发送能力都正常。
- 在四次挥手中，需要四步是因为当一方完成数据发送后，还需要确保对方所有的数据都接收完毕才能完全关闭连接，而且 TCP 连接是全双工的，每个方向都必须单独进行关闭。

正确理解并能够清晰表述这两个过程对于理解 TCP 协议的可靠性机制非常重要。

**Time-Wait 和 Closed-Wait**

在 TCP 协议中，`TIME-WAIT` 和 `CLOSE-WAIT` 是两种不同的状态，它们出现在 TCP 连接的生命周期中的不同阶段，主要涉及连接的终止过程。下面是这两个状态的详细解释：

**TIME-WAIT** 状态

- **定义**：`TIME-WAIT` 状态发生在 TCP 四次挥手过程的最后阶段。当一个 TCP 连接正在关闭，并且主动关闭连接的一方（通常是客户端）发送了最后一个 ACK 响应后，它会进入 `TIME-WAIT` 状态。
  
- **目的**：
  - 确保最后一个 ACK 报文能够到达对方。如果对方没有收到这个 ACK，它会重新发送 FIN 报文，`TIME-WAIT` 状态的一方应该对此做出响应。
  - 允许旧的重复分段在网络中消失。这样可以避免在新的连接中出现旧连接的数据包，确保下一个连接是干净的。
- **持续时间**：这个状态通常会持续 2 倍的 MSL（Maximum Segment Lifetime，最大报文生存时间），MSL 通常假定为 2 分钟，因此 `TIME-WAIT` 状态通常持续 4 分钟。

**CLOSE-WAIT** 状态

- **定义**：在 TCP 四次挥手过程中，当被动关闭连接的一方（通常是服务器）收到对方发送的 FIN 报文，确认对方要求关闭连接后，它会发送 ACK 响应并进入 `CLOSE-WAIT` 状态。
- **目的**：`CLOSE-WAIT` 状态表示等待本地应用程序关闭连接。在这个状态下，TCP 连接的这一端知道对方想要关闭连接，但在它可以发送自己的 FIN 报文之前，需要等待本地应用程序决定完成剩余的数据发送并正式关闭连接。
- **行为**：在 `CLOSE-WAIT` 状态下，应用程序应该**继续读取**任何到达的数据，并最终**调用关闭连接**的操作。完成这些操作后，它会发送 FIN 报文给对方并进入 `LAST-ACK` 状态，等待对方的最后一个 ACK 响应。

区别总结

- `TIME-WAIT` 是主动关闭连接方的一个状态，保证连接被平滑地关闭，避免在网络中的旧数据包影响新连接。
- `CLOSE-WAIT` 是被动关闭连接方的状态，**等待本地应用程序关闭连接**。

正确管理这些状态对于维护 TCP 连接的可靠性和性能至关重要。尤其是在高性能网络应用中，理解这些状态如何影响资源利用和连接管理非常重要。

**chmod751**

Owner Group Others  
读 写 执行

## 螣龙安科 2.28（OC 已拒）

**Redis string 底层** #不懂

**Gin 特性**

Gin 是一个用 Go (Golang) 编写的 HTTP web 框架。它是一个类似于 martini 但拥有更好性能的 API 框架，由于使用了 **httprouter**，性能提升显著。Gin 是处理高性能请求的理想选择。以下是 Gin 的一些显著特性：

1. **快速**：Gin 使用了自定义的 HTTP 路由器，它比 Go 的标准库、mux 和其他路由器更快。其性能接近原生 HTTP 处理。
2. **轻量级**：Gin 提供了最基础的、核心的功能，避免了额外的库和依赖，使得框架保持简洁和轻量。
3. **中间件支持**：Gin 支持中间件，允许用户在处理请求和响应之前或之后执行代码，非常适合处理日志、用户认证、数据校验等任务。
4. **错误管理**：Gin 提供了一种便捷的方式来集中处理请求过程中发生的错误。
5. **路由分组**：支持路由分组功能，能够共享相同的路径前缀、中间件等，这对于构建具有共同 URL 前缀的路由集合非常有用，例如 API 版本管理。
6. **JSON 验证**：Gin 提供了结构体绑定和验证的功能，支持绑定 JSON、XML 和标准表单值等数据，并且可以对绑定的数据进行验证。
7. **模板渲染**：内置模板渲染功能，支持 HTML、XML、JSON 等格式的响应，方便构建不同的 Web 应用。
8. **高度可定制**：Gin 的设计允许高度的定制，包括自定义中间件、绑定器、渲染等。
9. **强大的性能与内存优化**：Gin 经过了精心优化，旨在减少内存分配，提高处理速度，使其成为构建高性能应用的理想选择。
10. **社区支持**：Gin 拥有活跃的社区和大量的外部库，方便开发者扩展功能和解决问题。

Gin 通过提供简洁的 API、出色的性能和高度的可扩展性，成为了 Go 开发者构建 web 应用和微服务的热门选择。

**sync.map** [[../../../Coding/Go/深入理解go/Go Map 原理|Go Map 原理]]

**JWT 单点登录**  

[[../../../Course/极客时间/初级 Golang 工程师/03 Session 和 JWT|03 Session 和 JWT]]

**Slice 并发访问**

**Slice 扩容**

**map 底层实现 B 的作用** [[go map]]

**MySQL 事务**

事务提及如何保证一致性

BufferPool

口述算法：

**三数之和**

**最长回文子串**

## 好未来 2.28 一面

mysql：

事务隔离级别、索引优化、查看 SQL 使用索引 (explain)

redis：

数据类型

String 和 Hash 区别

过期策略

如何让一个 key 过期

主要结合项目拷打 redis、mysql

作者：池敖池恩  
链接：[https://www.nowcoder.com/discuss/593098900697788416?sourceSSR=post](https://www.nowcoder.com/discuss/593098900697788416?sourceSSR=post)  
来源：牛客网

## 好未来 Go 实习面经 （挂）

处女面，双非 无实习 区域铜。2.29 技术面主管面 hr 面。3.4 挂。  
无项目问题（6.824，简单微服务，xv6），无算法问题，这是 kpi 吗？kpi 为啥还有 hr 面。  

1. map 是否线程安全  
2. **gin 框架大致原理**   
3. 进程线程协程，如何实现协程  
4. mysql 事务隔离级别  
5. 可重复读和读已提交差别，举例说明，简单讲了 mvcc  
6. 可重复读不适用场景  
7. 幻读问题  
8. 联合索引  

场景题：  

1. 分数和年龄两个字段，联合索引顺序。  
2. redis 排行榜

作者：haria_  
链接：[https://www.nowcoder.com/feed/main/detail/8156f85cafb44b97b8b7fe65732f09b9?sourceSSR=search](https://www.nowcoder.com/feed/main/detail/8156f85cafb44b97b8b7fe65732f09b9?sourceSSR=search)  
来源：牛客网

本人 25 届，目前收到快手电商 Java 实习的正式 offer，base 杭州。百度网盘商业化 Golang 实习口头 offer（开始走流程），base 北京。本人是 Java 技术栈为主，觉得以后秋招也是以 Java 技术栈为主，但是感觉百度的 title 会不会更好一些。想听听各位牛友的建议  

作者：junzuoguan  
链接：[https://www.nowcoder.com/feed/main/detail/a740c67812094f588d9977dbbcc3e54a?anchorPoint=comment](https://www.nowcoder.com/feed/main/detail/a740c67812094f588d9977dbbcc3e54a?anchorPoint=comment)  
来源：牛客网

## 滴滴地图三面速通

一面：  
实习项目  
**go 的 gin？go 服务？**  
连数据库用的哪个库  
**MySQL 的数据库的锁**  
锁触发条件/情况  
**go 的 GPM 模型简单介绍**  
**go 的垃圾回收**  
**进程和线程的区别**  
**进程间通信方式**  
**线程间通信方式**  
**常用的 Linux 命令**  

在 Linux 操作系统中，有许多常用的命令可以帮助您完成日常的文件管理、系统维护、网络配置、程序运行等各种任务。以下是一些最基础且常用的 Linux 命令及其简单描述：

1. **目录和文件操作命令：**
   - `cd`：改变当前工作目录。
   - `ls`：列出目录内容。
   - `pwd`：打印当前工作目录的绝对路径。
   - `mkdir`：创建新的目录。
   - `rmdir`：删除空目录。
   - `rm`：删除文件或目录（使用 `-rf` 参数可递归删除非空目录）。
   - `cp`：复制文件或目录。
   - `mv`：移动或重命名文件和目录。
   - `touch`：创建新文件或更新已有文件的访问和修改时间。
   - `ln`：创建硬链接或符号链接。

2. **文件内容查看和编辑：**
   - `cat`：合并并打印文件内容到标准输出。
   - `less` 或 `more`：分页查看文件内容。
   - `head`：查看文件开头部分内容。
   - `tail`：查看文件结尾部分内容，`tail -f` 实时跟踪文件末尾变化。
   - `vim` 或 `nano` 或 `emacs`：文本编辑器，用于编辑文件内容。

3. **文件权限和所有权管理：**
   - `chmod`：更改文件或目录的权限。
   - `chown`：更改文件或目录的所有者。
   - `chgrp`：更改文件或目录所属的组。

4. **系统信息查询：**
   - `uname`：显示系统信息，如内核名称、版本等。
   - `uptime`：查看系统运行时间和负载情况。
   - `top` 或 `htop`：实时显示系统状态和进程资源占用情况。
   - `free`：查看内存使用情况。
   - `df`：报告文件系统的磁盘空间使用情况。
   - `du`：估算文件或目录所占磁盘空间大小。

5. **搜索文件和内容：**
   - `find`：根据名称、类型、大小、时间等条件搜索文件。
   - `grep`：在文件中搜索符合模式的行。

6. **压缩和解压缩：**
   - `gzip`、`gunzip` 或 `zcat`：gzip 压缩和解压。
   - `bzip2`、`bunzip2` 或 `bzcat`：bzip2 压缩和解压。
   - `tar`：打包和解包文件，支持多种压缩格式。

7. **网络和通信：**
   - `ping`：测试网络连通性。
   - `ifconfig`（旧版）或 `ip`（新版）：查看和配置网络接口。
   - `netstat`（旧版）或 `ss`（新版）：显示网络连接、路由表等信息。
   - `curl` 或 `wget`：从互联网下载文件。

8. **进程控制：**
   - `ps`：报告当前系统中进程的状态。
   - `top` 或 `htop`（增强版）：动态查看和管理进程。
   - `kill` 或 `pkill`：结束进程。
   - `jobs`：查看当前 shell 环境下已启动的任务列表。
   - `fg` 或 `bg`：将后台任务调至前台运行或恢复后台运行。

9. **软件安装和包管理：**
   - 在 Debian/Ubuntu 系列中：`apt-get` 或 `apt`。
   - 在 CentOS/RHEL/Fedora 系列中：`yum` 或 `dnf`。

10. **其他常用命令：**
    - `man`：查看命令的手册页。
    - `history`：查看历史命令记录。
    - `clear` 或 `Ctrl + L`：清屏。
    - `echo`：输出字符串或变量值。
    - `alias`：设置命令别名。

以上只列举了一部分常见命令，实际使用的命令远不止这些，具体使用时可根据需要查阅更详细的命令手册。

**队列和栈的区别**  
图的了解  
图上两点的最小距离何种算法  

- Dijkstra 算法和 Floyd 算法

goroutine 中有哪几种锁  

**手撕：快排**  

二面：  
论文项目介绍  
实习项目介绍  
更新缓存数据场景的应对  
**go 中多态的实现**  
定位是偏网络 数据库 还是 Web  
Web 框架的使用  
**gin 对于用户登录态的处理**  

在 Gin 框架中，处理用户登录态通常涉及到 session 或者 token 的管理。以下是一种基于 JWT（JSON Web Tokens）的处理方式：

1. 用户登录时，验证用户名和密码是否正确。如果正确，服务器生成一个 JWT，这个 JWT 包含了用户的唯一标识符以及其他可能需要的信息，并且设置了过期时间。然后将 JWT 通过 HTTP Header 或 Cookie 返回给客户端。

```go
import (
    "github.com/gin-gonic/gin"
    "github.com/dgrijalva/jwt-go"
)

func login(c *gin.Context) {
    var user User // 假设 User 是你的用户模型结构体
    if err := c.ShouldBind(&user); err == nil {
        // 验证用户名和密码逻辑...
        if ok := validate(user.Username, user.Password); ok {
            token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{
                "username": user.Username,
                "exp":      time.Now().Add(time.Hour * 24).Unix(), // 设置 token 过期时间为24小时
            })
            tokenString, _ := token.SignedString([]byte("your_secret_key")) // 签名并生成 token 字符串
            c.JSON(200, gin.H{
                "token": tokenString,
            })
        } else {
            c.JSON(401, gin.H{"error": "Invalid username or password"})
        }
    } else {
        c.JSON(400, gin.H{"error": "Invalid request body"})
    }
}
```

1. 客户端在后续请求中，将 JWT 放在 Authorization 请求头中（通常是 Bearer 模式），发送给服务器。
2. 服务器在每个受保护的路由中间件中，解析并验证 JWT，验证通过则继续执行后续操作，否则返回未授权错误。

```go
func authenticateMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" {
            c.AbortWithStatusJSON(401, gin.H{"error": "Unauthorized"})
            return
        }

        tokenString := strings.Replace(authHeader, "Bearer ", "", 1)
        token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
            if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
                return nil, fmt.Errorf("Unexpected signing method: %v", token.Header["alg"])
            }
            return []byte("your_secret_key"), nil // 这里应使用与签发时相同的密钥
        })

        if err != nil {
            c.AbortWithStatusJSON(401, gin.H{"error": "Unauthorized"})
            return
        }

        if claims, ok := token.Claims.(jwt.MapClaims); ok && token.Valid {
            // 获取到的 claims 可以用于获取用户信息或进行其他权限校验
            username := claims["username"].(string)
            // ...
        } else {
            c.AbortWithStatusJSON(401, gin.H{"error": "Unauthorized"})
        }
        
        c.Next()
    }
}

// 使用中间件
router.GET("/protected", authenticateMiddleware(), func(c *gin.Context) {
    // ...
})
```

注意：上述代码仅作示例用途，请根据实际需求调整并确保安全性，如对 secret key 的安全存储和使用等。同时，JWT 不适合存储过于敏感的数据，因为它在传输过程中是明文的，尽管可以被签名但不能被加密。对于非常敏感的信息，建议结合 HTTPS 和后端数据库一同处理。

用户态的管理，用户登录态的保持  
多个进程（含同名进程）全部杀掉的 Linux 命令  

三面：  
**项目中遇到的一个有挑战的技术问题，如何解决的，解决思路**  

- 索引优化、性能优化等等功能，高并发的场景

**B+ 树索引**  

B+ 树（B-plus Tree）是一种广泛应用于数据库和文件系统中用于索引的数据结构，尤其在关系型数据库管理系统如 MySQL 中扮演着关键角色，它优化了磁盘 I/O 密集型环境下的数据检索性能。  

**B+ 树的主要特点**

1. **层级结构**：B+ 树是一个自平衡的多路搜索树，它的每个节点包含多个键和对应数量的指针。B+ 树的阶表示每个节点最多有多少个孩子，它决定了树的扇出度（即每个节点可以有多少个子节点）。相比 B 树，B+ 树的每个节点通常能存储更多的键值对和指针，从而使得树的高度更低，减少了磁盘 I/O 次数。
2. **叶节点存储数据**：在 B+ 树中，所有的数据都存储在叶子节点上，而非叶子节点仅存储索引（键值对），并不直接保存实际的数据行。并且，所有叶子节点形成了一个有序链表，这样有利于范围查询和全表扫描。
3. **高扇出性**：B+ 树的节点具有较高的扇出性，这意味着在一个节点内可以存储大量的键值和指针，从而保证即使数据量很大，树的高度也能维持在较低水平，通常在 2 到 4 层之间，这对于减少磁盘寻址的 I/O 次数至关重要。
4. **聚簇索引与辅助索引**：
   - **聚簇索引**（Clustered Index）：在 InnoDB 存储引擎中，主键索引采用的就是聚簇索引，数据行的实际内容就储存在叶子节点上，按照主键的顺序排列。因此，一张表只有一个聚簇索引，它决定数据行的物理存储顺序。
   - **辅助索引**（Secondary Index，又称非聚集索引）：除了主键索引外的其他索引都是辅助索引，它们的叶子节点存储的是相应键值以及对应的主键值，而不是实际的行数据。
5. **范围查询友好**：由于所有叶子节点形成连续的有序链表，对于需要范围查询的情况，B+ 树只需要沿着叶子节点的链表顺序扫描即可，无需像 B 树那样回溯父节点，大大提高了效率。

总结来说，B+ 树索引的设计理念是为了最大化地利用外部存储（如磁盘）的特点，通过合理的数据分布和组织形式，使得数据读取更加高效，尤其适合大量数据和频繁的查询操作场景。  

wgs84  

WGS84（World Geodetic System 1984）是一种全球大地坐标系标准，由美国国防部研制并在 1984 年确定，被广泛应用于地理信息系统、航空航海、测绘、GPS 全球定位系统等领域。它是目前国际上公认并普遍采用的地心坐标系统之一。

在 WGS84 坐标系中，主要特点包括：

- 原点位于地球质心。
- Z 轴指向国际时间局（BIH）在 1984.0 定义的协议地球极（CTP）方向，即地球自转轴在某一特定时刻的方向。
- X 轴指向 BIH1984.0 的零度子午面（Prime Meridian）和 CTP 赤道的交点，也即是国际本初子午线穿过赤道的地方。
- Y 轴通过右手定则确定，从而构成右手直角坐标系。

WGS84 还包括了一个地球参考椭球体模型，用来逼近地球的形状，并提供了精确的参数来描述地球表面的几何特征。这一模型被用于计算地理位置的经纬度坐标、海拔高度以及相关空间位置的转换。

随着时间的推移，WGS84 经历了多次修订，以改进其精度，每一次修订都会产生一个新的版本，例如通过 GPS 卫星网络收集数据来进行细微修正。由于其与 GPS 系统的紧密联系，WGS84 成为现代导航、定位和遥感应用的基础坐标框架。

**谷歌卫星影像数据的组织形式，如何覆盖一个地球以及缩放**  
**缓存预热方案的背景与解决方案**  

所谓缓存预热，就是提前把数据库里的数据刷到缓存里，通常有这些方法：

1. 直接写个缓存刷新页面或者接口，上线时手动操作
2. 数据量不大，可以在项目启动的时候自动进行加载
3. 定时任务刷新缓存

缓存预热（Cache Priming）是在缓存系统中的一种策略，主要是指在应用程序启动之初或者在服务可用之前，预先将一些重要的、经常访问的数据加载到缓存系统中，以便当用户发起请求时可以直接从缓存中获取数据，而不是等到有请求到达时才触发缓存填充，这样可以显著提升系统的响应速度和服务质量。

背景：

- **性能优化**：对于依赖缓存提供高性能的服务而言，首次请求时如果数据不在缓存中，就需要从持久化存储（如数据库）中加载，这通常比从缓存中读取慢得多，可能导致延迟增加和系统负载突增。
- **高峰时段应对**：在高峰期到来之前进行缓存预热，可以防止大量并发请求在同一时间尝试加载相同数据而造成的“缓存雪崩”现象，保证服务稳定性。
- **热点数据**：对于那些访问频度极高或者重要性极强的热点数据，必须确保它们始终存在于缓存中，以提供近乎实时的服务体验。

解决方案：

1. **手动预热**：开发人员编写专门的脚本或页面，在服务部署或重启后手动触发加载关键数据到缓存。
2. **自动预热**：
   - **项目启动时预加载**：应用程序初始化阶段，可以通过监听启动事件，自动化加载高频访问的数据到缓存中。
   - **定时任务**：设定定时任务，在固定时间段或周期性地将预期会访问的数据加载到缓存。
   - **事件驱动**：基于业务逻辑，当发生某些事件（如数据库数据变更）时触发预热操作。
3. **增量预热**：只预热最近新增或更新的数据，而不是每次全部重新加载。
4. **全量预热**：适用于数据量相对较小的情况，在系统启动时一次性加载所有缓存数据。
5. **分布式缓存预热**：对于大型分布式系统，可能需要设计复杂的分布式缓存预热策略，确保多个节点上的缓存同步和有效预加载。
6. **API Gateway 预热**：在 API Gateway 层面设计预热策略，当流量入口感知到服务启动或配置变更时，主动发起预热请求。
7. **监控和智能预热**：结合监控工具和 AI 算法预测哪些数据可能会变成热点数据，并提前进行预热，实现智能化管理缓存。

总之，缓存预热的具体实现方式会根据应用场景、数据量、系统架构等因素的不同而有所差异，目标是让缓存系统能在真正开始服务时处于准备就绪的状态。

**Redis 数据如何做淘汰**  

Redis 数据淘汰策略（ eviction policy）是在 Redis 内存使用达到用户预设的 `maxmemory` 上限时触发的一种机制，用于在内存不足时自动删除部分数据以腾出空间。Redis 提供了多种淘汰策略供用户选择，以下是其中几种主要的淘汰策略：

1. **volatile-lru**：仅针对设置了过期时间（TTL）的键进行淘汰，通过 LRU（Least Recently Used）算法来选择最近最少使用的键进行删除。
2. **allkeys-lru**：对所有键（包括没有设置过期时间的键）使用 LRU 算法淘汰。
3. **volatile-lfu**：仅针对设置了过期时间的键，使用 LFU（Least Frequently Used）算法淘汰访问频率最低的键。
4. **allkeys-lfu**：对所有键使用 LFU 算法淘汰。
5. **volatile-random**：随机淘汰设置了过期时间的一个键。
6. **allkeys-random**：随机淘汰任意一个键，无论其是否有过期时间。
7. **volatile-ttl**：优先淘汰即将过期的键，也就是说，根据键的剩余生存时间（TTL）进行淘汰，生存时间越短的键越先被淘汰。
8. **noeviction**（默认策略）：不允许任何数据被驱逐，当内存满时，所有引起更多内存分配的操作都会返回错误，除非是 DEL 或者 UNLINK 这样的删除操作。

选择合适的淘汰策略需要根据您的应用特性和数据访问模式来决定。在 Redis 配置文件中（如 redis.conf），通过设置 `maxmemory-policy` 参数来指定使用哪种淘汰策略。一旦达到 `maxmemory` 限制，Redis 就会依据所选策略开始淘汰数据。

**Redis 中的 Key 如何设计**

在 Redis 中设计 Key 是至关重要的，因为良好的 Key 设计可以提升数据查询效率、节省存储空间并简化维护。以下是一些建议和最佳实践：

1. **命名规范**：
   - **简洁明确**：Key 应该尽可能简短，减少网络传输开销，同时易于理解和记忆。例如，`user:1234:name` 表示用户 ID 为 1234 的用户名信息。
   - **有意义**：Key 应该能够表达其存储的内容，遵循一定的命名约定，例如使用冒号（:`）、破折号（-）或下划线（_）分隔字段，便于阅读和理解。
   - **统一前缀**：为不同类型的数据添加统一前缀，如 `user:`, `order:`, `session:` 等，方便分类管理和批量操作。
2. **结构化设计**：
   - **嵌套结构**：对于关联性强的数据，可以考虑使用 Hash 结构，比如 `user:1234` 作为一个 Hash 键，内部包含多个字段如 `name`, `email` 等。
   - **集合和列表**：若数据需要按集合或列表存储，如用户关注列表，可以设计为 `followers:1234`。
3. **过期时间**：
   - 对于临时或有生命周期的数据，如 Session、验证码等，设置合适的过期时间（TTL）非常重要，避免内存中积累大量无用数据。
4. **大小控制**：
   - 注意 BigKey 问题，避免单个 Key 的 Value 过大（例如大于几兆字节），以免影响 Redis 性能和网络带宽。
   - 使用合适的 Redis 数据结构（如 Set、Sorted Set 等）替代大体积的 String 类型，降低存储成本。
5. **扩容与分区**：
   - 如果应用需要横向扩展，考虑在 Key 设计时加入分片标识，使数据均匀分布在多个 Redis 实例中。
6. **避免热点 Key**：
   - 避免所有客户端都频繁访问同一 Key，如果不可避免，可以考虑使用 Lua 脚本减少网络往返次数。
7. **事务与批处理**：
   - 在设计 Key 时考虑到原子操作和批处理的需求，比如使用 pipeline 或 multi/exec 事务。
8. **冗余与一致性**：
   - 根据业务需求，可能需要设计带有备份或镜像功能的 Key，例如使用 Redis 主从复制或集群。
9. **删除策略**：
   - 适时地清理不再使用的 Key，尤其是在有限内存场景下，配合 Redis 的淘汰策略。

综上所述，设计 Redis Key 的关键是兼顾可读性、易维护性、性能优化及资源利用率。同时，还要结合具体的业务场景和技术要求做出合理的选择。

Redis 具体设计的原理  

Redis 的设计原理可以从以下几个核心方面进行详细说明：

1. **内存数据库**：
   - Redis 是一个纯内存数据库，它将所有数据存储在内存中，以此实现快速的数据读写操作。内存存储意味着读写速度接近于处理器的速度，相较于传统的硬盘存储，大幅度提升了性能。
2. **数据结构丰富**：
   - Redis 不仅仅是一个简单的键值存储系统，它支持五种基本数据结构：字符串（Strings）、列表（Lists）、集合（Sets）、有序集合（Sorted Sets）和哈希表（Hashes）。这些数据结构提供了丰富多样的操作，例如列表的 push/pop、集合的交并差运算、有序集合的范围查找等，满足多种业务场景需求。
3. **单线程模型**：
   - 采用了单线程事件驱动模型，所有客户端请求都在同一个线程中顺序执行。虽然看似单线程限制了并发能力，但由于数据在内存中，不存在传统数据库磁盘 I/O 瓶颈，所以单线程足以充分利用 CPU 并发处理网络请求。同时，单线程避免了锁竞争，简化了编程模型，提高了系统的稳定性和性能。Redis
4. **异步持久化**：
   - Redis 提供两种持久化机制，分别是 RDB（Redis Database）和 AOF（Append Only File）：
     - RDB：通过定时快照的方式将内存中的数据保存到磁盘上，是一种周期性全量持久化的方法，**适合灾难恢复场景**。
     - AOF：记录每一个写命令到日志文件中，当 Redis 重启时再重新执行这些命令来重建数据，支持多种不同的持久化策略和日志重写优化，可以实现更高的数据安全性。
5. **网络模型**：
   - Redis 使用了基于 Reactor 模式的网络库，如 **epoll**（Linux）或 kqueue（BSD/Mac OS X），能够高效地处理大量并发连接，支持非阻塞 I/O。
6. **复制与高可用**：
   - Redis 支持主从复制（Replication），主节点的数据会异步复制到从节点，从而实现数据的备份和故障转移。
   - Redis Sentinel（哨兵）系统提供了自动化的故障检测和恢复，能够选举新的主节点，保持 Redis 集群的高可用性。
   - Redis Cluster 则实现了数据的分布式存储和管理，通过分片（Sharding）技术分散数据压力，支持线性水平扩展。
7. **Lua 脚本与事务**：
   - Redis 支持在服务器端执行 Lua 脚本，可以在服务器端一次执行多个命令，保证原子性和减少网络延迟。
   - Redis 的事务支持多条命令的一次性执行，采用 Multi/Exec 模式，但需要注意的是 Redis 的事务不保证严格的 ACID 特性，而是提供一种简单的命令序列执行。
8. **性能优化**：
   - Redis 自身实现了多种优化技术，包括高效的内存管理、数据结构的紧凑存储、字典的渐进式 rehash 等，最大限度地减少内存消耗和 CPU 开销。

以上是 Redis 的几个主要设计原理，这些特性共同构成了 Redis 高性能、低延迟、持久化、高可用的 NoSQL 数据存储系统。

timeline:10.9 投递 -10.12 三面速通 -12.15OC-12.19offer

作者：99 小菜鸡  
链接：[https://www.nowcoder.com/feed/main/detail/10340b068c664dc7b4a6155609de5e72?sourceSSR=search](https://www.nowcoder.com/feed/main/detail/10340b068c664dc7b4a6155609de5e72?sourceSSR=search)  
来源：牛客网

## 简历怎么写

- [看看一份标杆简历的分析（建议收藏）_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/566984772325515264?sourceSSR=search)

## 寄了！，有请下一位天才中单

### 百度后端实习 一面凉经

15min

### 自我介绍 + 问项目

数据库表是怎么建的，数据读取流程是怎么样的

redis 用到了那些结构，是怎么保持数据一致性的

我看你有整合日志，你是怎么对日志分级的

怎么串联起日志的上下游（不会）

25 Min

### Golang 基础

**slice 和 array 的区别**

Go 语言中的数组（Array）和切片（Slice）都是用于存储一组元素的数据结构，但在很多方面有着明显的区别：

1. **固定长度 vs 动态长度**：
   - 数组：数组是具有固定长度的，一旦声明，其长度就不能改变。例如 `var arr [5]int` 表示一个包含 5 个整数的数组。
   - 切片：切片则是动态长度的，可以追加元素或者收缩容量，其内部实际上是对数组的一个引用窗口，可以自由改变切片的长度和容量。
2. **声明与初始化**：
   - 数组：在声明时必须指定长度，并且可以初始化所有元素，例如 `var arr [5]int = [5]int{1, 2, 3, 4, 5}`。
   - 切片：声明时不需指定长度，甚至可以不指定容量，例如 `var sli []int`。切片可以使用 make 函数创建，如 `sli := make([]int, 0, 5)`，这里创建了一个初始长度为 0，容量为 5 的切片。
3. **容量与增长**：
   - 数组：数组的容量就是它的长度，无法自动增长。
   - 切片：切片有一个长度和容量的概念，当向切片追加元素超出长度但未达到容量时，会自动增长（默认翻倍并预留一定数量的空间），可通过 `append` 函数实现。
4. **底层数据共享**：
   - 当切片是对数组的一部分引用时，两者共享同一段底层数组。对切片的修改会影响到原数组。
5. **赋值与传递**：
   - 数组赋值是值传递，意味着复制整个数组。
   - 切片赋值是引用传递，复制的是切片结构本身，但它们仍然共享相同的底层数组，因此修改其中一个切片可能会影响另一个。

总的来说，数组更适合知道确切大小且不需要动态增长或收缩的场合；而切片在大多数场景下更实用，尤其是需要动态操作序列长度的时候。

**slice 的扩容过程**

Go 语言中的切片（slice）在容量不足时会自动进行扩容。扩容的过程可以概括为以下几个步骤：

1. **判断是否需要扩容**：  
   当调用 `append` 函数尝试向切片追加元素，且当前切片的容量（cap）不足以容纳新元素时，Go 会触发扩容操作。
2. **计算新容量**：
   - 在旧容量（cap）小于等于 1024 个元素时，扩容后的容量一般会翻倍，也就是新容量为旧容量的 2 倍。
   - 当旧容量超过 1024 个元素时，扩容的增长因子变为大约 1.25 倍（实际上是 `oldCap * 2 / 3 + oldCap / 4`，也就是大约 1.5 倍，但实际比例略低于此）。
   - 新版本的 Go 可能会对扩容策略进行微调，具体细节需要查阅最新的官方文档或源代码。
3. **分配新内存**：  
   Go 运行时会分配一块新的、足够大的内存区域来存放扩容后的数据。
4. **复制旧数据**：  
   将旧切片中的元素复制到新分配的内存区域。
5. **更新切片元信息**：  
   更新切片结构（header）中的指针和容量信息，使其指向新的内存区域，并更新容量值。
6. **追加新元素**：  
   在扩容后的新内存区域追加新元素，此时切片的长度（len）会增加。

需要注意的是，扩容操作的目的是尽量避免频繁的内存分配和数据迁移，所以在实际扩容时会尽量增大新容量以适应未来可能的连续追加操作，同时也考虑到了内存分配的效率和内存浪费之间的平衡。随着 Go 语言的发展，其内部的扩容策略可能会有微调以优化性能表现。

**大切片和小切片的耗时是一样的吗**

在 Go 语言中，操作切片（不论是大切片还是小切片）的时间复杂度主要取决于操作本身的性质，而不是切片的大小。例如，遍历一个切片（无论是大是小）的时间复杂度通常是 O(n)，n 代表切片的长度。

**defer 的执行流程，顺序** defer 八股文 —— **课程中有的**

在 Go 语言中，`defer` 语句用于在函数执行完成后（无论是正常返回还是抛出异常）延后执行某个函数调用。`defer` 的执行流程和顺序遵循以下规则：

1. **注册顺序**： 当函数执行过程中遇到 `defer` 语句时，被 `defer` 修饰的函数会被压入一个延迟调用栈（Last In First Out，LIFO），也就是说，最后注册的 `defer` 语句首先被压入栈顶，最早注册的 `defer` 语句压在栈底。
2. **执行顺序**： 当函数即将返回时，不论函数是如何结束（无论是通过 `return` 语句、`panic` 引起的异常退出或是其他方式），都将按照栈底到栈顶的顺序，依次执行之前注册的 `defer` 函数。
3. **与 return 的关系**：
    - `return` 语句首先执行并计算返回值，但是实际的返回动作（即函数真正结束并返回给调用者）发生在所有 `defer` 函数执行完毕之后。
    - 即使在 `return` 语句之后还有 `defer` 函数，这些 `defer` 函数也会得到执行的机会。

### Mysql

**mysql 有哪些索引**  
**你项目里的 mysql 是怎么建索引的**  
**索引树的数据结构是什么样的**  
联合索引的流程，结构

联合索引（Composite Index 或 Multi-column Index）是数据库中对多个列同时建立的索引，它主要用于优化包含多个字段组合查询的性能。联合索引的流程和结构大致如下：

结构

联合索引的结构就像一个多维的有序数组或 B 树/B+ 树。以 MySQL 为例，假设我们有一个 `users` 表，包含 `first_name`、`last_name` 和 `age` 三个字段，并创建了一个联合索引 (`index_name`)，索引列顺序为 `(first_name, last_name, age)`：

1. **索引树结构**：
   - 联合索引的第一层根据 `first_name` 排序；
   - 第二层在相同 `first_name` 的情况下，根据 `last_name` 排序；
   - 第三层在相同 `first_name` 和 `last_name` 的情况下，根据 `age` 排序。

2. **索引键**：
   - 联合索引的键是由参与索引的所有列的值组成的，如 `(张, 三, 30)`。

流程

1. **创建联合索引**：

   ```sql
   CREATE INDEX index_name ON users (first_name, last_name, age);
   ```

2. **索引使用**：
   - 查询时，如果 WHERE 子句中包含了索引列的左边部分，那么数据库就可以有效地利用联合索引进行查询加速。例如：

     ```sql
     SELECT * FROM users WHERE first_name = '张' AND last_name = '三';
     ```

     此查询可以根据索引快速定位到结果。

3. **索引覆盖**：
   - 若查询涉及的所有列都在索引中，无需回表查询，这种现象称为索引覆盖。例如：

     ```sql
     SELECT first_name, last_name FROM users WHERE first_name = '张' AND last_name = '三';
     ```

4. **最左前缀原则**：
   - 联合索引的查询主要遵循最左前缀原则，即查询时至少要包含第一个索引列。例如，只查询 `last_name` 就无法利用此索引：

     ```sql
     SELECT * FROM users WHERE last_name = '三'; -- 无法利用索引
     ```

5. **索引优化**：
   - 在设计联合索引时，应当根据实际业务中查询的频繁程度和查询条件的组合来决定索引列的顺序。

**走索引和不走索引的流程**

在数据库查询过程中，走索引和不走索引的流程有所不同，以下是它们的基本流程对比：

走索引流程（使用索引查询）：

1. **查询阶段**：
   - 当查询条件中包含索引列时，数据库系统首先检查是否存在与查询条件相匹配的索引。
   - 如果找到相应的索引，数据库将通过索引树或索引表来查找数据，索引结构（如 B 树或 B+ 树）允许数据库系统快速定位到符合条件的数据所在的物理位置。
2. **索引查找**：
   - 根据索引的结构（如 B+ 树），数据库沿着索引树从根节点向下遍历，通过比较索引键值快速缩小搜索范围，最终找到匹配查询条件的索引记录。
   - 对于范围查询，数据库会在索引区间内进行遍历，而不是全表扫描。
3. **回表查询**（如果有需要）：
   - 如果索引是非覆盖索引（Index Scan without Covering），即查询结果需要包含索引之外的列，数据库在找到索引匹配项后，还需要回到主数据区（数据页）获取其他列的数据。
4. **返回结果**：
   - 数据库根据索引查找的结果，返回所需的记录集。

不走索引流程（全表扫描）：

1. **查询阶段**：
   - 当查询条件中没有合适的索引可用，或者数据库优化器判断全表扫描更为高效时，数据库将进行全表扫描操作。
2. **数据扫描**：
   - 数据库系统会逐行遍历表中的每一行记录，对每一行数据执行查询条件判断。
3. **筛选结果**：
   - 对每一行数据执行 WHERE 子句中的条件检查，保留符合查询条件的行。
4. **排序和分组（如有必要）**：
   - 如果查询中有 ORDER BY、GROUP BY 或 LIMIT 等子句，数据库需要对扫描得到的结果集进行排序或分组处理。
5. **返回结果**：
   - 数据库系统将过滤后的结果集返回给客户端。

总结

走索引的查询通常更快，因为它减少了需要处理的数据量，特别是在大数据表中。而不走索引的全表扫描效率较低，尤其是在数据量庞大的情况下，因为它需要遍历整个表的所有行。然而，数据库优化器会根据查询条件、表数据分布、索引的使用成本等因素综合决定是否使用索引。

mysql 的锁了解吗（只知道行锁）

MySQL 中的锁是数据库管理系统用于控制对数据并发访问的重要机制，旨在确保在多用户或多事务环境下数据的一致性和完整性。MySQL 支持多种类型的锁，主要包括以下几种：

1. **表级锁 (Table-level Locks)：**
   - **表锁**：锁定整个表，MyISAM 存储引擎默认采用表锁，开销小，加锁快，但并发能力较弱，不适合高并发写入的场景。
   - **意向锁 (Intent Locks)**：在 MySQL 中，对表加行锁前需要先获得意向锁，意向锁用来表明事务打算在表的某个部分（如行）上加锁。
2. **行级锁 (Row-level Locks)：**
   - **Record Locks**：锁定一行记录。
   - **Gap Locks**：锁定一个范围内的间隙，阻止其他事务在这个范围内插入新行。
   - **Next-Key Locks**：结合了 Record Locks 和 Gap Locks，锁定一个范围包括记录本身及其前面的间隙。
3. **页级锁 (Page-level Locks)**：
   - 有些存储引擎（如 InnoDB 在某些情况下）使用页级锁，锁定一个数据页内的所有记录。
4. **意向锁与其他类型的兼容性**：
   - 不同类型的锁之间有不同的兼容性，例如，多个事务可以同时获得表的意向读锁（意向共享锁，Intention Shared Lock, IS），但一个事务持有表的意向排他锁（意向独占锁，Intention Exclusive Lock, IX）时，其他事务不能获取表的任何其他锁。
5. **事务隔离级别与锁的关系**：
   - 不同的事务隔离级别（Read Uncommitted、Read Committed、Repeatable Read、Serializable）对锁的使用策略有所不同，尤其是 Repeatable Read 级别下，InnoDB 会默认使用 Next-Key Locks 来防止幻读。
6. **乐观锁 (Optimistic Locking) 与悲观锁 (Pessimistic Locking)**：
   - MySQL 还支持乐观锁策略，它不是真正的锁，**而是在数据版本**（如 MySQL 的 `SELECT … FOR UPDATE` 或 `SELECT … LOCK IN SHARE MODE`）或应用程序层面实现的一种并发控制机制。悲观锁则是事务在执行操作前就先锁定资源，防止其他事务干扰。
7. **自动增长 (Auto-Increment Locks)**：
   - 当插入新行并使用自动增长列时，会使用特殊的锁来保证序列值的唯一性和一致性。
8. **死锁检测与预防**：
   - MySQL 的 InnoDB 存储引擎具有死锁检测机制，当两个或多个事务相互等待对方持有的锁时，InnoDB 会识别并回滚一个事务以打破死锁循环。

通过合理使用和配置 MySQL 的各种锁机制，可以有效地管理并发事务间的冲突，确保数据在并发环境下的完整性和一致性。

行锁解决了哪些问题（不会）

行锁（Row-level Locks）主要解决以下在数据库并发访问中的问题：

1. **并发事务间的冲突**：
   - 多个事务同时更新同一条记录时，如果没有适当的锁机制，可能会导致数据不一致。例如，“丢失更新”（Lost Update）问题，其中一个事务对某行的修改可能会被另一个并发事务覆盖，破坏事务的隔离性。
   - 行锁确保当一个事务正在修改某行时，其他事务不能同时修改该行，从而避免了这类并发问题。
2. **避免长事务阻塞**：
   - 行锁相比于表锁，可以提供更细粒度的并发控制，减少锁的争抢。如果只是修改表中的个别行，行锁仅会阻塞对那些受影响行的访问，而不会阻塞对表中其他行的并发访问，降低了并发操作时的阻塞等待时间，提高了系统吞吐量。
3. **数据一致性**：
   - 行锁确保了事务在修改数据时，只有在锁释放后，其他事务才能看到修改的结果，这是事务 ACID 属性中的“隔离性”（Isolation）要求。通过行锁，可以实现可重复读（Repeatable Read）等事务隔离级别，避免了脏读（Dirty Reads）、不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）等问题。
4. **提高并发性能**：
   - 在高并发环境下，行锁极大地提高了系统的并发处理能力，因为它允许多个事务同时处理不同的行数据，而不会互相阻塞。对于 OLTP（在线事务处理）系统，行锁的使用能够更好地满足频繁的小规模读写操作需求。

总之，行锁通过对数据库中最基本的数据单元——行进行锁定，能够在并发环境下保障数据的准确性和一致性，同时最大程度地减小了事务间的等待和冲突，提高了数据库系统的并发性能。

### Redis

**你项目里有用到 hash 吗，具体是什么样的**

Redis 的 Hash 是一种存储键值对的集合，它是 Redis 支持的五种主要数据类型之一。在 Hash 类型中，每个 Hash 可以存储多个键值对，其中每个键即为字段（Field），对应的值可以是字符串。这种数据结构特别适合用于存储对象或多个相关属性的集合。

Hash 使用场景

1. **对象存储**：最常见的使用场景是存储对象。例如，你可以使用 Hash 来存储用户的信息，如用户名、邮箱、密码等，其中 Hash 的键是用户的 ID，字段是属性名，字段值是属性值。
2. **避免多次访问 Redis**：相比于将对象的每个属性单独存储为 String 类型，使用 Hash 存储一个对象的所有属性可以减少与 Redis 的通信次数，因为你可以一次性读写对象的多个属性。
3. **节省空间**：对于拥有相同一组字段的多个对象，使用 Hash 比单独的字符串键占用更少的内存空间。Redis 内部对小于一定数量的小 Hashes 进行了特殊编码，使其占用的空间更少。
4. **计数器和统计**：Hash 还可以用于维护计数器和统计数据，比如社交媒体上的帖子的浏览量、点赞数等。通过字段进行累加或递减操作，既可以实现计数器的功能，又能保持数据的整洁。
5. **缓存数据结构**：当需要缓存复杂的数据结构时，如用户的购物车信息或临时的会话数据，Hash 类型提供了一种便捷的方式来存储和访问这些数据。

常用命令

- `HSET key field value`：向名为 key 的 Hash 中添加字段 field 的值为 value。
- `HGET key field`：获取名为 key 的 Hash 中字段 field 的值。
- `HMSET key field1 value1 [field2 value2 …]`：同时设置多个字段的值。
- `HMGET key field1 [field2 …]`：获取所有给定字段的值。
- `HGETALL key`：获取 Hash 中所有的字段和值。
- `HDEL key field1 [field2 …]`：删除一个或多个字段。
- `HINCRBY key field increment`：将 Hash 中指定字段的数值增加给定的数字。

Hash 类型是 Redis 提供的一个非常强大和灵活的数据结构，适用于各种不同的场景，特别是在需要存储和管理对象属性时。通过合理使用 Hash，可以提高数据操作的效率，同时优化内存的使用。

**hash 的底层数据结构是什么（不会）**

Redis 的 Hash 结构在底层实现上使用了两种不同的数据结构：压缩列表（ziplist）和哈希表（hashtable），具体使用哪种数据结构取决于 Hash 的大小以及 Redis 的配置。

1. **压缩列表（ziplist）**：当 Hash 包含的字段和字段值都相对较小，且数量不超过一定的阈值时，Redis 会使用压缩列表作为 Hash 的底层实现。压缩列表是一种为了节省空间而设计的紧凑的顺序数据结构，它将所有的元素紧密地排列在一起，没有任何间隙。这种结构非常适合存储少量的小数据。
2. **哈希表（hashtable）**：当 Hash 的字段数量增加或字段的大小增长到超过预设的阈值时，Redis 会自动将底层数据结构从压缩列表转换为哈希表。哈希表是一种典型的键值对集合，提供了非常快速的查找、添加和删除操作。在哈希表中，每个字段都被映射到哈希表的一个槽位中，从而能够快速地进行访问。

Redis 使用这两种数据结构的主要考虑是空间效率和操作效率之间的平衡。对于小的 Hash 结构，压缩列表可以显著减少内存使用，但是随着元素数量的增加，列表的操作效率会下降。此时转换为哈希表虽然会增加内存的使用，但能够保持操作的高效率，尤其是在进行频繁的读写操作时。

可以通过 Redis 配置文件中的 `hash-max-ziplist-entries` 和 `hash-max-ziplist-value` 两个参数来控制 Hash 使用压缩列表和哈希表的转换阈值。这两个参数分别表示压缩列表最多可以存储的元素数量和元素值的最大大小。

**string 的底层数据结构是什么**

Redis 的 String 类型是最简单也是最常用的数据类型之一，用于存储字符串值。尽管它被称为“String”，但实际上可以存储任何形式的数据，包括二进制数据。String 类型的底层数据结构有两种：简单动态字符串（Simple Dynamic String，SDS）和整数值（Integer）。

1. **简单动态字符串（SDS）**：SDS 是 Redis 用来实现 String 类型的主要数据结构。与传统的 C 字符串相比，SDS 有几个关键的优势：
   - **安全**：不会因为忘记空字符 '\0' 而导致的缓冲区溢出问题。
   - **效率**：增加或减少字符串长度时，SDS 可以更有效地进行内存的分配和释放。由于维护了字符串的实际长度，SDS 可以在 O(1) 时间复杂度内获取字符串长度，而 C 字符串需要遍历整个字符串计算长度，时间复杂度为 O(n)。
   - **灵活性**：SDS 支持二进制安全，意味着它们可以包含任何二进制数据，包括 '\0' 字符。
2. **整数值（Integer）**：当 String 类型的值可以表示为 64 位长整型数时，Redis 会优化存储方式，直接使用整数值来存储，而不是转换成字符串存储。这种优化可以减少内存的使用，同时加快操作速度。例如，如果你使用 String 类型存储数字 "100"，Redis 会将它存储为一个整数值而不是字符串。

Redis 会根据存储的内容自动选择最适合的底层实现，以达到高效存储和访问的目的。对于开发者而言，这些底层的优化是透明的，无需进行额外的配置或操作，你只需要按照 String 类型的接口来使用它即可。

**redis 的缓存策略有哪些 (内存淘汰策略)**

reids 的缓存开着和关着的时候对读写有什么影响吗（不会）——指的是持久化方案嘛？

**redis 过期删除策略有那些**

**用 redis 实现分布式锁的流程是什么样的**

使用 Redis 实现分布式锁是一种常见的做法，尤其适用于分布式系统中资源或操作需要同步访问的场景。这里介绍一个基本的流程来实现一个简单但有效的分布式锁：

获取锁

- 使用 `SET` 命令结合一些特定的参数来设置一个锁。这个命令的一种常见形式是 `SET lock_key random_value NX PX 30000`。这条命令的意思是：
  - `lock_key`：锁对应的键。
  - `random_value`：锁的值，这是一个随机生成的字符串，确保解锁操作的安全性，防止误解锁。
  - `NX`：仅当键不存在时设置键，确保锁的互斥性。
  - `PX 30000`：设置键的过期时间，例如这里是 30000 毫秒（30 秒），防止死锁。

锁定资源的操作

- 当客户端成功设置了锁键时（即 `SET` 操作返回 `OK`），它获得了锁，并可以执行被锁定资源的操作。

释放锁

- 完成资源操作后，客户端应该立即释放锁。由于只有持有锁的客户端知道 `random_value`，因此它可以通过 `random_value` 来验证并安全地释放锁。
- 释放锁一般通过一个 Lua 脚本来实现，这个脚本会检查 `lock_key` 的值是否与 `random_value` 相等，如果相等，则删除键，释放锁。这样做是为了确保操作的原子性，防止在检查和删除之间发生的状态变化导致误解锁。

注意事项和改进

- **锁的安全性**：为了防止释放由其他客户端获得的锁，使用 `random_value` 作为锁的值是非常重要的。
- **续租机制**：为了避免长时间运行的操作因锁过期而导致的问题，可以实现锁的续租机制，即在锁快要过期时自动延长其过期时间。
- **避免阻塞**：如果不能立即获得锁，客户端应该等待一段时间后重试。可以实现一个带有**超时的重试逻辑**，以避免无限等待。
- **使用 Redisson**：对于 Java 应用，可以考虑使用 Redisson 这样的库，它提供了更高级的分布式锁实现，包括自动续租、公平锁等特性。

使用 Redis 实现分布式锁虽然广泛，但需要仔细设计以避免死锁、锁提前过期和其他潜在问题。在实际应用中，还需要考虑网络延迟、客户端崩溃等因素对锁机制的影响。

**在分布式锁中怎么防止等待太久或者因为故障不能解锁**

在实现分布式锁时，确保锁机制既高效又安全是至关重要的。防止客户端等待时间过长或因为故障而不能正确解锁，需要采取一些策略和考虑以下几个关键点：

**设置合理的锁超时时间**

- **锁超时时间**是指锁自动释放的时间，应根据操作的预期执行时间来设置。这可以防止一个客户端在获得锁后因崩溃或其他原因未能释放锁，导致其他客户端永久等待的情况。
- 锁超时时间不应过长，以避免资源长时间不可用；同时也不应过短，以防锁在操作完成前过期。

**锁续租**

- 对于预计执行时间较长的操作，可以实现一个**锁续租**机制。客户端定期发送续租请求，以延长锁的超时时间，直至操作完成。
- 这要求客户端能够检测自身状态，一旦发现自己无法完成操作（比如因为崩溃或网络问题），就不再续租。

**设置获取锁的超时时间**

- 当一个客户端尝试获取锁时，应该设置一个合理的超时时间。如果在超时时间内未能获取锁，则放弃，这样可以避免无限等待。
- 超时时间的设定应根据业务场景和操作的紧急程度来决定。

**使用心跳机制**

- 类似于锁续租，心跳机制可以用来检测持有锁的客户端是否仍然活跃。客户端定期发送心跳信号，如果在预定时间内未收到心跳，系统可以认为客户端已经失效，自动释放锁。
- 心跳机制需要额外的机制来跟踪和管理心跳状态，可能会增加系统的复杂度。

**采用现有的分布式锁实现**

- 使用成熟的分布式锁库，如 Redisson（Java）、RedLock 等，这些库通常已经考虑了上述问题，并提供了解决方案。
- 这些实现通常包括锁的自动续租、锁获取超时、锁释放保证等特性，减少了开发和维护自定义解决方案的复杂度。

**失败重试机制**

- 对于因锁获取失败的操作，实现一个具有退避策略的重试机制，例如，使用指数退避策略逐渐增加重试间隔。
- 重试机制能够在不影响系统整体性能的前提下，提高资源利用率和操作成功率。

综上所述，设计一个既快速又安全的分布式锁机制，需要综合考虑锁的超时、续租、心跳和获取策略，同时利用现有的成熟实现可以大大减少开发的难度和潜在的风险。

**分布式锁解决了什么单机锁不能解决的问题**（没答到点上）

分布式锁解决了在分布式系统环境下资源访问冲突的问题，这是单机锁在分布式场景中无法解决的。以下是分布式锁能够解决的一些关键问题，而单机锁则不能：

1. **多进程/多服务实例之间的资源同步**  
在分布式系统中，可能有多个进程或服务实例需要同时访问和修改共享资源（比如数据库记录或文件）。单机锁只能在单个进程或服务器上同步访问，而无法跨多个进程或多个服务器实例工作。分布式锁能够跨不同的进程和服务器实例提供一致的资源访问控制。

2. **故障容错和高可用性**  
分布式系统设计时需要考虑节点故障的情况。单机锁无法处理节点故障后的锁恢复和转移问题。分布式锁通常结合分布式存储（如 Redis、Zookeeper 等）实现，能够保证即使某些节点发生故障，锁的状态也能够被其他节点访问和管理，从而提高了系统的可用性和容错性。

3. **分布式事务**  
在处理分布式事务时，需要协调多个系统或服务之间的操作，以确保数据的一致性。分布式锁可以用来同步各个系统间的操作，确保在一个分布式事务中，相关的操作要么全部成功，要么全部失败，这是单机锁无法实现的。

4. **跨数据中心的资源同步**

随着云计算的普及，应用可能部署在不同的数据中心或地理位置。分布式锁可以跨数据中心工作，确保全球范围内的应用实例能够安全地访问和修改共享资源。

1. **动态集群成员管理**

分布式系统中的节点和服务实例可能会动态变化（例如，通过自动扩缩容）。分布式锁能够动态地适应这种变化，无需人工干预即可在新的节点间同步状态和数据。

总之，分布式锁通过在多节点、多服务实例间提供一致和同步的访问控制，解决了分布式环境中的并发和同步问题，提高了系统的稳定性和可靠性。这是在分布式系统架构中，单机锁所无法达到的。

**Redis Cluster**

### 数据结构

聊聊链表和二叉树的区别，插入，搜索方面

10min

### 算法

**一个二叉树从树的右边看，看到的值是哪些**

```go
		if depth == len(res) {
			res = append(res, node.Val)
		}
```

作者：lustresix  
链接：[https://www.nowcoder.com/discuss/567019741512990720?sourceSSR=search](https://www.nowcoder.com/discuss/567019741512990720?sourceSSR=search)  
来源：牛客网

## 滴滴 秋招 网约车 后端开发 一二面（凉经）

### 一面 10.12（43min）

- MySQL 性能慢的原因

MySQL 数据库性能问题可以由多种因素引起，通常涉及到查询效率、服务器配置、数据设计等多个层面。以下是一些常见的导致 MySQL 性能慢的原因：

1. 未优化的查询
- **复杂查询**：复杂的 SQL 语句或子查询可能会导致数据库执行缓慢。
- **没有使用索引**：未正确使用索引导致数据库进行全表扫描，大大增加了查询时间。
- **索引未命中**：即使创建了索引，也可能因为查询方式不当（如使用了前置通配符）导致索引未被有效利用。

1. 索引问题
- **索引过多**：过多的索引会增加写入操作的负担，因为每次写入都需要更新所有的索引。
- **索引设计不当**：不恰当的索引（如选择了错误的列作为索引）可能不会被查询有效利用。
- **未使用最合适的索引类型**：比如，在某些场景下前缀索引、全文索引或空间索引可能更适合。

1. 服务器配置不当
- **内存不足**：对于缓存、索引等内存使用不足，导致频繁的磁盘 I/O 操作。
- **配置参数不当**：如缓冲池大小（buffer pool）、线程数等未根据硬件和负载适当调整。

1. 数据库设计
- **表结构设计不合理**：如过度使用 NULL 字段、数据类型选择不当（例如，使用过大的数据类型）。
- **没有归档老旧数据**：随着数据量的增加，老旧数据如果不进行归档，会导致查询性能下降。

1. 服务器硬件限制
- **磁盘 I/O 瓶颈**：磁盘速度慢或磁盘 I/O 高，特别是在高并发写入时。
- **CPU 性能限制**：高复杂度查询或高并发请求导致 CPU 瓶颈。

1. 并发处理不当
- **锁竞争**：大量并发事务争抢锁资源，导致部分事务等待锁释放。
- **事务处理时间过长**：长事务不仅占用资源，还可能阻塞其他事务的执行。

1. 网络问题
- **网络延迟**：数据库服务器和应用服务器之间的网络延迟高，影响数据传输速度。

解决策略

- **优化 SQL 查询和索引**：定期审查和优化查询语句，合理设计和使用索引。
- **调整数据库配置**：根据具体的工作负载和硬件条件调整 MySQL 的配置。
- **硬件升级**：考虑升级硬件，如使用更快的磁盘、增加内存。
- **数据库归档和分片**：定期归档不常用的数据，考虑对大表进行分片处理，降低单个查询的数据量。
- **使用缓存**：对频繁读取但不经常更改的数据使用应用层缓存，如 Redis、Memcached 等。

通过综合分析和逐一排查这些潜在的问题点，可以有效地定位并解决 MySQL 性能慢的根本原因。

- **联合索引 (a, b, c)，where b = 1，能走吗，where a = 1，能走吗**
- **MySQL 索引原理**
- **B+ 树更扁 有什么好处**
- **InnoDB 默认隔离级别**
- **可重复读级别是怎么实现的**

在数据库事务中，可重复读（Repeatable Read）是一种隔离级别，旨在确保在同一事务内多次读取同一数据集时，结果保持一致，即使在这期间其他事务也在对数据进行修改。MySQL 的 InnoDB 存储引擎默认使用这个隔离级别。可重复读级别主要通过以下机制实现：

1. 多版本并发控制（MVCC）  
MVCC 是实现可重复读隔离级别的关键技术。它允许在不锁定整个表的情况下，执行读取操作，从而提高并发性。每当一个事务更新一行数据时，InnoDB 会保留原始数据的快照版本。当其他事务请求读取相同数据时，根据它们各自的事务版本号，InnoDB 能够提供一个一致的视图，即使数据已经被另一个事务更改。

2. 一致性读  
在可重复读隔离级别下，普通的 SELECT 操作执行的是一致性读。这意味着读取操作可以看到事务开始时刻的数据快照，并且这些读操作不会看到其他事务在此期间所做的更改。这种读取不会阻塞其他事务对这些数据行的写操作，也不会被其他事务的写操作阻塞。

3. Next-Key Locks  
为了防止幻读（即当一个事务在读取某个范围内的记录时，另一个事务插入了一个新的记录），InnoDB 在可重复读隔离级别下使用了 Next-Key Locks。Next-Key Locks 是记录锁（行锁）和间隙锁（防止其他事务插入或修改当前读取范围内的数据）的组合。这确保了在同一事务内，即使有新的数据插入，读取范围的结果也不会改变。

4. Undo 日志  
InnoDB 使用 Undo 日志来支持数据的旧版本。当事务需要读取的数据已经被其他事务修改时，它可以通过 Undo 日志来访问该数据的早期版本，以维持操作的一致性。

5. 锁定读  
在需要的情况下（如 SELECT FOR UPDATE），事务可以执行锁定读，这会对选定的数据行加上排他锁。虽然这与可重复读的非锁定原则相违背，但它提供了在需要时强制数据一致性的能力。

通过结合使用 MVCC、一致性读、Next-Key Locks 和 Undo 日志，可重复读隔离级别能够在允许高度并发的同时，确保数据的一致性和隔离性。然而，它也可能导致一些特定的问题，如事务依赖的历史数据量可能会增长，影响性能。因此，数据库的运维人员需要根据实际情况调整参数，以平衡一致性、隔离性和性能。

- 限流算法
- 手撕
    - **力扣 92.反转链表 II**
    - **力扣 53.最大子数组和**
- Redis 持久化
- **AOF 文件存储的是什么类型的数据**
- 反问

### 二面 10.12（50min）

- **Go 协程模型**
- **协程创建过程**（启动 main 函数初始化，它会创建哪些协程、哪些 G、哪些 M、哪些 P、队列是什么时候创建的、全局队列是什么时候创建的）
    - 这块不会，跟面试官说我是主 Java 的，然后问了我线程池的创建过程

在 Go 语言中，协程（Goroutine）、线程（M）、调度器上下文（P）、以及各种队列的创建和初始化过程涉及 Go 运行时的内部机制。下面是这一过程的概述，包括在启动时发生的事情：

**启动过程**

当一个 Go 程序启动时，它会初始化运行时（runtime），这包括创建调度器（scheduler）的必要组件：M（OS 线程），P（处理器或调度器上下文），G（Goroutine）以及相关的队列。

1. **main Goroutine（G）**：程序开始运行时，首先会创建一个主 Goroutine 来执行 `main` 函数。
2. **M（机器或线程）**：运行主 Goroutine 的是一个操作系统线程，称为 M。在程序启动时，至少会有一个 M 被创建，它负责执行第一个 Goroutine。
3. **P（处理器）**：P 代表了运行时对操作系统线程的虚拟化，它包含了运行 Goroutines 所需的资源。在程序启动时，Go 运行时根据 `GOMAXPROCS` 的设置值初始化 P 的数量。默认情况下，`GOMAXPROCS` 的值是机器上的 CPU 核心数，但可以通过环境变量或在运行时通过调用 `runtime.GOMAXPROCS` 函数来修改。
4. **队列**：
   - **本地运行队列（Local Run Queue）**：每个 P 都有自己的本地运行队列，用于存储与这个 P 关联的 Goroutines。这些队列在 P 创建时初始化。
   - **全局运行队列（Global Run Queue）**：所有没有被分配给某个 P 的 Goroutines 会被放到全局运行队列中。这个队列在运行时初始化，并在必要时被 P 从中取出 Goroutines 来执行。
   - **Netpoller 队列**：用于等待网络 I/O 操作的 Goroutines。当 Goroutines 执行网络 I/O 操作且等待数据时，它们会被移到 Netpoller 队列。一旦 I/O 操作准备就绪，这些 Goroutines 会被移动回本地或全局运行队列，等待重新被调度。
5. **创建过程**：
   - 在程序初始化阶段，Go 运行时会设置初始的 M、P、全局队列，并创建主 Goroutine。
   - 主 Goroutine（执行 `main` 函数）开始在初始的 M 上执行。
   - 根据 `GOMAXPROCS` 的值，创建相应数量的 P，每个 P 都可以关联一个活跃的 M 来执行 Goroutine。
   - 全局运行队列和每个 P 的本地运行队列在这个过程中被初始化。  
**结论**

Go 程序的启动过程包括初始化运行时环境、创建主 Goroutine、分配初始的 M 和 P，以及初始化各种队列。这个过程设计到复杂的内部机制，使得 Go 程序能够高效地调度和执行数以千计的 Goroutines。通过运行时的调度器，Go 既支持了并发（concurrency）也支持了并行（parallelism），使得开发高效、可扩展的并发程序变得简单。

- 线程池中的线程，工作的时候是什么状态，不工作的时候是什么状态
- 线程在什么场景下会变为 `Blocked` 状态
- **线程 进程区别**
- **可达性分析算法**
- 除了可达性分析算法还有什么标记法
- TCP 怎么保证可靠性
- 超时重传，时间设置不当会有什么问题
- 滑动窗口 接收方窗口过大会有什么影响
- MySQL 事务，读已提交、可重复读
- 手撕
    - **力扣 33. 搜索旋转排序数组**
    - **力扣 300. 最长递增子序列**
- 反问

> 手撕最后一道没撕出来，直接秒挂了。写成了最长连续递增子序列，太扯淡了..

> 每轮面试 2 道手撕，没顶住呀。

作者：海苔 ___  
链接：[https://www.nowcoder.com/discuss/567296604001009664?sourceSSR=search](https://www.nowcoder.com/discuss/567296604001009664?sourceSSR=search)  
来源：牛客网

## Tag

## 百度二面

百度实习二轮面试

好消息，一面过了，坏消息，二面更炸

### 纯聊天

5min

为什么来北京

未来职业规划

非常轻松

### Golang 相关

10min

**GMP 的底层实现**

**map 的底层实现**

**扩容，缩容的流程**（缩容不太懂）

锁的底层原理 #不懂

![[Snipaste/Pasted image 20240312162108.png]]

**设计一个并发安全的 map**

设计一个并发安全的 `map` 需要确保在多个 goroutine 同时对 `map` 进行读写操作时，不会发生数据竞争或其他并发问题。Go 语言标准库中的 `sync.Map` 提供了一个并发安全的 `map` 实现，但了解如何手动实现一个可以提供有价值的学习经验。以下是一个简单的并发安全 `map` 的实现，使用了 `sync.RWMutex` 来提供读写锁定功能：

```go
package main

import (
    "sync"
)

// ConcurrentMap 是一个并发安全的map
type ConcurrentMap struct {
    m    map[string]interface{} // 基础的map结构
    lock sync.RWMutex           // 读写锁
}

// NewConcurrentMap 创建并返回一个新的ConcurrentMap
func NewConcurrentMap() *ConcurrentMap {
    return &ConcurrentMap{
        m: make(map[string]interface{}),
    }
}

// Set 设置一个键值对，如果键已存在则覆盖其值
func (cm *ConcurrentMap) Set(key string, value interface{}) {
    cm.lock.Lock()         // 在修改之前加写锁
    defer cm.lock.Unlock() // 方法返回前释放写锁
    cm.m[key] = value
}

// Get 返回给定键的值和一个布尔值，指示键是否存在
func (cm *ConcurrentMap) Get(key string) (interface{}, bool) {
    cm.lock.RLock()         // 在读取之前加读锁
    defer cm.lock.RUnlock() // 方法返回前释放读锁
    value, ok := cm.m[key]
    return value, ok
}

// Delete 删除给定的键及其对应的值
func (cm *ConcurrentMap) Delete(key string) {
    cm.lock.Lock()         // 在删除之前加写锁
    defer cm.lock.Unlock() // 方法返回前释放写锁
    delete(cm.m, key)
}

// Size 返回map中键值对的数量
func (cm *ConcurrentMap) Size() int {
    cm.lock.RLock()         // 在获取大小之前加读锁
    defer cm.lock.RUnlock() // 方法返回前释放读锁
    return len(cm.m)
}
```

这个实现使用了 `sync.RWMutex`，它是一个读写锁。这种锁允许多个读操作并发进行，但写操作会互斥，即在进行写操作时，不能有其他的读或写操作。这样设计可以在保证并发安全的同时，提高读操作的并发性能。

- 方法 `Set` 和 `Delete` 使用了 `Lock()` 和 `Unlock()` 方法来获取和释放写锁，保证了在写操作进行时，不会有其他的读或写操作干扰。
- 方法 `Get` 和 `Size` 使用了 `RLock()` 和 `RUnlock()` 方法来获取和释放读锁，允许多个读操作同时进行，但如果有写操作，读操作将等待写操作完成。

这个简单的实现展示了如何利用读写锁来创建一个并发安全的 `map`。在实际应用中，你可以根据需要扩展这个基本的结构，添加更多的功能和优化。

**你知道泛型吗，和 interface 的区别**

是的，泛型（Generics）是编程语言中的一个特性，允许在定义函数、类型或结构时不指定具体的数据类型，而是在使用时指定。这可以提高代码的复用性和类型安全性。Go 语言从版本 1.18 开始正式引入了泛型支持，标志着 Go 语言在类型系统上的一个重大进步。

**泛型的主要优点**

1. **类型安全**：泛型允许在编译时检查类型，减少运行时的类型错误。
2. **代码复用**：通过泛型，可以写出更加通用的函数和数据结构，减少代码重复。

**泛型和接口（`interface{}`）的区别**

在 Go 中，`interface{}` 被用来实现在函数或结构体中使用任意类型，实现类似泛型的功能。但使用 `interface{}` 和泛型还是有明显区别的：

1. **类型安全**：使用 `interface{}` 缺乏类型安全。你需要在运行时通过类型断言来检查和转换类型，这增加了运行时的开销和出错的可能。而泛型在编译时就确定了类型，提高了类型安全和性能。
2. **性能**：使用 `interface{}` 通常涉及到运行时的类型断言和反射，这会带来性能开销。而泛型允许编译器在编译时生成具体类型的代码，避免了这些开销。
3. **可读性和易用性**：泛型代码相比使用 `interface{}` 的代码，更加清晰和易于理解。使用泛型，函数或数据结构的意图和类型约束更加明显。

**你写 golang 的时候遇到什么坑吗**

- **认真处理所有的错误**：不要忽视函数返回的错误。
- **使用 `go race` 检测并发问题**：在开发阶段使用它来帮助找到数据竞争。
- **理解并正确使用指针**：熟悉 Go 语言中指针的用法。
- **合理使用 `defer`**：理解 `defer` 的执行顺序，确保资源正确释放。
- **掌握 `go mod`**：使用 Go 模块来管理依赖。
- **谨慎使用 `interface{}`**：只在需要时使用，避免滥用。
- **区分 nil 切片和空切片**：根据实际需求选择使用它们。
- **深入理解并发模型**：正确地使用 goroutines 和 channels，避免常见的并发问题。
- 在为 nil 的 channel 上发送和接收数据将会永远阻塞
- 对于 defer 延迟执行的函数，传参在声明的时候就会求出具体值，而不是在执行时才求值。
- 在 Python 和 C/C++ 等语言中，数组类型做为函数传参时，相当于传递了数组内存地址的引用，在函数内可以更改原数组的值。但是在 Golang 中，数组类型做为函数传参时是进行的值拷贝，在函数内部无法更改原数组的值。
	- 如果用的是 slice，虽然在传参是也是值拷贝，但是拷贝的是引用，指向的还是相同的一片内存。因此可以更新原 slice 的值。
- 将元素放到 slice, map 中是进行的值拷贝，这意味着更改原始元素不会影响 slice, map 中的元素。
- 可借助 github.com/shopspring/decimal 包来实现更加高的精度
- https://coders.run/golang%E8%B8%A9%E5%9D%91%E9%9B%86%E9%94%A6/

### 计算机网络

5min

**从输入域名到返回页面的全部流程**

从在浏览器中输入域名到显示网页的全过程涉及多个步骤，每个步骤都是整个网络通信过程中不可或缺的一环。下面是这个过程的简化描述：

1. DNS 查询
	- **域名解析**：浏览器首先需要将你输入的域名（如 `www.example.com`）转换成 IP 地址。这是通过向 DNS（域名系统）服务器进行查询完成的。如果这个域名的 IP 地址在浏览器或操作系统的缓存中找不到，浏览器会向配置的 DNS 服务器发送一个请求来解析这个域名。
2. TCP 连接
	- **建立连接**：浏览器获得目标服务器的 IP 地址后，会尝试与服务器建立一个 TCP 连接（对于 HTTPS 网站，还会进行 TLS 握手），这通常涉及到三次握手过程。
3. 发送 HTTP 请求
	- **构造请求**：浏览器构造一个 HTTP（或 HTTPS）请求。请求中包含了请求方法（如 GET）、请求的资源路径、协议版本以及可能包含的头信息等。
	- **发送请求**：浏览器通过建立的 TCP 连接向服务器发送这个 HTTP 请求。
4. 服务器处理请求并返回响应
	- **服务器接收请求**：服务器接收到请求后，会根据请求的路径、方法等信息处理请求，可能涉及到查询数据库、执行后端逻辑等操作。
	- **服务器发送响应**：处理完请求后，服务器会向浏览器返回一个 HTTP 响应，响应中包含了响应码（如 200 OK）、响应头信息以及响应体（即请求的资源内容）。
5. 浏览器处理响应
	- **渲染页面**：浏览器接收到服务器的响应数据后，会根据响应体中的 HTML 内容开始渲染页面。
	- **请求额外资源**：如果 HTML 中包含了额外的资源（如 CSS 文件、JavaScript 文件、图片等），浏览器会再次发起 HTTP 请求去获取这些资源。
	- **执行 JavaScript**：页面中的 JavaScript 会被浏览器执行，可能会修改 DOM、动态加载新内容等。
6. **显示页面**
	- 当 HTML 和所有被引用的资源都被下载、解析和渲染后，最终的页面会显示在浏览器窗口中。

这个过程涉及到许多底层网络协议和浏览器的内部机制，包括但不限于 DNS 解析、TCP/IP 通信、HTTP 协议规范、SSL/TLS 加密、HTML/CSS/JavaScript 的解析和渲染等。每个步骤都是整个网页加载过程中重要的环节，任何一个环节的延迟或失败都可能影响到最终页面的加载时间和显示效果。

**负载均衡的策略**（不会）

**限流的例子**  

日常的业务上有类似秒杀活动、双十一大促或者突发新闻等场景，用户的流量突增，后端服务的处理能力是有限的，如果不能处理好突发流量，后端服务很容易就被打垮，导致整个系统崩溃！

亦或是爬虫等不正常流量，我们对外暴露的服务都要以最大恶意去防备我们的调用者。我们不清楚调用者会如何调用我们的服务。假设某个调用者开几十个线程一天二十四小时疯狂调用你的服务，不做啥处理咱服务也算完了。更胜的还有 DDos 攻击。

### 设计

5min

**设计一个好友系统，要什么技术**（答得非常不好）

设计一个好友系统，例如用于社交网络或游戏中的好友功能，需要考虑多个技术和架构层面的方面。以下是实现好友系统时可能涉及到的关键技术和设计考虑：

1. 数据库设计
	- **关系型数据库**（如 PostgreSQL, MySQL）：适用于存储用户信息、好友关系等结构化数据。需要设计合理的数据模型来支持快速查询、添加、删除好友等操作。
	- **非关系型数据库**（如 MongoDB, Redis）：适用于存储大量非结构化数据，如用户活动、消息记录等。Redis 可用于实现高效的在线状态检查。
2. 数据模型设计
	- **好友关系模型**：通常用两种方式之一来建模好友关系：双向关系模型（每个好友关系作为两条记录存储）或单向关系模型（一条记录表示双方关系）。双向模型查询简单，但更新复杂；单向模型相反。
	- **索引优化**：为常用查询路径（如用户 ID）添加索引，以加快查询速度。
3. API 设计
	- **RESTful API**：设计 RESTful API 以供前端或移动应用调用，实现好友列表展示、好友添加/删除、好友推荐等功能。
	- **WebSocket**：实现实时通信功能，如在线状态更新、即时消息等。
4. 缓存策略
	- **缓存层**：使用缓存（如 Redis）减轻数据库负担，缓存热点数据，如用户的好友列表、在线状态等，以提高读取速度。
5. 安全性考虑
	- **身份验证和授权**：确保用户身份验证机制（如 OAuth 2.0、JWT）安全可靠，只允许用户访问其自己的数据和好友数据。
	- **数据加密**：在存储和传输敏感信息（如私密消息）时使用加密技术。
6. 可扩展性和高可用性
	- **微服务架构**：考虑采用微服务架构分离好友系统的不同组件（如用户服务、好友关系服务、消息服务），便于独立扩展和维护。
	- **负载均衡和冗余**：使用负载均衡器分配流量，确保服务在高负载下的可用性。
7. 好友推荐算法
	- **机器学习**：采用机器学习算法分析用户行为、兴趣等数据，提供个性化的好友推荐。

**技术栈示例**

- 前端：React / Vue.js（Web）、Swift（iOS）、Kotlin（Android）
- 后端：Node.js / Go / Java
- 数据库：PostgreSQL / MySQL（关系型）、MongoDB / Redis（非关系型）
- API 通信：REST / GraphQL
- 实时通信：WebSocket
- 身份验证：OAuth 2.0 / JWT
- 云服务和部署：Docker / Kubernetes、AWS / Google Cloud / Azure

设计好友系统时，选择哪些技术和架构取决于系统的规模、预期的用户数量、功能需求以及团队的技术栈偏好。建议从简单开始，根据系统的成长和需求逐步迭代和优化架构。

**如何保证 redis 双写一致**

在分布式系统中，保证缓存（如 Redis）与数据库的双写一致性是一个常见的挑战。双写一致性问题主要出现在同时更新缓存和数据库时，如何保证两者的数据一致性。下面是一些常用的策略来保证 Redis 缓存与数据库的双写一致性：

1. 延迟双写
	- **更新数据库，延迟更新缓存**：首先更新数据库，然后使用消息队列等机制异步更新缓存。这种方式可以减少因直接更新缓存导致的不一致问题，但可能会有短暂的数据不一致期。
2. 先删除缓存，后更新数据库
	- **删除缓存**：在更新数据库之前或之后立即删除缓存中的旧值。
	- **数据库更新**：更新数据库中的数据。
	- **延迟重新缓存**：更新数据库成功后，可以等待下一次读操作时再将数据缓存，或使用后台任务异步预热缓存。  
	这种策略的关键是确保删除缓存操作成功执行。如果删除缓存失败，需要有回滚或重试机制。
3. 先更新数据库，后更新缓存
	- **数据库更新**：首先更新数据库中的数据。
	- **更新缓存**：数据库更新成功后，再更新缓存中的数据。  
	这种策略的风险在于，如果在更新数据库和更新缓存之间有新的读请求，可能会读取到旧的缓存数据，并且这个旧数据可能被重新设置缓存，导致数据不一致。
4. 使用事务或分布式锁
	- **事务**：如果数据库支持事务，可以在事务中同时执行数据库更新和缓存更新操作，确保二者的原子性。
	- **分布式锁**：使用分布式锁来锁定正在操作的数据项，直到缓存和数据库更新都完成。这可以防止在更新过程中其他操作干扰数据一致性。
5. 最终一致性  
	在某些场景下，接受短暂的数据不一致，采用最终一致性模型。通过设计系统使得数据最终能够达到一致状态，比如通过定期同步缓存和数据库的数据。

- 注意事项
	- **监控和报警**：设置监控和报警，及时发现数据不一致的情况。
	- **一致性级别**：根据业务需求选择合适的一致性级别，不同的场景可能对数据一致性的要求不同。
	- **测试和验证**：在生产环境部署前，通过压力测试和故障注入等方式充分测试双写方案，确保其在各种条件下都能保持一致性。

保证 Redis 双写一致性需要综合考虑系统的特点和业务需求，不存在一劳永逸的解决方案。在实际应用中，可能需要结合多种策略来达到最优的效果。

### Gin 框架的底层实现是什么（只知道中间件和路由前缀树）**

Gin 是一个用 Go 语言编写的 Web 框架，因其高性能和易用性而受到广泛欢迎。Gin 的底层实现依赖于 Go 语言的标准库，特别是 `net/http` 包，同时它通过一系列的设计和优化，提供了比 Go 标准库更为高效和灵活的功能。下面是 Gin 框架一些关键的底层实现细节：

#### 1. 基于 `net/http` 包

Gin 的底层 HTTP 监听和处理基于 Go 语言的 `net/http` 包。Gin 的 `Engine` 结构体实现了 `http.Handler` 接口，使得它可以与 Go 的 HTTP 服务器兼容。

```go
func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) {
    // 处理请求
}
```

#### 2. 路由

Gin 使用自定义的路由机制，而不是直接使用 `net/http` 的默认多路复用器（ServeMux）。Gin 的路由使用基数树（Radix Tree）来实现，这使得路由匹配更加高效，尤其是对于具有大量路由规则的应用程序。

#### 3. 中间件

Gin 提供了中间件支持，允许在处理请求前后执行额外的处理逻辑（如日志记录、身份验证等）。Gin 中的中间件也是利用 Go 的函数作为一等公民的特性来实现的，中间件可以被视为包装在 HTTP 处理函数外层的函数。

```go
func Middleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 中间件逻辑
        c.Next() // 调用下一个中间件或请求处理函数
    }
}
```

#### 4. 上下文（Context）

Gin 为每个请求提供了一个 `Context` 对象，这是它处理请求的核心。`Context` 封装了 Go 原生的 `http.Request` 和 `http.ResponseWriter`，并提供了一系列方便的方法来读取请求数据、设置响应数据、管理中间件流程等。

#### 5. 性能优化

Gin 对性能做了许多优化，包括但不限于：

- **零内存分配的路由**：Gin 的路由设计最小化了内存分配，减少了垃圾回收的压力。
- **快速的 HTTP 参数解析**：Gin 提供了高效的方式来解析 QueryString、Form 数据和 JSON 体等。
- **Context 对象池**：Gin 使用 `sync.Pool` 来复用 `Context` 对象，减少每个请求的内存分配。

#### 结论

Gin 框架通过高效的路由算法、中间件机制、上下文管理以及对 Go 标准库的有效利用，提供了一个轻量级、高性能且易于使用的 Web 开发框架。通过这些设计和实现，Gin 能够支持构建高效且可维护的 Web 应用。

### 算法

5min

**两数之和**

### 总结

这次时间非常短，30 几分钟不到，面试官非常和气，我说不会都是笑着说没事可以学的那种，（但是估计心里想的是怎么会有这种 sb），虽然感觉又寄了但是面试体验很好，一点都不紧张，哎，只能说技不如人是这样的。二面项目完全没问，感觉就是层次上了一个台阶真正开始问素养方面了，，，还得多练

作者：lustresix  
链接：[https://www.nowcoder.com/discuss/567743711845560320?sourceSSR=search](https://www.nowcoder.com/discuss/567743711845560320?sourceSSR=search)  
来源：牛客网

## 字节暑期实习二面面经

1. **gc 垃圾回收算法**  
2. **Golang 设计模式: 举例说明** [[../../../Basic/设计模式/Go 设计模式/Go 设计模式索引|Go 设计模式索引]]
3. **手撕算法，需要手写输入输出实例 字符串的最长不重复子串长度**(滑动窗口或者动态规划都可以实现)  
4. 你觉得秒杀有什么难解决的技术难点？(我没做过秒杀项目嘤嘤嘤不知道面试官为什么问秒杀相关 只蒙了应该有瞬间高并发问题和库存数据一致性的问题)  

秒杀系统是电商等平台用来处理大量用户在极短时间内对限量商品的抢购请求的系统。由于其特殊性，秒杀系统面临着一系列技术难点和挑战：

### 秒杀

#### 1. 高并发请求处理

- 秒杀活动通常在短时间内吸引大量用户参与，系统需要能够处理高达数万到数百万级别的并发请求。
- 解决方案包括使用高性能的服务器、负载均衡、分布式缓存等技术来分散请求压力。

#### 2. 系统性能和稳定性

- 在面对极高的请求量时，系统必须保持高性能和稳定性，避免崩溃。
- 采用优化的数据库访问策略、合理的缓存策略、限流和降级等手段来确保系统稳定运行。

#### 3. 库存超卖

- 秒杀系统需要准确控制库存，避免因为并发导致的超卖现象。
- 通常使用乐观锁、数据库事务、消息队列等技术来保证库存的一致性和正确性。

#### 4. 用户体验

- 用户在参与秒杀时期望能有公平、及时的反馈。
- 系统需要合理安排用户的请求处理顺序，使用异步处理、页面静态化等技术提高用户体验。

#### 5. 安全问题

- 秒杀活动可能会吸引恶意用户利用脚本、抢购机器人等自动化工具参与秒杀，影响正常用户的权益。
- 通过验证码、行为分析、IP 限制等手段来识别和阻止恶意请求。

#### 6. 数据一致性

- 在分布式系统中，保证数据在各个组件之间的一致性是一个挑战。
- 可以采用分布式事务、最终一致性等策略来确保数据的一致性。

#### 7. 流量削峰

- 秒杀活动开始时用户的请求量会出现短时间的剧增，给系统带来巨大压力。
- 通过引入消息队列、预售卷、分时秒杀等策略来平滑流量峰值，避免系统过载。

#### 8. 快速失败和自我保护

- 在极端情况下，系统可能需要舍弃部分请求以保护自身不被压垮。
- 实现快速失败机制和自我保护策略，如设置超时、限流降级等，确保系统核心功能的稳定。

综上所述，设计和实现一个高效、稳定、公平的秒杀系统需要综合考虑众多因素，采取相应的技术和架构策略。随着技术的发展，还会有更多的解决方案被提出来应对这些挑战。

**解决库存超卖的问题**

解决库存超卖的问题是电商和秒杀系统等需要精确控制库存的场景中的一个关键挑战。以下是一些常见的策略和技术手段：

1. 使用乐观锁  
乐观锁基于数据版本控制的原理，每次更新库存前，检查当前库存的版本号是否与读取时的版本号一致，如果一致则进行更新并将版本号加一，否则放弃更新。这种方法可以避免在高并发情况下的数据冲突，从而防止超卖。
2. 悲观锁  
悲观锁直接在数据库上锁定正在操作的资源，直到事务完成。虽然悲观锁能有效避免超卖，但它会显著降低系统的并发性能，因此需要谨慎使用。
3. 基于 Redis 的库存控制  
将库存数量存储在 Redis 这类内存数据库中，利用 Redis 原子操作如 `DECRBY` 来减少库存。Redis 的操作是原子性的，可以有效避免超卖问题。但需要考虑的是如何同步 Redis 中的库存状态到持久化数据库中，以及在操作失败时如何回滚。
4. 消息队列  
使用消息队列处理库存扣减请求，确保每次只有一个请求操作库存，通过队列的先进先出特性来控制并发访问，减少超卖风险。但这种方法可能会增加用户等待时间。
5. 预扣库存  
在用户下单前，先预扣除库存，然后再进行后续的订单处理流程。如果订单处理失败或者在一定时间内未能完成支付，则释放预扣的库存。这种方法可以有效避免超卖，但需要合理设置库存释放策略。
6. 分布式锁  
在更新库存前，通过分布式锁确保同一时间只有一个请求能操作库存。这可以用在分布式系统中保证操作的原子性。分布式锁可以通过 Redis、ZooKeeper 等组件实现。
7. 数据库事务  
使用数据库事务确保库存更新操作的原子性。在事务中对库存进行检查和更新，可以防止并发请求导致的数据不一致问题。但在高并发场景下，过多的事务可能会导致数据库性能瓶颈。

作者：重金属音乐爱好者  
链接：[https://www.nowcoder.com/feed/main/detail/007df2c150b84121b10d470de49ad3c8?sourceSSR=search](https://www.nowcoder.com/feed/main/detail/007df2c150b84121b10d470de49ad3c8?sourceSSR=search)  
来源：牛客网

## 京东 Golang 开发面经 （挂 Go 掌握程度不足）

### 一面 9.16 60min

- **数据结构**
- **go 语言的 map**
- **拉链法的优缺点**

优点

1. **处理冲突简单**
2. **动态扩展**
3. **链表优化**：链表可以被其他高效的数据结构（如红黑树）替换以提高查找效率，这在 Java 8 的 HashMap 实现中得到了应用。
4. **负载因子较高时仍能工作**
5. **删除操作简单**

缺点

1. **内存使用较多**：每个元素都需要额外的空间来存储指向链表中下一个元素的指针（或引用）。
2. **缓存性能不佳**：链表的节点可能在内存中分布不连续，导致较差的缓存局部性（Cache Locality），影响性能。
3. **平均查找时间较长**。
4. **链表操作开销**

### **拉链法如何优化**

拉链法作为解决哈希表冲突的一种常用方法，虽然简单且有效，但在处理大量数据或高并发场景时可能面临性能瓶颈。以下是几种对拉链法进行优化的策略：

#### 1. 使用更高效的链表结构

- **平衡树**：当链表变得较长时，可以将链表转换为平衡二叉树（如红黑树）或跳表，这些数据结构的查找、插入和删除操作的时间复杂度为 \(O(\log n)\)，可以显著提高长链表的操作效率。Java 8 的 `HashMap` 就采用了这种优化策略。
- **双向链表**：在需要频繁删除元素的场景中，使用双向链表可以简化删除操作，因为可以直接定位到前驱节点。

#### 2. 改进哈希函数

- **减少冲突**：设计一个良好的哈希函数，减少冲突的概率。理想的哈希函数应该能够将输入均匀分布到不同的桶中。
- **动态哈希**：实现动态调整哈希表大小的机制，根据元素数量动态增加哈希桶的数量，保持较低的装载因子，从而减少链表的平均长度。

#### 3. 分离溢出区

- 将哈希表分为主区和溢出区，所有哈希冲突的元素都存放在溢出区。这样可以保持主区的访问速度，对溢出区进行专门优化。

#### 4. 并发控制

- **细粒度锁**：在并发环境下，为每个链表（或桶）实现独立的锁（细粒度锁），而不是对整个哈希表加锁（粗粒度锁）。这样可以减少锁竞争，提高并发性能。
- **无锁设计**：考虑使用原子操作和无锁数据结构来管理链表，减少锁的开销，提高效率。

#### 5. 缓存优化

- **局部性优化**：考虑数据的存储方式和访问模式，尽量使经常一起访问的数据在内存中也相邻，以提高缓存命中率。

#### 6. 预分配内存

- 对于预知最大元素数量的场景，可以预先分配足够的哈希桶和链表节点，减少运行时内存分配和扩容操作的开销。

#### 7. 懒惰删除

- 在删除元素时，只标记该元素为已删除状态，而不立即从链表中移除。定期或在链表长度达到一定阈值时再进行实际的删除操作，以减少删除操作对性能的影响。

#### 8. 批量操作优化

- 对于批量插入、删除操作，可以采用批处理技术，如先计算出所有操作的最终结果，再一次性更新哈希表，减少中间状态的处理开销。

通过这些优化策略，可以显著提高拉链法在特定场景下的性能和效率，尤其是在处理大量数据和高并发请求时。然而，需要注意的是，每种优化策略都有其适用场景，选择和实施优化策略时应根据具体需求和约束进行权衡。

- 负载因子调到 1 会有什么后果
	- 空间利用率提高，但是发生冲突的可能性也增大了
- **数据库**
- **数据库索引有哪些**
- **sql 建表**  
	设计一张字生表：表需求是可以记录学生姓名、出生日明、手机 号、是否在读。邮箱。家庭地址、生表现评价 常见查询条件为姓名、出生日期、手机号、是否在读
- **这个表有什么缺陷**

### 新加一个学号字段要考虑什么

给已存在的数据表添加新字段是数据库维护和迭代中的常见操作。进行这样的操作时，需要综合考虑以下几个方面：

#### 1. 兼容性

- **向后兼容性**：确保新增字段不会破坏现有应用的功能。考虑现有的查询、报告或第三方应用是否会受到影响。
- **默认值**：为新字段指定一个合适的默认值，特别是当表中已经存在数据时。这样可以保证旧数据在新逻辑下仍然有效。

#### 2. 性能影响

- **索引考虑**：新增字段是否需要被索引？索引可以加速查询，但也会增加插入、更新和删除操作的开销。
- **表锁定**：在某些数据库系统中，添加新字段可能会在修改期间锁定整个表，这对于大表来说可能会导致显著的性能下降和服务不可用。

#### 3. 数据一致性

- **数据验证**：为新字段定义数据完整性约束，如数据类型、非空约束（NOT NULL）、唯一约束（UNIQUE）、检查约束（CHECK）等，确保数据的一致性和准确性。
- **外键关系**：如果新字段与其他表的字段有外键关系，需要定义外键约束，以维持数据的引用完整性。

#### 4. 数据迁移和更新

- **数据迁移**：考虑是否需要对现有数据进行迁移或转换，以适应新字段的添加。
- **批量更新**：如果新字段需要基于现有数据计算得出，考虑执行批量更新操作，并评估最佳的执行时间以减少对生产环境的影响。

#### 5. 应用代码修改

- **代码修改**：更新应用代码以包含对新字段的引用，包括模型定义、业务逻辑处理等。
- **API 变更**：如果应用提供 API 接口，考虑 API 的变更是否会影响到客户端，是否需要版本控制。

#### 6. 测试和部署

- **回滚计划**：在执行变更前，准备好回滚计划以应对变更失败的情况。
- **测试**：在开发或测试环境中先行测试变更，确保新字段的添加不会引入错误或异常。
- **监控**：在部署变更后，密切监控系统性能和应用日志，确保变更没有引入新的问题。

#### 7. 文档和沟通

- **文档更新**：更新相关文档，包括数据库模式、API 文档等。
- **团队沟通**：通知团队成员关于数据库变更的详情，尤其是对开发、测试和运维团队成员。

总的来说，给数据表添加新字段需要全面考虑影响并做好充分的准备，以确保变更的平滑实施和系统的稳定运行。

- **数据库四大特性**
- **innodb 默认隔离级别**
- **rr 是怎么实现的**
- 网络
- **tcp 三次握手**
- **ip 位于哪层？icmp 位于哪层？ping 命令位于哪层？**
	- **ip 网络层，icmp 网络层，ping 应用层**
- **telnet 是什么操作？位于哪层？**
	- **telnet 测试映射端口或远程访问主机，应用层**
- https 加密过程 (这个我不太清楚 如果有大佬知道 麻烦评论区指点一下)

### 二面 9.27 35mn

- **说一说对 slice 的认识

#### ****slice 如何做深拷贝**

在 Go 语言中，slice 是引用类型，这意味着当你将一个 slice 赋值给另一个变量时，两个变量实际上会指向同一块内存区域。因此，更改其中一个 slice 的内容会影响到另一个。为了避免这种情况，你需要进行深拷贝（deep copy），深拷贝会创建一个新的 slice，并将原始数据的值复制到新的 slice 中，这样原始 slice 和新的 slice 会在内存中占有不同的位置。

##### 实现深拷贝的方法

1. **使用 `copy` 函数**

   Go 语言标准库提供的 `copy` 函数可以用来复制 slice 的元素到一个新的 slice 中。

   ```go
   originalSlice := []int{1, 2, 3}
   newSlice := make([]int, len(originalSlice))
   copy(newSlice, originalSlice)
   ```

   这里，`make` 函数首先创建了一个与原始 slice 大小相同的新 slice，然后 `copy` 函数将 `originalSlice` 的所有元素复制到 `newSlice` 中。

2. **使用切片操作**

   你也可以通过切片操作创建一个新的 slice，并复制原始 slice 的元素。

   ```go
   originalSlice := []int{1, 2, 3}
   newSlice := append([]int(nil), originalSlice...)
   ```

   这里使用了 `append` 函数和切片操作符 `…` 来复制 `originalSlice` 的元素到一个新的 slice `newSlice` 中。

##### 注意事项

- 这些方法适用于 slice 中存储的是基本数据类型（如 `int`、`float`、`string` 等）。如果 slice 存储的是指针或包含指针的复杂结构体，上述方法只会复制指针值，而不是指针指向的数据。在这种情况下，你需要遍历 slice，并对每个元素进行深拷贝。
- 对于包含自定义结构体的 slice，如果结构体中没有指针或其他引用类型，上述方法仍然有效。否则，需要逐个元素进行深拷贝。

深拷贝确保了原始数据的修改不会影响到拷贝后的数据，这在处理共享数据或进行并发编程时尤其重要。

#### **如何避免回表**

在数据库设计和查询优化中，" 回表 "（Fetching）是指基于索引检索数据后，再次访问主表以获取完整记录的过程。回表操作主要发生在使用二级索引（非聚集索引）进行查询时，因为二级索引只包含索引的键值和指向主表记录的指针，并不包含行的全部数据。尽管回表是一个常见的操作，但在某些场景下，频繁的回表可能会导致性能问题。以下是几种避免或减少回表操作的策略：

##### 1. 使用覆盖索引

覆盖索引（Covering Index）是指一个索引包含了查询所需的所有数据字段，因此查询可以直接在索引上完成，无需回表到主表中获取数据。确保查询语句中的所有选取字段都包含在索引中，这样数据库引擎就可以直接返回索引中的数据，而不需要访问主表。

##### 2. 精心设计索引

精心设计索引，使其尽可能满足查询需求。这可能涉及到创建复合索引，即在单个索引中包含多个列，以支持对这些列的组合查询。复合索引的顺序也很重要，应该根据查询条件中列的使用频率和过滤能力来安排列的顺序。

##### 3. 查询优化

优化查询语句，避免不必要的列选取。只查询所需的数据列，尽量减少返回的数据量。如果可能，尝试修改查询逻辑，避免复杂的连接操作，特别是涉及大表的连接。

##### 4. 使用聚集索引

在一些数据库系统中（如 MySQL 的 InnoDB 存储引擎），表数据是按照聚集索引（Clustered Index）存储的。如果查询可以直接通过聚集索引完成，那么可以避免回表，因为聚集索引已经包含了完整的行数据。对于主键查询，通常不会发生回表。

##### 5. 控制表的规范化程度

过度规范化可能会导致查询时需要多次回表，特别是在进行多表连接查询时。适度的反规范化，例如通过在表中冗余一些经常一起查询的数据，可以减少查询的复杂度和回表的需要。但反规范化也需要谨慎使用，因为它可能增加数据维护的复杂性。

##### 6. 数据库选型和配置

选择合适的数据库和存储引擎，以及合理配置数据库参数，也可以在一定程度上影响和减少回表的性能开销。

避免或减少回表操作需要综合考虑索引设计、查询优化和数据模型设计等多个方面。在实际应用中，应根据具体的业务需求和数据库性能表现，通过测试和分析来选择最合适的优化策略。

- 标识性差的字段一定不能做索引列吗？
- 标识性差的字段为什么不能用来做索引列？
- **b 和 b+ 树的区别**
- **mysql 默认隔离级别**
- **rr 如何解决不可重复读**

作者：留不住的四月  
链接：[https://www.nowcoder.com/discuss/353158536559534080](https://www.nowcoder.com/discuss/353158536559534080)  
来源：牛客网

## 字节飞书 Golang 二面实习面经 (已 OC)

(应该是 g 了,easy 算法没做出来)

1. **算法 (手里一副扑克牌, 第一张放在桌面上,第二张放回手牌底部, 重复第一步直到手里没牌. 根据桌子上的牌, 推出手里的牌)**
2. 一面试完下来就秒了, 面试半小时找规律, 结果发现做错了
3. 讲讲线程、协程、进程区别  
线程、协程和进程是操作系统中处理并发和并行任务的关键抽象概念。它们各自有不同的特性和用途，理解它们之间的区别对于设计和实现高效的程序非常重要。  
**进程（Process）**
- **定义**：进程是操作系统进行资源分配和调度的基本单位。它是一个程序的实例，拥有独立的地址空间、内存、数据栈以及其他跟踪执行的辅助信息。
- **隔离性**：每个进程都在自己独立的地址空间执行，进程间通信（IPC）需要特定的机制，如管道、信号、共享内存、消息队列等。
- **用途**：适用于需要运行独立应用程序的场景，保证了应用程序之间的稳定性和安全性。  
**线程（Thread）**
- **定义**：线程是进程中的执行单元，是操作系统调度的最小单位。一个进程可以包含多个线程，它们共享进程的地址空间和资源，但每个线程有自己的执行栈和程序计数器。
- **隔离性**：线程之间共享同一个进程的资源，如内存和文件句柄，因此线程间的通信和数据共享相对容易，但也容易引起同步和数据一致性的问题。
- **用途**：适用于需要大量并行计算，而计算任务之间需要频繁交换数据或通信的应用场景。  
**协程（Coroutine）**
- **定义**：协程是一种用户态的轻量级线程，它的调度完全由用户控制，而非操作系统内核。协程依靠语言的运行时（Runtime）支持，提供了非抢占式的多任务并发执行的能力。
- **隔离性**：协程通常运行在同一个线程中，因此它们共享相同的地址空间和资源。协程之间的切换不需要操作系统的上下文切换，开销比线程小得多。
- **用途**：适用于 IO 密集型任务、需要大量并发的网络应用，如 Web 服务器、数据库操作等。协程能有效提高程序在并发处理上的效率。  
 **主要区别**
- **调度**：进程和线程的调度由操作系统负责，具有抢占式特性；协程的调度由程序逻辑控制，是协作式的。
- **开销**：进程 > 线程 > 协程。进程拥有独立的资源，创建和销毁的开销最大；线程共享进程资源，开销小于进程；协程在同一线程内切换，开销最小。
- **通信**：进程间通信需要 IPC 机制；线程间可以直接读写进程数据段（如全局变量）来进行通信；协程则依赖于特定的语言特性或库来实现通信。
- **并发性**：协程可以在单线程中实现大规模并发，对 IO 密集型应用尤其有效。  
	理解这些概念的区别有助于开发者根据应用的需要选择最适合的并发模型。
1. 讲讲你最喜欢哪个语言, 为什么 (ababa, 说了 go 比 java 以来管理简单,但是他说 maven 其实比 mod 强的不是一点)
2. 微服务的优点?对比单体的优点?(聊了十几分钟, 但是面试官都说这种单体其实也可以)
3. 每个业务单独开来,自己用自己的数据库, 高内聚 低耦合 服务分工明确 (那单体也可以划分模块呀?)
4. 可以实现多部署, 高可用 (单体也可以部署多个呀?)
5. 微服务, 如果一个服务挂了, 其余的服务还可以支持, 起码有容错 (我单体部署几百个,也可以呀?)
6. 分布式部署,对机器压力小 (我微服务分几个部署在我的机器上, 浪费资源不是更多吗?)
7. 其实如果真的服务器很少的话, 单体也可以, 看业务的体量和需求吧
8. 说到了负载均衡, 负载均衡有哪些技术?
9. **RR**
10. **哈希取模**
11. **一致性哈希**
12. 怎么实现负载均衡呢?
13. nginx
14. nginx 在哪里实现?
15. 网关服务
16. **nginx 在 osi 哪一层, 负载均衡在哪一层?**
17. 讲一下 golang 协程池, 作用是什么? (扯了 10 分钟, 感觉不符合面试官预期)
18. 资源复用 (但是 goroutine 本来就很轻, 感觉没有必要复用呀?)
19. 限制资源个数, 避免高并发过多 goroutine 冲垮服务器
20. 还有呢? 不知道了…
21. 输入 url 到渲染的总流程
22. 输出 10 分钟
23. 为什么二进制的文件到了客户端,浏览器可以看到多彩的画面
24. html?js?css?
25. **又给了一道巨简单的题目, 算是做出来了.**
26. **反问**
27. **学习的建议**

哎, 头痛一整天, 算法脑子又宕机, 字节 886 😭

面试官还是很和蔼的 0.0

----

11.18 接好运, 2 面已过, 我是字节的🐶

作者：Lewy 华  
链接：[https://www.nowcoder.com/discuss/554371366380650496](https://www.nowcoder.com/discuss/554371366380650496)  
来源：牛客网

## 字节飞书后端实习 Golang 一面面经

1. **手写 LRU**
2. **说一下 golang 协程调度**
3. 说一下如果你要设计一款 RPC 框架，你会如何设计
4. **看你说到了负载均衡，说一下一致性哈希**
5. **MySQL 的事务如何实现的**

MySQL 事务的实现依赖于其存储引擎，不同的存储引擎对事务的支持程度不同。InnoDB 是 MySQL 中默认的事务型存储引擎，它通过以下几个关键机制来实现事务：

### 1. 日志

- **重做日志（Redo Log）**：InnoDB 使用重做日志来确保事务的持久性。当事务提交时，其更改会先写入到重做日志中，并在适当的时候异步刷新到磁盘的数据文件。在系统崩溃后，重做日志可以用来恢复未写入磁盘的事务。
- **撤销日志（Undo Log）**：用于事务的回滚和多版本并发控制（MVCC）。撤销日志记录了事务发生之前的数据状态，如果事务需要回滚，InnoDB 会使用撤销日志来恢复数据。撤销日志也用于实现 MVCC，它允许读取事务开始前的数据版本，实现非锁定读。

### 2. 锁

InnoDB 实现了行级锁和表级锁，支持共享锁（S 锁）和排他锁（X 锁）。行级锁可以最大程度地减少数据库操作的冲突，提高并发性能。锁机制是实现事务隔离级别的基础，保证了事务的一致性和隔离性。

### 3. 多版本并发控制（MVCC）

MVCC 允许在不加锁的情况下，通过创建数据在某个时间点的“快照”来访问数据，从而提高并发性能。它通过撤销日志来实现，每个读取操作都可以看到一个一致性的数据快照。

### 4. 事务隔离级别

MySQL 支持四种事务隔离级别：READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。不同的隔离级别对应不同的一致性和隔离性保证，以及不同的性能开销。InnoDB 默认的隔离级别是 REPEATABLE READ，它通过锁和 MVCC 来实现。

### 5. 原子性操作

事务的原子性通过撤销日志实现。如果事务失败或调用了回滚命令，InnoDB 将使用撤销日志中的信息来撤销事务中已执行的操作，确保数据库的一致性。

### 实现事务的流程

1. **开始事务**：通过 `START TRANSACTION` 或设置自动提交为关闭来开始一个事务。
2. **执行操作**：在事务中执行 SQL 命令，如 INSERT、UPDATE、DELETE 等。
3. **日志记录**：修改操作写入撤销日志和重做日志。
4. **提交或回滚**：根据操作结果，提交事务并将修改永久保存到数据库，或回滚事务并撤销所有修改。
5. **锁释放**：事务完成后，释放所有在事务期间获得的锁。

MySQL 通过这些机制和流程实现了事务的 ACID 属性（原子性、一致性、隔离性、持久性），保证了数据库操作的可靠性和数据的完整性。

1. 看你会 Kitex，说一下这个你了解多少
2. **刚开你说到了 ZSet，底层是什么数据结构**
3. **这个底层的 Hashtable 时间复杂度**
4. 反问：

作者：Lewy 华  
链接：[https://www.nowcoder.com/discuss/551074669743378432?sourceSSR=users](https://www.nowcoder.com/discuss/551074669743378432?sourceSSR=users)  
来源：牛客网

## 松鼠 Ai Golang 后端实习 一面面经

- **golang 的内存模型**
- **golang 垃圾回收**
- **golang 数组和切片的底层实现**
- **给你一个容量 15 的切片，截取他的 [2:20] 可以吗**
- **mysql 底层数据结构**
- **b+ 树叶子结点的数据结构，怎么连接的**
- mysql 有很多种 int 类型，每种的大小多少
- tinyint 的范围是多少
- mysql 里面创建的时候 int1 int10 有啥区别
- 用户数据库分库分表，你会怎么分
- 那比如 1 亿个用户，你会通过那些字段来分
- **char varchar 区别**
- count * count 1 count 字段 的区别
- 那 count * count 字段的时候，某些字段有 null，那有啥区别？
- 看你项目有用 redis，说一下常用的数据结构
- 项目里怎么用的，zset 评论区怎么弄的
- 看你有用 redis 实现令牌桶，讲一下令牌桶的思想
- redis 用的什么数据结构实现的令牌桶
- 看你有用 rocketmq 做消息队列，为什么不用 redis 做呢？
- kafka 的 ack 机制了解吗？每个值对应哪种情况？
- 反问业务

作者：Lewy 华  
链接：[https://www.nowcoder.com/discuss/552458157377728512?sourceSSR=users](https://www.nowcoder.com/discuss/552458157377728512?sourceSSR=users)  
来源：牛客网

## 字节跳动 - 头条后端 (Go)- 暑期实习面经（已接 offer）

第一份实习，拿到 offer 才敢写面经系列…

面试经验总的来说：

- 心态一定要好，多和面试官交流，不要沉默，实在不会大方承认
- 简历上的项目一定要熟，项目用到的东西也要熟，用到 redis 必问
- 面试官喜欢问为什么，多查查，遇到了就能装 b
- 算法题需要亿点运气

### 一面（3.22）55min

面试官是个小姐姐，nice

1. **go 垃圾回收**
    - 不太熟，大概描述了一下，提了一嘴 Python（简历上写了熟悉 Python），小姐姐说没关系，说下 Python 是怎么做的
2. **hashmap**（说了 go 的 map 和 redis 的 hash 结构）
3. **redis rehash 过程**
4. **rehash 过程中添加数据，查询数据怎么办？**（就是问渐进式 rehash，刚好没看到，瞎猜了半天）
5. **hash 冲突用的什么方法解决的？查询时间？最坏时间？**
6. **你说链地址法冲突到一条链上会退化成 O(n)，它不好为什么要用？为什么不用其他的？**
    - 没太明白她的意思，我只是说最坏情况可没说它不好。。然后只能说它们各有优缺点吧
    - 应该再说一下链地址法的主要优势的
7. 一道没见过的算法题

> 给出一个分子式，比如：HMg2(H2ON3)3N2，计算这个分子式中每个原子出现了多少次，输出一个 map，比如上面的分子式中：map[string]int {"H": 7, "Mg": 2,"O": 3, …}
> 1. 都以大写字母开头，后面跟 0 个或者 1 个小写字母，比如 Mg, H
> 2. 单个原子后面跟 0 个或者 1 个数字表示它出现的次数，比如 Mg2 表示 Mg 出现 2 次，数字范围 2-9
> 3. 分子式中可能有括号，括号后面可能跟 0 个或者 1 个数字表示整个括号内的原子出现的次数，比如 (N3Ag)2 表示 N 出现 6 次，Ag 出现 2 次 4. 括号可以嵌套
> 4. 输入是合法的

上来就遇到这么长的题让我很慌，加上之前 redis 被问到不会，这里感觉都要停止思考了。。看了半天说想办法从后往前把数字乘进去去掉括号再处理，问她思路有没有问题，得到肯定回答才松了一口气，然后说了下具体方法，理清之后面试官把括号去掉了，然后说时间不够了写下简化版代码吧

1. 反问

算法题写了有二三十分钟，感觉要凉了，没想到结束时面试官说先别走啊，我去喊一下二面面试官，瞬间复活

### 二面（3.22）1h

逐渐有状态了，二面还算轻松，全程在线，当时感觉过挺快，回头一听才发现问了这么多问题

1. **gmp**
2. 协程的优势

协程（Coroutines）是一种轻量级的程序执行单位，相较于传统的线程和进程，协程提供了更为灵活和高效的并发编程模型。以下是协程的一些主要优势：

### 1. 更高的并发性

协程占用的资源少（尤其是内存），启动和切换的开销远小于线程，这意味着在相同的硬件资源条件下，可以运行更多的协程实例，实现更高的并发度。

### 2. 轻量级的上下文切换

协程的上下文切换开销比线程小得多，**因为协程的切换是由程序自身控制**而不是依赖于操作系统的调度，避免了传统线程切换时涉及到的内核态与用户态之间的**转换**。

### 3. 简化异步编程

协程支持以同步的方式编写异步代码，**极大地简化了异步编程的复杂度**。开发者可以使用协程以顺序的方式编写代码，**而底层实现则自动将其转化为非阻塞的异步调用**。

### 4. 提高资源利用率

通过使用协程，**应用程序能够以较少的线程处理更多的任务**，从而提高系统资源（尤其是 CPU 和内存）的利用率，降低系统负载。

### 5. 灵活的调度控制

协程的调度通常是由用户空间的库（如 Python 的 asyncio，Go 语言的 goroutine 调度器）控制的，**这为开发者提供了更灵活的控制机制**，可以根据应用程序的需要自定义调度策略。

### 7. 适用于 I/O 密集型任务

协程非常适合 **I/O 密集型**的应用场景，**如网络服务器**、**数据库操作等**。在这些场景下，协程能够在等待 I/O 操作完成时释放 CPU 资源给其他协程使用，从而提高程序的整体性能。

尽管协程提供了许多优势，但它们在使用时也需要注意合理的设计模式和错误处理策略，以避免出现死锁、资源泄露等问题。不同的编程语言和框架提供了不同的协程实现和 API，开发者应根据具体的应用需求和性能目标选择合适的协程模型。

1. **进程线程区别**
2. 进程地址空间有哪些划分
3. **进程间通信**
4. 共享内存是怎么回事？映射到实际物理内存的虚拟地址在地址空间的哪一部分（我猜在堆区）
5. 虚拟内存
6. 页面置换算法（说了局部算法和全局算法）
7. **LRU 实现思路**
8. mysql 引擎，它们的区别
9. **innodb 辅助索引为什么存主键 id，回表不是要浪费时间？**
10. **b+ 树索引优势**
11. **acid**
12. **隔离级别，可重读是怎么实现的？幻读是怎么回事？间隙锁知道不？**
13. 读写锁互斥关系，其他分类的锁
14. 我看你项目用到了 redis 具体用到了哪些数据结构？（string，hash，zset）
15. zset 实现，跳表是怎么回事？高度？时间复杂度？为什么不用 b+ 树？
16. **redis 是单进程还是多进程？**
17. 扒项目（另一个爬虫项目）
18. （第一个项目）压测怎么做的？其他一些可以优化的点
19. **力扣原题，舒服：力扣 33. 搜索旋转排序数组**
20. 反问

二面面试官超级 nice，各种引导，问到我不会了就说 ok 没问题，全程给我信心，越面越顺

晚上另一个 hr 小哥哥加我微信约了三面时间，之前联系我的小姐姐不见了，唉

### 三面（3.25）30min

1. 扒项目（收获什么的）
2. 我看你项目用了 mongodb，mongodb 存储索引知道吗？和 mysql 比有哪些优势？（回答 mongodb 并不熟，只是毕设想用用新东西，优点就知道非结构化扩展容易，速度快）
3. mysql 存储引擎
4. **项目用到了 redis 哪些结构（zset，hash），说一说底层实现**
5. **zset 除了跳表 +hash 表外还有其他实现吗？**
    - 才想起来数据量较小时会用压缩列表实现
    - 又问压缩列表实现的主要目的，答节省内存
6. **进程通信方式**
7. io 多路复用的几种方法（不熟，就提了下名字）
8. cookie session
9. 拥塞控制
10. **力扣原题，舒服：力扣 15. 三数之和**

三面面试官应该是某个部门老大，面相和蔼，问了 30 分钟就结束了，有点慌，没想到结束后 10 分钟 hr 就发来微信约 hr 面了

### Hr 面（3.29）15min

聊天，实习生都没啥好问的

面完晚上我等不及就微信问 hr 结果，说没问题，offer 在审批了，然后就是漫长的等待，中间还赶上清明假期，足足等了一周多才接到 offer，期待成为一名 ByteDancer

作者：两三点雨山前  
链接：[https://www.nowcoder.com/discuss/353157793744101376](https://www.nowcoder.com/discuss/353157793744101376)  
来源：牛客网

## 京东 Golang 开发工程师 校招三面面经，许愿 Offer

去年秋招的时候面试的这家公司，马上又要秋招了，给小伙伴们分享下作参考：

**一面（一个小时左右）**

1. 读写锁机制
2. **哈希的存储、查询和冲突**
3. Go sync.Map

## 面经

- [golang面试经验答案总结（一）分享一篇B站后端面经 哔哩哔哩_golang 2年经验面试-CSDN博客](https://blog.csdn.net/jinchenga/article/details/131500407?spm=1001.2014.3001.5502)
- [golang面试经验答案总结（二）字节跳动一面 golang_字节跳动go面试题-CSDN博客](https://blog.csdn.net/jinchenga/article/details/131502376?spm=1001.2014.3001.5502)
