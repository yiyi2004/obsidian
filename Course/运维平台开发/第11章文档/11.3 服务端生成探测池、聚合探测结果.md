# 01 配置中添加静态指定探测目标的配置

- 位置 server\config\config.go

```go
type Config struct {
	MysqlS       []*MySQLConf         `yaml:"mysql_s"`
	RpcAddr      string               `yaml:"rpc_addr"`
	HttpAddr     string               `yaml:"http_addr"`
	PCC          *PublicCloudSyncConf `yaml:"public_cloud_sync"`
	IndexModules []*IndexModuleConf   `yaml:"index_modules"`
	ProberTargets     []*Targets `yaml:"prober_targets"`
}
type Targets struct {
	ProberType string   `yaml:"prober_type"`
	Region     string   `yaml:"region"`
	Target     []string `yaml:"target"`
}

```

- yaml中的相关配置

```yaml
prober_targets:
  #  - prober_type: icmp
  #    region: region1
  #    target:
  #      - "1.1.1.1"
  #      - "2.2.2.2"
#  - prober_type: http
#    region: region2
#    target:
#      - http://yourdomain.com/api/xxx/xxx
```

# 02 根据上报的ip生成探测池

- 位置 D:\go_path\src\open-devops\src\modules\server\xprober\target_pool.go

```go
package xprober

import (
	"github.com/toolkits/pkg/logger"
	"open-devops/src/common"
	"open-devops/src/modules/server/config"
	"sync"
	"time"
	"context"

	"github.com/go-kit/kit/log"
	"github.com/go-kit/kit/log/level"

	"fmt"
)

type TargetPool struct {
	ProbeType     string
	regionTargets sync.Map
}

var (
	IcmpRegionProberMap  = sync.Map{}  // icmp的池子
	OtherRegionProberMap = sync.Map{} //http的池子
	AgentIpRegionMap     = sync.Map{}  // agent ip的map
)

type TargetFlushManager struct {
	Logger     log.Logger
	ConfigFile string
}

func rangeIcmpMap() {
	f := func(k, v interface{}) bool {
		region := k.(string)
		data := v.(*common.ProberTargets)
		fmt.Println("rangeIcmpMap", region, data)
		return true
	}

	IcmpRegionProberMap.Range(f)
}

func (t *TargetFlushManager) flushAgentIpIntoGlobalMap() {
	level.Info(t.Logger).Log("msg", "flushAgentIpIntoGlobalMap run....")
	tmpM := make(map[string][]string)

	f := func(k, v interface{}) bool {
		ip := k.(string)
		region := v.(string)
		logger.Infof("[AgentIpRegionMap.show][ip:%+v][region:%+v]",ip,region)
		tmpM[region] = append(tmpM[region], ip)

		return true
	}
	AgentIpRegionMap.Range(f)
	for region, ips := range tmpM {
		tNew := &common.ProberTargets{}
		tNew.Region = region
		tNew.ProberType = "icmp"
		tNew.Target = ips

		preData, loaded := IcmpRegionProberMap.LoadOrStore(region, tNew)
		preDataN := preData.(*common.ProberTargets)
		if loaded {
			thisT := tNew.Target
			originT := preDataN.Target
			thisTM := make(map[string]string)
			for _, tt := range thisT {
				thisTM[tt] = tt
			}
			for _, tt := range originT {
				if _, exists := thisTM[tt]; exists == false {
					thisT = append(thisT, tt)
				}
			}
			a := &common.ProberTargets{
				Region:     region,
				ProberType: "icmp",
				Target:     thisT,
			}
			IcmpRegionProberMap.Store(region, a)
		}

	}
	//rangeIcmpMap()

}

func NewTargetFlushManager(logger log.Logger, configFile string) *TargetFlushManager {

	return &TargetFlushManager{Logger: logger, ConfigFile: configFile}
}
func (t *TargetFlushManager) Run(ctx context.Context) error {

	ticker := time.NewTicker(10 * time.Second)
	level.Info(t.Logger).Log("msg", "TargetFlushManager start....")
	t.refresh()
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			t.refresh()

		case <-ctx.Done():
			level.Info(t.Logger).Log("msg", "TargetFlushManager exit....")
			return nil
		}
	}

}

func (t *TargetFlushManager) refreshFromConfigFile() {
	level.Info(t.Logger).Log("msg", "refreshFromConfigFile run....")

	config, _ := config.LoadFile(t.ConfigFile)
	otmpM := make(map[string][]*common.ProberTargets)
	icmpM := make(map[string]*common.ProberTargets)
	if len(config.ProberTargets) <= 0 {
		level.Info(t.Logger).Log("msg", "refreshFromConfigFile empty targets....")
		return
	}
	for _, t := range config.ProberTargets {
		tNew := &common.ProberTargets{}
		tNew.Region = t.Region
		tNew.ProberType = t.ProberType
		tNew.Target = t.Target
		otmpM[tNew.Region] = append(otmpM[tNew.Region], tNew)
		switch t.ProberType {
		case "icmp":
			icmpM[tNew.Region] = tNew
		default:
			otmpM[tNew.Region] = append(otmpM[tNew.Region], tNew)
		}

	}
	for k, v := range icmpM {
		preData, loaded := IcmpRegionProberMap.LoadOrStore(k, v)
		preDataN := preData.(*common.ProberTargets)
		if loaded {
			thisT := v.Target
			originT := preDataN.Target
			thisTM := make(map[string]string)
			for _, tt := range thisT {
				thisTM[tt] = tt
			}
			for _, tt := range originT {
				if _, exists := thisTM[tt]; exists == false {
					thisT = append(thisT, tt)
				}
			}
			a := &common.ProberTargets{
				Region:     k,
				ProberType: "icmp",
				Target:     thisT,
			}
			IcmpRegionProberMap.Store(k, a)
		}

	}

	for k, v := range otmpM {

		OtherRegionProberMap.Store(k, v)
	}
}

func (t *TargetFlushManager) refresh() {
	go t.refreshFromConfigFile()
	go t.flushAgentIpIntoGlobalMap()
}

func GetTargetsByRegion(sourceRegion string) (res []*common.ProberTargets) {

	f := func(k, v interface{}) bool {
		//key := k.(string)
		va := v.([]*common.ProberTargets)
		//if key != sourceRegion {
		res = append(res, va...)

		//}
		return true
	}
	fi := func(k, v interface{}) bool {
		key := k.(string)
		va := v.(*common.ProberTargets)
		if key != sourceRegion {
			res = append(res, va)

		}
		return true
	}

	IcmpRegionProberMap.Range(fi)
	OtherRegionProberMap.Range(f)
	return
}

```

# 03 新增数据处理的任务

- 位置  D:\go_path\src\open-devops\src\modules\server\xprober\data_process.go
- 为什么要做数据处理：就是为了去掉毛刺，将一个region内多个机器对另一个region 的探测结果聚合后得到更准确的数据，避免单个机器数据飘的问题

```go
package xprober

import (
	"open-devops/src/common"
	"sync"
	"time"
	"strings"
	"context"

	"github.com/go-kit/kit/log"
	"github.com/go-kit/kit/log/level"
	"github.com/prometheus/client_golang/prometheus"

)

const (
	MetricCollectInterval      = 15 * time.Second
	TargetFlushManagerInterval = 60 * time.Second
	MetricOriginSeparator      = `_`
	MetricUniqueSeparator      = `#`
)

// rpc receive data
// update to local cache
// ticker data process
// expose prome http metric

var (
	IcmpDataMap         = sync.Map{}
	HttpDataMap         = sync.Map{}
	PingLatencyGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNamePingLatency,
		Help: "Duration of ping prober ",
	}, []string{"source_region", "target_region"})
	PingPackageDropGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNamePingPackageDrop,
		Help: "rate of ping packagedrop ",
	}, []string{"source_region", "target_region"})

	PingTargetSuccessGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNamePingTargetSuccess,
		Help: "target success",
	}, []string{"source_region", "target_region"})

	HttpInterFaceSuccessGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpInterfaceSuccess,
		Help: "whether http probe success",
	}, []string{"source_region", "addr"})
	HttpHttpResolvedurationMillonsecondsGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpResolvedurationMillonseconds,
		Help: "domain resole time",
	}, []string{"source_region", "addr"})
	HttpTlsDurationMillonsecondsGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpTlsDurationMillonseconds,
		Help: "domain tls handshake time",
	}, []string{"source_region", "addr"})
	HttpConnectDurationMillonsecondsGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpConnectDurationMillonseconds,
		Help: "http connect time",
	}, []string{"source_region", "addr"})
	HttpProcessingDurationMillonsecondsGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpProcessingDurationMillonseconds,
		Help: "http process time",
	}, []string{"source_region", "addr"})
	HttpTransferDurationMillonsecondsGaugeVec = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: common.MetricsNameHttpTransferDurationMillonseconds,
		Help: "http transfer time",
	}, []string{"source_region", "addr"})
)

func NewMetrics() {

	prometheus.DefaultRegisterer.MustRegister(PingLatencyGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(PingPackageDropGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(PingTargetSuccessGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpInterFaceSuccessGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpHttpResolvedurationMillonsecondsGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpTlsDurationMillonsecondsGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpConnectDurationMillonsecondsGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpProcessingDurationMillonsecondsGaugeVec)
	prometheus.DefaultRegisterer.MustRegister(HttpTransferDurationMillonsecondsGaugeVec)
}

func DataProcess(ctx context.Context, logger log.Logger) error {

	ticker := time.NewTicker(MetricCollectInterval)
	level.Info(logger).Log("msg", "DataProcessManager start....")
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:

			go IcmpDataProcess(logger)
			go HttpDataProcess(logger)

		case <-ctx.Done():
			level.Info(logger).Log("msg", "DataProcessManager exit....")
			return nil
		}
	}

}

func HttpDataProcess(logger log.Logger) {
	level.Info(logger).Log("msg", "HttpDataProcess run....")
	var expireds []string
	resoleMap := make(map[string][]float64)
	processMap := make(map[string][]float64)
	transferMap := make(map[string][]float64)
	connMap := make(map[string][]float64)
	tlsMap := make(map[string][]float64)
	interSuccMap := make(map[string][]float64)

	f := func(k, v interface{}) bool {
		key := k.(string)
		va := v.(*common.ProberResultOne)

		// check item expire
		now := time.Now().Unix()
		if now-va.TimeStamp > 300 {
			expireds = append(expireds, key)
		} else {
			if strings.Contains(va.MetricName, MetricOriginSeparator) {
				metricType := strings.Split(va.MetricName, MetricOriginSeparator)[1]
				uniqueKey := va.MetricName + MetricUniqueSeparator + va.SourceRegion + MetricUniqueSeparator + va.TargetAddr

				switch metricType {
				case "resolveDuration":
					old := resoleMap[uniqueKey]
					if len(old) == 0 {
						resoleMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						resoleMap[uniqueKey] = append(resoleMap[uniqueKey], float64(va.Value))
					}
				case "tlsDuration":
					old := tlsMap[uniqueKey]
					if len(old) == 0 {
						tlsMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						tlsMap[uniqueKey] = append(tlsMap[uniqueKey], float64(va.Value))
					}
				case "connectDuration":
					old := tlsMap[uniqueKey]
					if len(old) == 0 {
						connMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						connMap[uniqueKey] = append(connMap[uniqueKey], float64(va.Value))
					}
				case "processingDuration":
					old := tlsMap[uniqueKey]
					if len(old) == 0 {
						processMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						processMap[uniqueKey] = append(processMap[uniqueKey], float64(va.Value))
					}
				case "transferDuration":
					old := tlsMap[uniqueKey]
					if len(old) == 0 {
						transferMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						transferMap[uniqueKey] = append(transferMap[uniqueKey], float64(va.Value))
					}
				case "interface":
					old := tlsMap[uniqueKey]
					if len(old) == 0 {
						interSuccMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						interSuccMap[uniqueKey] = append(interSuccMap[uniqueKey], float64(va.Value))
					}

				}
			}

		}

		return true
	}

	HttpDataMap.Range(f)
	// delete  expireds
	for _, e := range expireds {
		HttpDataMap.Delete(e)
	}

	// compute data with avg or pct99
	dealWithDataMapAvg(resoleMap, HttpHttpResolvedurationMillonsecondsGaugeVec, "http")
	dealWithDataMapAvg(connMap, HttpConnectDurationMillonsecondsGaugeVec, "http")
	dealWithDataMapAvg(tlsMap, HttpTlsDurationMillonsecondsGaugeVec, "http")
	dealWithDataMapAvg(processMap, HttpProcessingDurationMillonsecondsGaugeVec, "http")
	dealWithDataMapAvg(transferMap, HttpTransferDurationMillonsecondsGaugeVec, "http")
	dealWithDataMapAvg(interSuccMap, HttpInterFaceSuccessGaugeVec, "http")
}

func IcmpDataProcess(logger log.Logger) {

	level.Info(logger).Log("msg", "IcmpDataProcess run....")

	var expireds []string

	latencyMap := make(map[string][]float64)
	packagedropMap := make(map[string][]float64)
	targetSuccMap := make(map[string][]float64)

	f := func(k, v interface{}) bool {
		key := k.(string)
		va := v.(*common.ProberResultOne)

		// check item expire
		now := time.Now().Unix()
		if now-va.TimeStamp > 300 {
			expireds = append(expireds, key)
		} else {
			if strings.Contains(va.MetricName, MetricOriginSeparator) {
				metricType := strings.Split(va.MetricName, MetricOriginSeparator)[1]
				uniqueKey := va.MetricName + MetricUniqueSeparator + va.SourceRegion + MetricUniqueSeparator + va.TargetRegion

				switch metricType {
				case "latency":
					old := latencyMap[uniqueKey]
					if len(old) == 0 {
						latencyMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						latencyMap[uniqueKey] = append(latencyMap[uniqueKey], float64(va.Value))
					}
				case "packageDrop":
					old := packagedropMap[uniqueKey]
					if len(old) == 0 {
						packagedropMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						packagedropMap[uniqueKey] = append(packagedropMap[uniqueKey], float64(va.Value))
					}
				case "target":
					old := targetSuccMap[uniqueKey]
					if len(old) == 0 {
						targetSuccMap[uniqueKey] = []float64{float64(va.Value)}
					} else {
						targetSuccMap[uniqueKey] = append(targetSuccMap[uniqueKey], float64(va.Value))
					}
				}
			}

		}

		return true
	}
	IcmpDataMap.Range(f)
	// delete  expireds
	for _, e := range expireds {
		IcmpDataMap.Delete(e)
	}

	// compute data with avg or pct99
	dealWithDataMapAvg(latencyMap, PingLatencyGaugeVec, "icmp")
	dealWithDataMapAvg(packagedropMap, PingPackageDropGaugeVec, "icmp")

	dealWithDataMapBool(targetSuccMap, PingTargetSuccessGaugeVec, "icmp")

}

func dealWithDataMapAvg(dataM map[string][]float64, promeVec *prometheus.GaugeVec, pType string) {
	for uniqueKey, datas := range dataM {
		//MetricName := strings.Split(uniqueKey, MetricUniqueSeparator)[0]
		SourceRegion := strings.Split(uniqueKey, MetricUniqueSeparator)[1]
		TargetRegionOrAddr := strings.Split(uniqueKey, MetricUniqueSeparator)[2]
		var sum, avg float64
		num := len(datas)
		for _, ds := range datas {
			sum += ds
		}
		avg = sum / float64(num)
		switch pType {
		case "http":
			promeVec.With(prometheus.Labels{"source_region": SourceRegion, "addr": TargetRegionOrAddr}).Set(avg)
		case "icmp":
			promeVec.With(prometheus.Labels{"source_region": SourceRegion, "target_region": TargetRegionOrAddr}).Set(avg)
		}

	}
}

func dealWithDataMapBool(dataM map[string][]float64, promeVec *prometheus.GaugeVec, pType string) {

	for uniqueKey, datas := range dataM {
		//MetricName := strings.Split(uniqueKey, MetricUniqueSeparator)[0]
		SourceRegion := strings.Split(uniqueKey, MetricUniqueSeparator)[1]
		TargetRegionOrAddr := strings.Split(uniqueKey, MetricUniqueSeparator)[2]
		//var sum, avg float64
		//num := len(datas)

		thisFailNum := 0

		for _, ds := range datas {
			if ds == -1 {
				thisFailNum += 1
			}
		}

		if thisFailNum == len(datas) {
			promeVec.With(prometheus.Labels{"source_region": SourceRegion, "target_region": TargetRegionOrAddr}).Set(0)
		} else {
			promeVec.With(prometheus.Labels{"source_region": SourceRegion, "target_region": TargetRegionOrAddr}).Set(1)
		}

	}
}

```

# 04 rpc方法 给出agent的探测目标 和处理agent上报的探测结果

- 位置 D:\go_path\src\open-devops\src\modules\server\rpc\xprober.go

```go
package rpc

import (
	"github.com/toolkits/pkg/logger"
	"open-devops/src/common"
	"open-devops/src/modules/server/xprober"
)

func (*Server) GetProberTargets(req common.ProberTargetsGetRequest, res *common.ProberTargetsGetResponse) error {
	region := req.LocalRegion
	xprober.AgentIpRegionMap.Store(req.LocalIp, req.LocalRegion)
	tgs := xprober.GetTargetsByRegion(region)
	res.Targets = tgs
	return nil
}

func (*Server) PushProberResults(req common.ProberResultPushRequest, res *common.ProberResultPushResponse) error {
	suNum := 0
	logger.Infof("PushProberResults.req:%+v",req)
	for _, prr := range req.ProberResults {
		prr:=prr
		logger.Infof("PushProberResults.prr:%+v",prr)
		uid := GetProbeResultUid(prr)
		switch prr.ProbeType {
		case `icmp`:
			xprober.IcmpDataMap.Store(uid, prr)
		case `http`:
			xprober.HttpDataMap.Store(uid, prr)
		}
		suNum += 1

	}
	res.SuccessNum = int32(suNum)
	return nil

}

func GetProbeResultUid(prr *common.ProberResultOne) (uid string) {
	uid = prr.WorkerName + prr.MetricName + prr.SourceRegion + prr.TargetRegion + prr.ProbeType + prr.TargetAddr
	return

}

```

# 05 server中的收尾

- main中注册xprober相关的metrics

```go
	// 注册xprober相关的metrics
	xprober.NewMetrics()
```

- 开启刷新探测目标池的任务和数据处理的任务

```go

	{
		// 刷新探测目标池的任务
		tfm := xprober.NewTargetFlushManager(logger, *configFile)
		// target flush manager
		g.Add(func() error {
			err := tfm.Run(ctxAll)
			return err
		}, func(err error) {
			cancelAll()
		})
	}

	{

		// data proceess.
		g.Add(func() error {
			err := xprober.DataProcess(ctxAll, logger)
			return err
		}, func(err error) {
			cancelAll()
		})
	}
```