基于3.1中得到的特征，我们使用随机森林和深度学习进行检测。在本节我们将详细介绍随机森林算法以及基于 CNN 和 Bi-LSTM(双向 LSTM) 的深度学习网络模型。

# 随机森林
随机森林属于集成学习方法[13]，指的是利用有限数量的决策树对样本进行训练并预 测的一种分类器，该分类器最早由Leo Breiman和Adele Cutler提出，并被注册成了商标。由于其具备良好的解释性，分类效果优，鲁棒性强，不易过拟合的特点，是一种流 行并被广泛使用的机器学习方法。下面首先介绍决策树的概念。 

## 决策树
决策树是一种基本的分类与回归方法，本节讨论用于分类的决策树。决策树模型吸引人的地方在于其模型的可解释性。 

构建好的分类决策树模型呈树形结构。树由上至下的构造过程如下：从树的根节点 开始，测试实例的特征，并根据测试结果将实例分配给相应的子节点。每个子节点对应 于特征的值，以便递归地测试和分配所有实例直到到达叶节点，并且最后将实例划分为 叶节点的类。 

图2-6是决策树模型的示意图，将数据自顶向下进行划分。

![[Snipaste/Pasted image 20230314145423.png]]

## 集成学习
决策树存在的过度拟合问题，可以通过集成学习方法Bagging或Boosting处理。集成学习（ensemble）思想是为了解决单个模型或者某一组参数的模型所固有的缺陷，从 而整合起更多的模型，取长补短，避免局限性。随机森林就是集成学习思想下的产物， 将许多棵决策树整合成森林，并合起来用来预测最终结果，它属于集成学习（Ensemble  Learning）中的Bagging算法。 

在统计学和机器学习方法中，集成学习通过结合多个相同或不同类别的学习器来获得比单独使用任何学习算法更好的预测性能。与统计学中使用的统计集成（通常是无限 的）不同，机器学习集成是由一组具体的数量限定的模型组成，这些替代模型可以有灵 活的组成结构。如图2-7所示，集成学习将多个分类器的分类结果进行组合来决定最终 的分类。如果使用相同的分类器，称为同质，使用不同的分类器则称为异质，常见的综 合判断策略包括加权平均和投票两种。 

![[Snipaste/Pasted image 20230314145447.png]]

集成学习可以分为以Boosting系列算法为代表的一类和以Bagging系列算法为代表 的一类。前者的集成模型是由大量单个分类模型串行生成，通过迭代训练使下层分类器 能够对上层弱分类器的错误进行适应性调整。后者的集成模型型是由大量单个分类模型 并行生成，单个分类器之间不存在强依赖关系，集成后的模型可以减少差异并有助于避 免过度拟合。 

Bagging（套袋法）的算法过程如下： 

Bagging使用自助法（bootstrap）采样，即对于给定大小为n的标准训练集D，每次 先随机采集一个样本放入新训练集 +,i=1,2,3…k，接着把该样本放回，由于是替换采 样，每个 +中可能有相同的训练样本。共进行k轮抽取，得到k个训练集。由于是随机 采样，每次的采样集和原始的训练集不用，和其他采样集也不同，对于每个新训练集 + 分别训练模型，每个模型采用的机器学习方法视具体问题而定，采用决策树模型的就称 为随机森林方法，这样就得到多个不同的分类器。 

对多个分类器的结果进行综合判断之后就可得到最终结果。回归问题习惯性取多个 分类器结果的均值作为预测值，分类问题通过投票决策出最终分类结果。 

## 随机森林的构建过程
与上面介绍的 Bagging 过程相似，随机森林通过下述步骤构建：  
1. 从原始训练集中使用使用自助法（bootstrap）采样得到n_tree个训练集。  
2. 对每个训练集分别训练，得到n_tree个决策树模型。 
3. 决策树模型每次分裂时会根据衡量标准选择最好的特征进行分裂，二叉决策树常 用的不纯度划分标准有：基尼系数（Gini index）、熵（entropy）、误分类率（classification  error）。 
4. 在每棵树的每个子节点上重复此划分过程，直到叶子节点。 随机森林算法对噪声具有良好的鲁棒性，不需要剪枝。
5. 由此产生的多个决策树形成一个随机森林。分类问题的结果由多棵树分类器的投 票决定。

随机森林的方法由于使用了集成学习的思想，对数据集的列变量和行观测的随机化，实际上相当于对于样本和特征都进行了采样，所以可以避免决策树过拟合的问题。 

随机森林有许多优点，包括准确率高，随机性的引入使得具备有很好的抗噪声能力， 能处理很高维度的数据，并且不用做特征选择，训练速度快，可以得到变量重要性排序， 容易实现并行化等。 

![[Snipaste/Pasted image 20230314145615.png]]

# CNN + BiLSTM
深度学习能够自动提取深层特征，实现较高的检测精度。网络攻击所产生的的大量网络通信流量是可被获取的数据，其中包含着恶意的、隐蔽的行为特征，可以作为深度学习模型训练的基础。下面将介绍深度学习中的卷积神经网络、Bi-LSTM、相应数据集以及数据的预处理方法。

## 卷积神经网络

卷积神经网络是一种用于深度学习的网络架构，可以直接从数据中学习，无需手动提取特征。它试图模仿人类视觉皮层中神经细胞功能，来实现高性能的图片识别。与一般的神经网络类似，卷积神经网络包含输入层、输出层和中间隐藏层，利用逆向传播的方式进行学习。卷积神经网络最基本的形式如图13所示。第一层是输入层，其中图像中的一个像素对应一个神经元（图表中的一个正方形对应一个神经元）。接下来是对应于简单单元的卷积层和对应于复杂单元的池化层。在池化层之后，连接“全连接层”和“输出层”。

![](file:///C:\Users\zhang\AppData\Local\Temp\ksohtml28668\wps1.png)

图 13 卷积神经网络基本形式

全连接层对应于普通神经网络中的隐藏层和输出层，用于收集池化层的输出。卷积神经网络与普通神经网络的区别在于卷积层和池化层。下面将进一步描述这两层。

（1）卷积层

卷积层是提取图像局部特征的层，特征的数量取决于过滤器的大小和数值。在卷积层中，输入图像被切割成一定像素大小，然后计算切割部分以识别特征并提取。图2显示了输入层和卷积层之间的连接，并用一个数学公式表示。其中x是输入图像的每个像素的值，w是权重，b是偏差，σ是激活函数。

![](file:///C:\Users\zhang\AppData\Local\Temp\ksohtml28668\wps2.png)

图 14 卷积神经网络卷积层和池化层的连接

权重w和偏差b由数据调整，并且与神经网络一样，调整使得卷积网络的输出值与正确答案值之间的差异变小。这组权重w称为过滤器，并且表示可以用作上述区分线索的形状。由于w是基于数据的调优目标，可以看出卷积网络在学习过程中自动调整了对判别有效的形状。

卷积层的具体计算流程如下：

i. 在过滤器的的网格上准备数值数据和相同大小的部分图像窗口。
ii. 使用过滤器计算这个窗口得到一个特定的值，存储该数值，并将过滤器移动固定的步幅，然后再次计算。
iii. 当所有输入的计算完成后，计算得到的全体数值集合作为局部提取的特征输出到下一层。
通过卷积层得到的数值，可以确定图像具有什么样的特征。

（2）池化层
在池化层中，对卷积层中局部提取的特征进行压缩，并舍弃非必要部分。也就是说，CNN会在池化层中聚合提取卷积层中发现的图像特征。常用的池化方法有最大值池化和平均值池化，最大值池化是选择一个窗口中的最大值，平均值池化是选择一个窗口中的平均值。

由于检测对象是在网络中获取到的未知的、疑似攻击行为的原始流量。为了获取用于能够输入检测模型的行为数据，以实现模型的训练和后续的验证，需要对流量进行一些处理。流量数据处理结束后，输入分类器进行实验验证。

从图()中可以看出，所提出的模型由一个1-D CNN层和多层Bi-LSTM层组成，其中插入了Reshape和 Batch Normalization 层(以下简称 BN 层)。这个想法是利用1-D CNN层和最大池化层的参数共享、空间排列和局部感知特性。参数共享允许使用减少的参数集和自由变量进行特征提取，从而减少了处理资源的使用。空间排列允许以稀疏矩阵的形式排列到目前为止识别出的特征，以便更好地识别特征之间的相关性。最后，局部感知允许使用较少的参数，从而大大减少训练时间。因此，1-D CNN允许在给定时间序列数据的情况下进行快速的空间学习。1-D CNN层后面跟着一个最大池化层，它允许对参数进行基于样本的离散化，以识别相关的特征，从而减少训练时间并防止过拟合。在最大池化之后，是Batch Normalization层，它使中间层之间的参数归一化，以防止较慢的训练时间。在Batch Normalization层之后，Reshape层将前一层的输出重新塑造为接下来一对Bi-LSTM层所需的形式。

Bi-LSTM层用于学习正向和反向的时间序列数据，其中隐藏层利用两个具有相同输入且连接到相同输出的单元。其中一个单元处理正向时间序列，另一个处理反向时间序列。这种所谓的排列被认为是为了提供层与未来数据，以提高训练时间和更好地学习特征，从而使长时间跨度的时间序列数据具有更高的精度。

该模型中的两个Bi-LSTM层按照每次迭代将其内核大小加倍的方式排列。根据模型的模块图，第一个Bi-LSTM层从64个单元开始，下一个也是最后一个Bi-LSTM层有128个单元。之所以选择这种方式，是为了模仿从粗到细的学习方式，更好地理解由第一个1-D CNN层学习的长程时间相关特征之间的相关性，从而更好地提取特征并加速训练。在每个Bi-LSTM层之间，有一个最大池化层来排除最不相关的特征，并有批归一化层来归一化前一层中间层的输出数据，以提高性能并减少训练时间。

接下来是全连接的 Dense 层，作为输出层，并紧随其后的是 Dropout 层。即使模型在每个层之间使用了最大池化，但是为了防止过拟合，也设置了 Dropout 层。这样做的原因是，通常情况下，CNN 和 RNN 的结合会更容易过拟合，并且在测试集上表现不佳。为了控制过拟合，该模型使用了 K 折交叉验证来进行评估。(有关 K 折交叉验证的更多信息，请参见下一节)


![[Snipaste/Pasted image 20230314152604.png]]



![[Snipaste/Pasted image 20230315064901.png]]


本文提出的模型在NSL-KDD和UNSW-NB15两个数据集上进行了评价。 


NSL-KDD数据集：NSL-KDD数据集由加拿大新不伦瑞克大学提供。NSL-KDD数据集是对KDDCup'99数据集的改进，因为后者具有各种分析所揭示的固有缺陷。NSL-KDD包含完整KDD数据集的基本记录，是网络入侵检测系统分析中最流行的数据集之一。NSL-KDD与其前身有很多区别，包括：删除冗余记录，训练和测试数据集中记录的充分可用性以及每个难度组中选择的记录数与原始KDD数据集中记录百分比成反比。

UNSW-NB15数据集：该数据集于2015年由新南威尔士大学发布。自发布以来，UNSW数据集已被广泛使用，并提供了包括更广泛的攻击类型家族、提取的特征数量、用于模拟和收集数据的不同IP地址数量在内的一系列特性。该数据集由网络流量的现代正常和当代合成攻击活动的混合组成。表1和表2显示了NSL-KDD和UNSW-NB15数据集中提供的功能列表。


## 数据预处理

NSL-KDD和UNSW-NB15数据集的预处理通常由数值特征的标准化和类别特征的独热编码来处理。但是正如之前讨论的那样，NSL-KDD数据集中每个攻击类别都有精细的记录数量。另一方面，UNSW-NB15数据集中像Worms、Fuzzers等类别的记录数量非常少。为了解决这个问题，过采样技术已经在训练集中使用，以确保每个攻击类别具有可比较的记录数。

1. One Hot Encoding（独热编码）：NSL-KDD和UNSW-NB15数据集中存在分类特征，这些特征需要被转换为数字值，以便我们的深度学习模型能够给出良好的预测结果。因此，在预处理部分中，使用pandas Python库的get-dummies函数将这些列转换为数字值。选择使用独热编码而不是标签编码，因为标签编码会在同一列中产生多个数字，模型可能会误认为这些值是按特定顺序排列的，这会影响分类。
2. 归一化：归一化是将数据重新缩放到特定范围内，以减少冗余并提高模型的训练时间。本文使用了最小-最大归一化，将数据范围重新缩放到[0,1]。

![[Snipaste/Pasted image 20230314231052.png]]

3. Stratified K-fold 交叉验证：Stratification 是将数据重新排列以确保每个折叠都是整个数据集的良好代表的过程。Stratified K-fold 交叉验证技术将数据集分成 K 个集合，模型使用 K-1 个折叠进行训练，并在第 K 个折叠上进行验证。这一过程一直持续到所有折叠都被用来验证模型为止。Stratification 确保每个折叠都是整个数据集的良好代表，这有助于对参数进行微调，并帮助模型更好地分类攻击。相较于其他验证方法，选择 K-fold 方法是因为它的表现更好且需要更少的计算能力 [29]。
4. Oversampling（过采样）：随机过采样是指随机复制少数类数据点，这减少了数据不平衡，并提高了少数类的预测准确性。使用imblearn.oversampling Python库中的RandomOverSampler类进行过采样，其中‘minority’作为参数。 UNSW-NB15数据集中Worms少数类的样本数为173，相对于总样本数257,673而言非常少，这种不平衡降低了少数类的预测准确性[30]。因此，随机过采样技术仅应用于UNSW-NB15的训练集中，并且在准确性和检测率方面，Worms类别有明显的提高，如图12所示。

- [ ] 似乎还差数据集的问题 + 结论的事情

- [x] 大部分内容完成
- [ ] 查缺补漏，看内容有没有问题
- [ ] 专业名词注意有没有写对
- [ ] 对应图片
- [ ] 修改格式，最好可以直接复制粘贴
## 实验验证
用于评估所提出模型性能的一些指标包括：准确率（ACC）、检测率（DR）、误报率（FPR）、F1-Score和ROC-AUC曲线。其中，准确率和检测率分别衡量模型对于所有分类和攻击的预测能力。误报率是将正常记录误分类为攻击的百分比，这与检测率和准确率一样重要。如果误报率很高，则模型可能不够有效，即使其检测率和准确率很高。F1-Score给出了更现实的性能评估，因为精确率和召回率本身可能无法清楚地反映性能。上述指标的定义见方程式（7）、（8）、（9）和（10）。

![[Snipaste/Pasted image 20230315105531.png]]

其中，TP表示被正确分类的攻击数量，TN表示被正确分类的正常流量数量，FN表示被错误地分类为正常流量的攻击数量，FP表示被错误地分类为攻击的正常流量数量。

![[Snipaste/Pasted image 20230315105647.png]]

最后，ROC-AUC曲线衡量模型在阈值变化时区分数据集类别的能力。AUC（曲线下面积）是ROC曲线下面的整个区域，其值在0到1之间变化。AUC越高，模型分类不同类别的能力越好。

多类分类：在k从2到10的情况下，对UNSW-NB15数据集进行的多类分类结果可以在图9的表格中看到。平均准确率为82.084％（ACC），检测率（DR％）为92.506％，误报率为6.092％。

第10图显示了每个10个类别的检测率，该模型能够非常准确地分类正常、后门、DOS、漏洞利用、Shellcode、通用、侦察和蠕虫。该模型平均具有检测模糊器类别的能力。假阳性率（FPR%）相对较低，比任何最先进的模型都要好，可以在第9图的表格中看到。

对于NSL-KDD数据集的多类分类，该模型在k值为10时具有99.4%的最佳准确率，平均准确率为99.22%。平均检测率为98.882%，k值为10时的最佳结果为99.13%。平均FPR％为0.0043，k值为10时的最佳值为0.0033。在图11中查看单个类别DR的图表可以看出，对于k值大于4，U2R类别的DR值逐渐降低，这是因为随着k值的增加，训练样本的数量减少。其中三个类别，包括正常，DoS，Probe具有较高的DR。可以在图9、图11中查看准确率、DR和FPR的单独值及图表。

多类别NSL-KDD分析的F1分数显示，从k值2到8值逐渐上升，但对于k值为10略有下降。正如讨论过的那样，F1分数是测试模型非常可靠的指标，其中k值为8时的F1分数为0.9929。图表可以在图13中看到。

类别“Analysis”的DR%非常低，因为该类在数据集中只有2677个样本，仅占总样本数的1.03％，模型没有足够的数据在这个类上表现更好。类别“Worms”的记录百分比（0.067％）低于类别“Analysis”，但是“Worms”类别的检测率接近100％，如图12所示，这是过采样的结果。由于对“Worms”类别进行了过采样，因此模型能够更好地训练，因为有更多的样本可用于训练。在混淆矩阵Fig.14中，测试集中的所有18个记录都被分类为Worms，检测率为100％，FPR％为0。

图16是在UNSW-NB15数据集上的ROC-AUC曲线图，所有类别的曲线下面积（AUC）均在0.94-1.0之间，平均AUC为0.971。这表明该模型在区分数据集中的各种类别方面非常有效和准确。

图17展示了多类NSL-KDD数据集的AUC，对于所有类别来说都是1.00。如前所述，AUC是衡量模型在区分数据集内不同类别/分类方面的能力的指标，该模型在NSL-KDD数据集上表现良好。

UNSW-NB15数据集中"Worm"的检测率
