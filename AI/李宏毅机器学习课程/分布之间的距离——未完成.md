## KL 散度
用来衡量两个分布之间的差异，等于一个交叉熵减去一个信息熵(交叉熵损失函数的由来)

### KL 散度的性质
1. 非负性
2. 不对称性 KL(P||Q) != KL(Q||P)

因为其不对称性，再实际使用过程中可能会存在一些问题，于是引出了 JS 散度。

当两个分布完全不重叠的时候，那么这个距离将是 无穷大， 这样就没办法衡量两个分布之间的差异了（应该是计算机难以处理这样的数值把）

## JS 散度

## MMD


## 有的没的
核化法的知识点需要补充