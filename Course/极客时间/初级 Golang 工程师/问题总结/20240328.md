- [[../07 点赞|07 点赞]]

1. insrCnt
	1. WithContext
	2. Clauses(OnConflict{Doupdates: clasuse.Assignments{map[string]any}})
	3. Create 如果不冲突，就创建一个。
2. gorm.Expr 操作 —— "`read_cnt` + 1"
3. 创建联合唯一索引 —— 文章 - 文章 id
4. Redis HIncrBy 能够保证，read_cnt 不存在，先设置为 0，然后自增 1
5. Lua 脚本执行 read_cnt 自增
6. 检查 — 做某事，容易出现并发问题，所以要用 Redis Lua 脚本去剞劂
7. cnt_key: read_cnt like_cnt or collect_cnt
8. delta +1 or -1
9. 软删除，只是更新状态
10. upsert 语义  
11. 查询接口
	1. 返回文章 + 文章的阅读、点赞、收藏数量
12. 小结
	1. 直接维持住总数，Redis 里面或者 MySQL 中
	2. 如果仅仅维护在 Redis 中，启动的时候，或者 Redis 过期的时候需要执行 Count 操作。
13. 有序问题：业务有序、全局有序
14. 同一个消费者组里面，一个分区最多只有一个消费者
15. 消费者之间的关系
16. ACK
	1. 0 不需要服务端确认
	2. 1 客户端发送，需要写入主分区里面
	3. -1 需要服务端同步到所有 ISR 上
17. 超时 context cancel
18. 指定偏移量消费
	1. 关键调用 ResetOffset 方法
19. 异步消费，批量提交 —— 优化手段 | 点赞，因为可以 offset。
20. 读事件 利用 kafka 解耦。实际上没什么用。读事件时批量处理的。
	1. 凑成一批要注意超时控制
	2. 发起调用
21. 插入 100 条数据提交 100 次，插入 100 条数据和提交 1 次的性能相差很大。
22. 消费者本身类似于 web 服务器的东西，需要启动
23. 引入阅读记录功能，不需要改变任何原来的代码，只需要订阅响应的消息队列即可。
24. 升职加薪
	1. 统一的 MQ 抽象
	2. 生产者 API
	3. 消费者 API
	4. 消息本身的抽象
	5. 参考：https://github.com/ecodeclub/mq-api
25. 生产者端，多条消息聚合成一个一批消息
26. 消息积压的解决方法：
	1. 增加分区、topic 现实中基本不可能
	2. 异步消费：也就是前面例子，开启 goroutine 并发消费，最后合并提交，提高消费者的消费能力
		1. **为什么要合并提交**
		2. **不合并提交有什么问题**
	3. 批量消费：将原本一个业务一个消息，改造成一批业务一个消息，一次处理一批业务，参考 Incr 的解决方案。

---
- [[../08 可观测性 prometheus|08 可观测性 prometheus]]

---

- [[../09 榜单模型与分布式任务调度之榜单模型|09 榜单模型与分布式任务调度之榜单模型]]
- 什么样的才算是热点？
- 如何计算热点？
- 热点必然带来高并发，那么怎么保证性能？
- 如果热点功能崩溃了，怎么样降低对整个系统的影响？

1. Hacknews：得票数最重要，而后热度随着事件衰减
2. Reddit 模型：赞成票、反对票和发帖事件

## 面经

[腾讯 IEG 3.8后台实习一面凉经_牛客网 (nowcoder.com)](https://www.nowcoder.com/feed/main/detail/7fd962836a004d66a27ff9b6a6133830?sourceSSR=users)

1. 操作系统内存管理
	1. 内存分配
	2. 虚拟内存
	3. 分页和分段
	4. 页表和段表
	5. 交换
	6. 内存保护
	7. 垃圾回收
