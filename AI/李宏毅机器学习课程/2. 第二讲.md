![[Pasted image 20220404081923.png]]
- [ ] [kaggle](https://www.kaggle.com/)

training data
![[Pasted image 20220404082058.png]]
以上就是攻略

![[Pasted image 20220404084818.png]]

![[Pasted image 20220404085013.png]]

![[Pasted image 20220404085023.png]]
那到底是哪种问题呢？

![[Pasted image 20220404085122.png]]

![[Pasted image 20220404085903.png]]

可以训练一些简单的 model，大概看一下效果怎么样。然后再用 deep learning。
![[Pasted image 20220404090228.png]]

optimization issue

model bias：the next lesson

the question of overfitting. write down the loss of training data.

an extreme example: overfitting
![[Pasted image 20220404090552.png]]
![[Pasted image 20220404090746.png]]

the first method: add more training data: focus on ml and dl

data augmentation(create new data)

![[Pasted image 20220404091024.png]]

flip right and left

according to the training data features;

the second mothod: constrained model;

y = a + bx + cx^2;

![[Pasted image 20220404091250.png]]

1. less parameters, sharing parameters: fully connected CNN.
2. less features: two days data
3. early stopping
4. regularization
5. dropout

constrain too much
![[Pasted image 20220404091641.png]]
the problem of model bias

![[Pasted image 20220404091936.png]]

how to choose the right model.

the extreme example model

**the useage of kaggle**
![[Pasted image 20220404092231.png]]

![[Pasted image 20220404092353.png]]

speech recognition

benchmark corpora. 

cross validation;
![[Pasted image 20220404093225.png]]

how to divide the training data: N-fold cross validation;
![[Pasted image 20220404094005.png]]
![[Pasted image 20220404094236.png]]

mismatch: differ from mismatch, cannot be solved by adding training data;

 ![[Pasted image 20220404094453.png]]







