# 本节重点介绍 :

- 日志任务增量更新管理器
- 具体的日志job对象
- 读取日志的reader对象

日志任务增量更新管理器和具体的日志job对象

# 日志任务增量更新管理器

- 位置 logjob/manager.go

## 增量更新解读

- 后续会做配置热更新或者 agent和server的交互
- 也就是logjob会有更新的情况

### 增量更新管理器

- activeTargets 中的map代表当前活跃的日志任务
- ```
  type LogJobManager struct {
  	targetMtx     sync.Mutex
  	activeTargets map[string]*LogJob
  	cq            chan *consumer.AnalysPoint
  }

  ```

### 增量更新体现在sync方法中

- 远端或新传入的jobs代表最新的全量配置
- 用jobs和本地上次的activeTargets最差异化
- 首先遍历jobs，将全量的结果塞入thisAllTargets map中

```go
func (jm *LogJobManager) Sync(jobs []*LogJob) {
	thisNewTargets := make(map[string]*LogJob)
	thisAllTargets := make(map[string]*LogJob)

	jm.targetMtx.Lock()
	for _, t := range jobs {
		hash := t.hash()
		thisAllTargets[hash] = t
		if _, loaded := jm.activeTargets[hash]; !loaded {
			thisNewTargets[hash] = t
			jm.activeTargets[hash] = t
		}
	}

	// 停止旧的
	for hash, t := range jm.activeTargets {
		if _, loaded := thisAllTargets[hash]; !loaded {
			logger.Infof("stop %+v stra:%+v", t, t.Stra)
			t.stop()
			delete(jm.activeTargets, hash)
		}
	}

	jm.targetMtx.Unlock()
	// 开启新的
	for _, t := range thisNewTargets {
		t := t
		t.start()
		//t.start(jm.cq)
	}

}

```

- 同时如果job在jobs中，但是不在activeTargets说明是新增的任务，塞入 thisNewTargets map中
- 如果在这次的map thisAllTargets中 但是不在activeTargets中，说明已经删除了，需要停止
- 开启新的任务

## 要求管理的对象有三个方法

- hash 判断唯一性的
- start 开始
- stop 停止

# 具体的日志job对象

- 日志logjob\perjob.go

```go
type LogJob struct {
	r    string              // 代表我们的生成者
	c    string              // 代表我们的消费者
	Stra *config.LogStrategy // 策略

}
```

## 增量更新要求job 有start、stop、hash方法

## 字段解析

```go
type LogJob struct {
	r    *reader.Reader          // 读取日志
	c    *consumer.ConsumerGroup // 消费日志
	Stra *strategy.Strategy      // 策略
}

```

# 读取日志的reader对象

- [底层库使用](https://github.com/hpcloud/tail)

## 使用tailer封装reader对象

- 位置reader\reader.go

```go
package reader

import "github.com/hpcloud/tail"

type Reader struct {
	FilePath    string        //配置的日志路径
	tailer      *tail.Tail    //tailer对象
	Stream      chan string   // 同步日志的chan
	CurrentPath string        // 当前路径
	Close       chan struct{} // 关闭的chan
	FD          uint64        //文件的inode ,用来处理文件名变更的情况
}

```

## 初始化tailer，打开日志文件

- stream 由外部传入，用作同步
- 文件打开方式解读
  - SeekStart   = 0 // seek relative to the origin of the file
  - SeekCurrent = 1 // seek relative to the current offset
  - SeekEnd     = 2 // seek relative to the end
- 代码如下

```go

func NewReader(filePath string, stream chan string) (*Reader, error) {
	r := &Reader{
		FilePath: filePath,
		Stream:   stream,
		Close:    make(chan struct{}),
	}
	err := r.openFile(io.SeekEnd, filePath)
	return r, err
}

func (r *Reader) openFile(whence int, filepath string) error {
	seekinfo := &tail.SeekInfo{
		Offset: 0,
		Whence: whence,
	}
	config := tail.Config{
		Location: seekinfo,
		ReOpen:   true,
		Poll:     true,
		Follow:   true,
	}
	t, err := tail.TailFile(filepath, config)
	if err != nil {
		return err
	}
	r.tailer = t
	r.CurrentPath = filepath
	r.FD = 0
	return nil
}

```

## 开启reader的方法

- 启动一个协程进行日志统计
- 核心方法为通过tailer的Lines 读取，然后通过stream发送出去

```go
func (r *Reader) StartRead() {

	var (
		readCnt, readSwp int64
		dropCnt, dropSwp int64
	)

	analysClose := make(chan struct{})
	go func() {

		for {

			select {
			case <-analysClose:
				return
			case <-time.After(10 * time.Second):

			}
			a := readCnt
			b := dropCnt
			logger.Infof("read [%d] line in last 10s", a-readSwp)
			logger.Infof("drop [%d] line in last 10s", b-dropSwp)
			readSwp = a
			dropSwp = b
		}

	}()

	for line := range r.tailer.Lines {
		readCnt++
		select {
		case r.Stream <- line.Text:
		default:
			dropCnt++
		}
	}
	close(analysClose)
}

```

## 停止reader的方法

```go
func (r *Reader) Stop() {
	r.StopRead()
	close(r.Close)
}

func (r *Reader) StopRead() {
	r.tailer.Stop()
}

```

# 本节重点总结 :

- 日志任务增量更新管理器
  - 增量更新的通用方法
    - hash
    - stop
    - start
- 具体的日志job对象
- 读取日志的reader对象
  - tailer对象