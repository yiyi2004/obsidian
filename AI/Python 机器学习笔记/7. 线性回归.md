```python
import numpy as np  
import matplotlib.pyplot as plt  
import pandas as pd  
  
# 高阶多维  
# 我在这听你讲，还不如去看课件呢  
# 这里需要补充弄一下  
# 数值迭代，梯度下降  
def predict(X, w, b):  
 return X.dot(w) + b  
  
  
def loss(X, w, b, y):  
 return np.sum((predict(X, w, b) - y) ** 2) / len(X) / 2  
  
  
# 当你放松下来看这些的时候真的蛮简单的嘛。  
def gradient(X, w, b, y):  
 grad_b = np.sum(predict(X, w, b) - y) / len(X)  
    grad_w = X.T.dot(predict(X, w, b) - y)  
    return grad_b, grad_w  
  
  
def train(X, w, b, y, alpha=0.01, tal=0.00000001, times=100000):  
 loss1 = loss(X, w, b, y)  
    grad_b, grad_w = gradient(X, w, b, y)  
  
    b2 = b - alpha * grad_b  
    w2 = w - alpha * grad_w  
    # 确实没问题  
  
 loss2 = loss(X, w2, b2, y)  
  
    t = 0  
  
 while np.abs(loss1 - loss2) > tal and t < times:  
 w = w2  
        b = b2  
        loss1 = loss2  
  
        grad_b, grad_w = gradient(X, w, b, y)  
        b2 = b - alpha * grad_b  
        w2 = w - alpha * grad_w  
        loss2 = loss(X, w2, b2, y)  
  
        print(loss2)  
        t += 1  
  
 return w, b  
  
  
xTrain = np.array([[6, 2], [8, 1], [10.0], [14, 2], [18, 0]])  
yTrain = np.array([7, 9, 13, 17.5, 18])  
  
w = np.array([2, 1])  
w1, b = train(xTrain, w, 0, yTrain)
```

线性回归有很多形式哦，复杂的场景哦。

![[Pasted image 20220313121250.png]]

这里我为什么听不懂呢，扩维降阶，也就是最终结果不一定是和一次项有关系，可能是二次项的关系（猜测），所以要进行扩维降阶。

![[Pasted image 20220313121910.png]]

![[Pasted image 20220313150549.png]]


10 啊510

![[Pasted image 20220313163540.png]]

归一化问题，数据可能会出现越界的问题。多个算法实现的问题。
![[Pasted image 20220313164232.png]]

归一化处理

alpha 衰减
![[Pasted image 20220313165346.png]]
![[Pasted image 20220313165525.png]]

模型的评判，过拟合和欠拟合的概念。