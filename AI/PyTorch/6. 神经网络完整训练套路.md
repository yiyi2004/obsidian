其实大多数时候我们都在调参哦。
![[Pasted image 20220414152059.png]]
步骤
1. 准备数据集
2. 训练集和测试集的长度
3. DataLoader
4. Model
5. loss function
6. optimistion
	1. learning rate
	2. SGD
7. 设置网络的一些参数
	1. 记录训练的次数
	2. 记录测试的次数
	3. 训练轮数

item() 原来是 tensor 类型，转换成真则会那个的数字。

with torch.no_grad(): 什么含义呢。

![[Pasted image 20220414154029.png]]

分类问题中的正确率

![[Pasted image 20220414154205.png]]
1 横着看，0 竖着看

![[Pasted image 20220414154237.png]]
这其实和现代中的行和列有点不同哦。

![[Pasted image 20220414154343.png]]

计算预测正确的个数哦。

![[Pasted image 20220414160138.png]]

torch.train() 和 torch.eval() 只对一些特殊的层有作用，详细内容见官方文档。

你自定义中训练和测试不是一条线的都涉及到这个是什么意思呢

with torch.no_grad() 实际上值得是不对梯度进行优化（测试的时候不必对梯度进行优化）

## 利用 GPU 进行训练
### 方法一
找到
1. 网络模型
2. 数据（输入、标注）
3. 损失函数
.cuda() 就可以了哦
![[Pasted image 20220414160837.png]]

优化器没有 cuda 方法
![[Pasted image 20220414160922.png]]
![[Pasted image 20220414160940.png]]

![[Pasted image 20220414160958.png]]
更好的写法

GPU 块多了哦。晚上的时候可以试一试，速度是真的快哦。

云训练 GPU

google colab
![[Pasted image 20220414161419.png]]
colab 怎么使用 GPU
![[Pasted image 20220414161515.png]]

这显卡也太牛了
![[Pasted image 20220414161547.png]]

太 NB 了，就用 colab 了
### 方法二
![[Pasted image 20220414161656.png]]
我在 B 站读研究生
定义训练的设备

这样更方便更改了哦，这样只需要改变头 CPU ---> GPU

![[Pasted image 20220414161848.png]]
![[Pasted image 20220414161858.png]]

优秀哦
cpu cuda

数据、标注 需要复制，模型、损失函数不需要复制
![[Pasted image 20220414162138.png]]




这节课的文件
1. train.py
2. model.py
3. 
## 模型验证套路
用已经训练好的模型
test.py

colab 有 pytorch 环境哦
![[Pasted image 20220414175353.png]]
![[Pasted image 20220414175651.png]]![[Pasted image 20220414175652.png]]

一般是 1000 轮起步？
![[Pasted image 20220414175836.png]]
reshape
41
42
养成良好的代码习惯
#argmax
argmax(1) 是横向的意思，argmin(0) 是纵向的意思



## 存在问题
- [ ] 格式化字符串 Python

